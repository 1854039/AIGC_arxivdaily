{"2025-07-10T00:00:00Z":{"Machine Learning":[{"id":"http://arxiv.org/abs/2507.08000v1","updated":"2025-07-10T17:59:59Z","published":"2025-07-10T17:59:59Z","title":"Impact of Pretraining Word Co-occurrence on Compositional Generalization\n  in Multimodal Models","summary":"  CLIP and large multimodal models (LMMs) have better accuracy on examples\ninvolving concepts that are highly represented in the training data. However,\nthe role of concept combinations in the training data on compositional\ngeneralization is largely unclear -- for instance, how does accuracy vary when\na common object appears in an uncommon pairing with another object? In this\npaper, we investigate how word co-occurrence statistics in the pretraining\ndataset (a proxy for co-occurrence of visual concepts) impacts CLIP/LMM\nperformance. To disentangle the effects of word co-occurrence frequencies from\nsingle-word frequencies, we measure co-occurrence with pointwise mutual\ninformation (PMI), which normalizes the joint probability of two words\nco-occurring by the probability of co-occurring independently. Using\nsynthetically generated images with a variety of concept pairs, we show a\nstrong correlation between PMI in the CLIP pretraining data and zero-shot\naccuracy in CLIP models trained on LAION-400M (r=0.97 and 14% accuracy gap\nbetween images in the top and bottom 5% of PMI values), demonstrating that even\naccuracy on common concepts is affected by the combination of concepts in the\nimage. Leveraging this finding, we reproduce this effect in natural images by\nediting them to contain pairs with varying PMI, resulting in a correlation of\nr=0.75. Finally, we demonstrate that this behavior in CLIP transfers to LMMs\nbuilt on top of CLIP (r=0.70 for TextVQA, r=0.62 for VQAv2). Our findings\nhighlight the need for algorithms and architectures that improve compositional\ngeneralization in multimodal models without scaling the training data\ncombinatorially. Our code is available at\nhttps://github.com/helenqu/multimodal-pretraining-pmi.\n","authors":["Helen Qu","Sang Michael Xie"],"pdf_url":"https://arxiv.org/pdf/2507.08000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07995v1","updated":"2025-07-10T17:59:53Z","published":"2025-07-10T17:59:53Z","title":"Single-pass Adaptive Image Tokenization for Minimum Program Search","summary":"  According to Algorithmic Information Theory (AIT) -- Intelligent\nrepresentations compress data into the shortest possible program that can\nreconstruct its content, exhibiting low Kolmogorov Complexity (KC). In\ncontrast, most visual representation learning systems use fixed-length\nrepresentations for all inputs, ignoring variations in complexity or\nfamiliarity. Recent adaptive tokenization methods address this by allocating\nvariable-length representations but typically require test-time search over\nmultiple encodings to find the most predictive one. Inspired by Kolmogorov\nComplexity principles, we propose a single-pass adaptive tokenizer, KARL, which\npredicts the appropriate number of tokens for an image in a single forward\npass, halting once its approximate KC is reached. The token count serves as a\nproxy for the minimum description length. KARL's training procedure closely\nresembles the Upside-Down Reinforcement Learning paradigm, as it learns to\nconditionally predict token halting based on a desired reconstruction quality.\nKARL matches the performance of recent adaptive tokenizers while operating in a\nsingle pass. We present scaling laws for KARL, analyzing the role of\nencoder/decoder size, continuous vs. discrete tokenization and more.\nAdditionally, we offer a conceptual study drawing an analogy between Adaptive\nImage Tokenization and Algorithmic Information Theory, examining the predicted\nimage complexity (KC) across axes such as structure vs. noise and in- vs.\nout-of-distribution familiarity -- revealing alignment with human intuition.\n","authors":["Shivam Duggal","Sanghyun Byun","William T. Freeman","Antonio Torralba","Phillip Isola"],"pdf_url":"https://arxiv.org/pdf/2507.07995v1.pdf","comment":"Code at: https://github.com/ShivamDuggal4/karl Keywords:\n  Representation Learning, Adaptive Tokenization, Compression, Algorithmic\n  Information Theory, Kolmogorov Complexity, Upside-Down RL"},{"id":"http://arxiv.org/abs/2507.07996v1","updated":"2025-07-10T17:59:53Z","published":"2025-07-10T17:59:53Z","title":"Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs","summary":"  Can a pretrained neural network adapt its architecture to different inputs\nwithout any finetuning? Do we need all layers for simple tasks, and are they\nadequate for challenging tasks? We found that the layers of a pretrained large\nlanguage model (LLM) can be manipulated as separate modules to build a better\nand even shallower model customized for each test sample. In particular, each\nlayer from the pretrained model can be skipped/pruned or repeated multiple\ntimes as recurrent neural networks (RNN), and stacked with others in arbitrary\norders, yielding a chain-of-layers (CoLa) per sample. This compositional space\ngreatly expands the scope of existing works on looped/recurrent pretrained\nmodules, layer pruning, or early-exit networks. We develop a Monte Carlo Tree\nSearch (MCTS) protocol to explore and identify the optimal CoLa for each sample\nfrom math and commonsense reasoning benchmarks. Compared to a static model of a\nfixed depth, CoLa allows shortcut paths (fast thinking), recurrence of the same\nlayer(s) (slow thinking), and combining both, offering more flexible, dynamic\narchitectures for different inputs. We conduct an extensive analysis of the\nMCTS-optimized CoLa, which leads to two key findings: (1) For >75% of samples\nwith correct predictions by the original LLM, we can find shorter CoLa,\nsuggesting a large space for improving inference efficiency; (2) For >60% of\nsamples with originally incorrect predictions, we can identify CoLa achieving\ncorrect predictions, suggesting a large space of performance enhancement. Our\nresults highlight the shortcomings of using a fixed architecture of pre-trained\nLLMs for inference on different samples and pave the way to unlock the\ngeneralization power of test-time depth adaptation.\n","authors":["Ziyue Li","Yang Li","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.07996v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.07986v1","updated":"2025-07-10T17:57:46Z","published":"2025-07-10T17:57:46Z","title":"EXPO: Stable Reinforcement Learning with Expressive Policies","summary":"  We study the problem of training and fine-tuning expressive policies with\nonline reinforcement learning (RL) given an offline dataset. Training\nexpressive policy classes with online RL present a unique challenge of stable\nvalue maximization. Unlike simpler Gaussian policies commonly used in online\nRL, expressive policies like diffusion and flow-matching policies are\nparameterized by a long denoising chain, which hinders stable gradient\npropagation from actions to policy parameters when optimizing against some\nvalue function. Our key insight is that we can address stable value\nmaximization by avoiding direct optimization over value with the expressive\npolicy and instead construct an on-the-fly RL policy to maximize Q-value. We\npropose Expressive Policy Optimization (EXPO), a sample-efficient online RL\nalgorithm that utilizes an on-the-fly policy to maximize value with two\nparameterized policies -- a larger expressive base policy trained with a stable\nimitation learning objective and a light-weight Gaussian edit policy that edits\nthe actions sampled from the base policy toward a higher value distribution.\nThe on-the-fly policy optimizes the actions from the base policy with the\nlearned edit policy and chooses the value maximizing action from the base and\nedited actions for both sampling and temporal-difference (TD) backup. Our\napproach yields up to 2-3x improvement in sample efficiency on average over\nprior methods both in the setting of fine-tuning a pretrained policy given\noffline data and in leveraging offline data to train online.\n","authors":["Perry Dong","Qiyang Li","Dorsa Sadigh","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2507.07986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08938v2","updated":"2025-07-10T17:55:06Z","published":"2024-10-11T16:03:58Z","title":"KinDEL: DNA-Encoded Library Dataset for Kinase Inhibitors","summary":"  DNA-Encoded Libraries (DELs) represent a transformative technology in drug\ndiscovery, facilitating the high-throughput exploration of vast chemical\nspaces. Despite their potential, the scarcity of publicly available DEL\ndatasets presents a bottleneck for the advancement of machine learning\nmethodologies in this domain. To address this gap, we introduce KinDEL, one of\nthe largest publicly accessible DEL datasets and the first one that includes\nbinding poses from molecular docking experiments. Focused on two kinases,\nMitogen-Activated Protein Kinase 14 (MAPK14) and Discoidin Domain Receptor\nTyrosine Kinase 1 (DDR1), KinDEL includes 81 million compounds, offering a rich\nresource for computational exploration. Additionally, we provide comprehensive\nbiophysical assay validation data, encompassing both on-DNA and off-DNA\nmeasurements, which we use to evaluate a suite of machine learning techniques,\nincluding novel structure-based probabilistic models. We hope that our\nbenchmark, encompassing both 2D and 3D structures, will help advance the\ndevelopment of machine learning models for data-driven hit identification using\nDELs.\n","authors":["Benson Chen","Tomasz Danel","Gabriel H. S. Dreiman","Patrick J. McEnaney","Nikhil Jain","Kirill Novikov","Spurti Umesh Akki","Joshua L. Turnbull","Virja Atul Pandya","Boris P. Belotserkovskii","Jared Bryce Weaver","Ankita Biswas","Dat Nguyen","Kent Gorday","Mohammad Sultan","Nathaniel Stanley","Daniel M Whalen","Divya Kanichar","Christoph Klein","Emily Fox","R. Edward Watts"],"pdf_url":"https://arxiv.org/pdf/2410.08938v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07981v1","updated":"2025-07-10T17:55:05Z","published":"2025-07-10T17:55:05Z","title":"Why is Your Language Model a Poor Implicit Reward Model?","summary":"  Reward models are key to language model post-training and inference\npipelines. Conveniently, recent work showed that every language model defines\nan implicit reward model (IM-RM), without requiring any architectural changes.\nHowever, such IM-RMs tend to generalize worse, especially out-of-distribution,\ncompared to explicit reward models (EX-RMs) that apply a dedicated linear head\nover the hidden representations of a language model. The existence of a\ngeneralization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They\ncan be trained using the same data, loss function, and language model, and\ndiffer only in how the reward is computed. Towards a fundamental understanding\nof the implicit biases underlying different reward model types, we investigate\nthe root cause of this gap. Our main finding, backed by theory and experiments,\nis that IM-RMs rely more heavily on superficial token-level cues. Consequently,\nthey often generalize worse than EX-RMs under token-level distribution shifts,\nas well as in-distribution. Furthermore, we provide evidence against\nalternative hypotheses for the generalization gap. Most notably, we challenge\nthe intuitive claim that IM-RMs struggle in tasks where generation is harder\nthan verification because they can operate both as a verifier and a generator.\nTaken together, our results highlight that seemingly minor design choices can\nsubstantially impact the generalization behavior of reward models.\n","authors":["Noam Razin","Yong Lin","Jiarui Yao","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2507.07981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.04462v2","updated":"2025-07-10T17:50:21Z","published":"2025-06-04T21:29:07Z","title":"Watermarking Degrades Alignment in Language Models: Analysis and\n  Mitigation","summary":"  Watermarking techniques for large language models (LLMs) can significantly\nimpact output quality, yet their effects on truthfulness, safety, and\nhelpfulness remain critically underexamined. This paper presents a systematic\nanalysis of how two popular watermarking approaches-Gumbel and KGW-affect these\ncore alignment properties across four aligned LLMs. Our experiments reveal two\ndistinct degradation patterns: guard attenuation, where enhanced helpfulness\nundermines model safety, and guard amplification, where excessive caution\nreduces model helpfulness. These patterns emerge from watermark-induced shifts\nin token distribution, surfacing the fundamental tension that exists between\nalignment objectives.\n  To mitigate these degradations, we propose Alignment Resampling (AR), an\ninference-time sampling method that uses an external reward model to restore\nalignment. We establish a theoretical lower bound on the improvement in\nexpected reward score as the sample size is increased and empirically\ndemonstrate that sampling just 2-4 watermarked generations effectively recovers\nor surpasses baseline (unwatermarked) alignment scores. To overcome the limited\nresponse diversity of standard Gumbel watermarking, our modified implementation\nsacrifices strict distortion-freeness while maintaining robust detectability,\nensuring compatibility with AR. Experimental results confirm that AR\nsuccessfully recovers baseline alignment in both watermarking approaches, while\nmaintaining strong watermark detectability. This work reveals the critical\nbalance between watermark strength and model alignment, providing a simple\ninference-time solution to responsibly deploy watermarked LLMs in practice.\n","authors":["Apurv Verma","NhatHai Phan","Shubhendu Trivedi"],"pdf_url":"https://arxiv.org/pdf/2506.04462v2.pdf","comment":"Published at the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025. OpenReview: https://openreview.net/forum?id=SIBkIV48gF"},{"id":"http://arxiv.org/abs/2507.07969v1","updated":"2025-07-10T17:48:03Z","published":"2025-07-10T17:48:03Z","title":"Reinforcement Learning with Action Chunking","summary":"  We present Q-chunking, a simple yet effective recipe for improving\nreinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks.\nOur recipe is designed for the offline-to-online RL setting, where the goal is\nto leverage an offline prior dataset to maximize the sample-efficiency of\nonline learning. Effective exploration and sample-efficient learning remain\ncentral challenges in this setting, as it is not obvious how the offline data\nshould be utilized to acquire a good exploratory policy. Our key insight is\nthat action chunking, a technique popularized in imitation learning where\nsequences of future actions are predicted rather than a single action at each\ntimestep, can be applied to temporal difference (TD)-based RL methods to\nmitigate the exploration challenge. Q-chunking adopts action chunking by\ndirectly running RL in a 'chunked' action space, enabling the agent to (1)\nleverage temporally consistent behaviors from offline data for more effective\nonline exploration and (2) use unbiased $n$-step backups for more stable and\nefficient TD learning. Our experimental results demonstrate that Q-chunking\nexhibits strong offline performance and online sample efficiency, outperforming\nprior best offline-to-online methods on a range of long-horizon, sparse-reward\nmanipulation tasks.\n","authors":["Qiyang Li","Zhiyuan Zhou","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2507.07969v1.pdf","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2507.07965v1","updated":"2025-07-10T17:45:15Z","published":"2025-07-10T17:45:15Z","title":"Prospective Learning in Retrospect","summary":"  In most real-world applications of artificial intelligence, the distributions\nof the data and the goals of the learners tend to change over time. The\nProbably Approximately Correct (PAC) learning framework, which underpins most\nmachine learning algorithms, fails to account for dynamic data distributions\nand evolving objectives, often resulting in suboptimal performance. Prospective\nlearning is a recently introduced mathematical framework that overcomes some of\nthese limitations. We build on this framework to present preliminary results\nthat improve the algorithm and numerical results, and extend prospective\nlearning to sequential decision-making scenarios, specifically foraging. Code\nis available at: https://github.com/neurodata/prolearn2.\n","authors":["Yuxin Bai","Cecelia Shuai","Ashwin De Silva","Siyu Yu","Pratik Chaudhari","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2507.07965v1.pdf","comment":"Accepted to AGI 2025"},{"id":"http://arxiv.org/abs/2507.07955v1","updated":"2025-07-10T17:39:37Z","published":"2025-07-10T17:39:37Z","title":"Dynamic Chunking for End-to-End Hierarchical Sequence Modeling","summary":"  Despite incredible progress in language models (LMs) in recent years, largely\nresulting from moving away from specialized models designed for specific tasks\nto general models based on powerful architectures (e.g. the Transformer) that\nlearn everything from raw data, pre-processing steps such as tokenization\nremain a barrier to true end-to-end foundation models. We introduce a\ncollection of new techniques that enable a dynamic chunking mechanism which\nautomatically learns content -- and context -- dependent segmentation\nstrategies learned jointly with the rest of the model. Incorporating this into\nan explicit hierarchical network (H-Net) allows replacing the (implicitly\nhierarchical) tokenization-LM-detokenization pipeline with a single model\nlearned fully end-to-end. When compute- and data- matched, an H-Net with one\nstage of hierarchy operating at the byte level outperforms a strong Transformer\nlanguage model operating over BPE tokens. Iterating the hierarchy to multiple\nstages further increases its performance by modeling multiple levels of\nabstraction, demonstrating significantly better scaling with data and matching\na token-based Transformer of twice its size. H-Nets pretrained on English show\nsignificantly increased character-level robustness, and qualitatively learn\nmeaningful data-dependent chunking strategies without any heuristics or\nexplicit supervision. Finally, the H-Net's improvement over tokenized pipelines\nis further increased in languages and modalities with weaker tokenization\nheuristics, such as Chinese and code, or DNA sequences (nearly 4x improvement\nin data efficiency over baselines), showing the potential of true end-to-end\nmodels that learn and scale better from unprocessed data.\n","authors":["Sukjun Hwang","Brandon Wang","Albert Gu"],"pdf_url":"https://arxiv.org/pdf/2507.07955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07949v1","updated":"2025-07-10T17:33:52Z","published":"2025-07-10T17:33:52Z","title":"TinierHAR: Towards Ultra-Lightweight Deep Learning Models for Efficient\n  Human Activity Recognition on Edge Devices","summary":"  Human Activity Recognition (HAR) on resource-constrained wearable devices\ndemands inference models that harmonize accuracy with computational efficiency.\nThis paper introduces TinierHAR, an ultra-lightweight deep learning\narchitecture that synergizes residual depthwise separable convolutions, gated\nrecurrent units (GRUs), and temporal aggregation to achieve SOTA efficiency\nwithout compromising performance. Evaluated across 14 public HAR datasets,\nTinierHAR reduces Parameters by 2.7x (vs. TinyHAR) and 43.3x (vs.\nDeepConvLSTM), and MACs by 6.4x and 58.6x, respectively, while maintaining the\naveraged F1-scores. Beyond quantitative gains, this work provides the first\nsystematic ablation study dissecting the contributions of spatial-temporal\ncomponents across proposed TinierHAR, prior SOTA TinyHAR, and the classical\nDeepConvLSTM, offering actionable insights for designing efficient HAR systems.\nWe finally discussed the findings and suggested principled design guidelines\nfor future efficient HAR. To catalyze edge-HAR research, we open-source all\nmaterials in this work for future\nbenchmarking\\footnote{https://github.com/zhaxidele/TinierHAR}\n","authors":["Sizhen Bian","Mengxi Liu","Vitor Fortes Rey","Daniel Geissler","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2507.07949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07947v1","updated":"2025-07-10T17:32:26Z","published":"2025-07-10T17:32:26Z","title":"Low Resource Reconstruction Attacks Through Benign Prompts","summary":"  The recent advances in generative models such as diffusion models have raised\nseveral risks and concerns related to privacy, copyright infringements and data\nstewardship. To better understand and control the risks, various researchers\nhave created techniques, experiments and attacks that reconstruct images, or\npart of images, from the training set. While these techniques already establish\nthat data from the training set can be reconstructed, they often rely on\nhigh-resources, excess to the training set as well as well-engineered and\ndesigned prompts.\n  In this work, we devise a new attack that requires low resources, assumes\nlittle to no access to the actual training set, and identifies, seemingly,\nbenign prompts that lead to potentially-risky image reconstruction. This\nhighlights the risk that images might even be reconstructed by an uninformed\nuser and unintentionally. For example, we identified that, with regard to one\nexisting model, the prompt ``blue Unisex T-Shirt'' can generate the face of a\nreal-life human model. Our method builds on an intuition from previous works\nwhich leverages domain knowledge and identifies a fundamental vulnerability\nthat stems from the use of scraped data from e-commerce platforms, where\ntemplated layouts and images are tied to pattern-like prompts.\n","authors":["Sol Yarkoni","Roi Livni"],"pdf_url":"https://arxiv.org/pdf/2507.07947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02401v3","updated":"2025-07-10T17:18:00Z","published":"2023-11-04T13:25:49Z","title":"BarcodeBERT: Transformers for Biodiversity Analysis","summary":"  In the global challenge of understanding and characterizing biodiversity,\nshort species-specific genomic sequences known as DNA barcodes play a critical\nrole, enabling fine-grained comparisons among organisms within the same kingdom\nof life. Although machine learning algorithms specifically designed for the\nanalysis of DNA barcodes are becoming more popular, most existing methodologies\nrely on generic supervised training algorithms. We introduce BarcodeBERT, a\nfamily of models tailored to biodiversity analysis and trained exclusively on\ndata from a reference library of 1.5M invertebrate DNA barcodes. We compared\nthe performance of BarcodeBERT on taxonomic identification tasks against a\nspectrum of machine learning approaches including supervised training of\nclassical neural architectures and fine-tuning of general DNA foundation\nmodels. Our self-supervised pretraining strategies on domain-specific data\noutperform fine-tuned foundation models, especially in identification tasks\ninvolving lower taxa such as genera and species. We also compared BarcodeBERT\nwith BLAST, one of the most widely used bioinformatics tools for sequence\nsearching, and found that our method matched BLAST's performance in\nspecies-level classification while being 55 times faster. Our analysis of\nmasking and tokenization strategies also provides practical guidance for\nbuilding customized DNA language models, emphasizing the importance of aligning\nmodel training strategies with dataset characteristics and domain knowledge.\nThe code repository is available at https://github.com/bioscan-ml/BarcodeBERT.\n","authors":["Pablo Millan Arias","Niousha Sadjadi","Monireh Safari","ZeMing Gong","Austin T. Wang","Joakim Bruslund Haurum","Iuliia Zarubiieva","Dirk Steinke","Lila Kari","Angel X. Chang","Scott C. Lowe","Graham W. Taylor"],"pdf_url":"https://arxiv.org/pdf/2311.02401v3.pdf","comment":"Main text: 14 pages, Total: 23 pages, 10 figures, formerly accepted\n  at the 4th Workshop on Self-Supervised Learning: Theory and Practice (NeurIPS\n  2023)"},{"id":"http://arxiv.org/abs/2507.07929v1","updated":"2025-07-10T17:09:14Z","published":"2025-07-10T17:09:14Z","title":"Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and\n  Identification Strategies for Laboratory Mice","summary":"  Continuous, automated monitoring of laboratory mice enables more accurate\ndata collection and improves animal welfare through real-time insights.\nResearchers can achieve a more dynamic and clinically relevant characterization\nof disease progression and therapeutic effects by integrating behavioral and\nphysiological monitoring in the home cage. However, providing individual mouse\nmetrics is difficult because of their housing density, similar appearances,\nhigh mobility, and frequent interactions. To address these challenges, we\ndevelop a real-time identification (ID) algorithm that accurately assigns ID\npredictions to mice wearing custom ear tags in digital home cages monitored by\ncameras. Our pipeline consists of three parts: (1) a custom multiple object\ntracker (MouseTracks) that combines appearance and motion cues from mice; (2) a\ntransformer-based ID classifier (Mouseformer); and (3) a tracklet associator\nlinear program to assign final ID predictions to tracklets (MouseMap). Our\nmodels assign an animal ID based on custom ear tags at 30 frames per second\nwith 24/7 cage coverage. We show that our custom tracking and ID pipeline\nimproves tracking efficiency and lowers ID switches across mouse strains and\nvarious environmental factors compared to current mouse tracking methods.\n","authors":["Juan Pablo Oberhauser","Daniel Grzenda"],"pdf_url":"https://arxiv.org/pdf/2507.07929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.00004v2","updated":"2025-07-10T17:08:40Z","published":"2025-06-10T14:47:48Z","title":"A Theory of Inference Compute Scaling: Reasoning through Directed\n  Stochastic Skill Search","summary":"  Large language models (LLMs) demand considerable computational, energy, and\nfinancial resources during both training and deployment. While scaling laws for\ntraining have guided much of the field's recent progress, inference costs now\nrepresent a significant and growing component of the overall resource burden,\nparticularly for reasoning-focused models. Existing characterizations of\ncompute-optimality that consider model size, dataset size, and inference tokens\nin isolation or in fixed combinations risk overlooking more efficient operating\npoints. We introduce directed stochastic skill search (DS3), a general\nframework that represents inference as stochastic traversal over a learned\nskill graph. From a simplified yet expressive instantiation, we derive\nclosed-form expressions for task success and compute cost across a wide range\nof inference strategies -- including chain-of-thought (CoT) and tree-of-thought\n(ToT) -- enabling comparative analysis as a function of task difficulty and\nmodel capability. To that end, we extend a prior first-principles tripartite\ngraph framework of LLM training to incorporate inference, and separately bridge\nDS3 with empirical methods that characterize LLM scaling behavior. We\ntheoretically recover empirically observed patterns, including: linear accuracy\nscaling with logarithmic compute; variation in preferred inference strategies\nas a function of task difficulty and model capability; emergent behavior\nelicited by reasoning even when performance plateaus under parameter scaling;\nand both best-of-N (BoN) and majority voting behavior captured within a unified\nanalytical framework. By explicitly characterizing training-inference\ninterdependencies, our framework deepens theoretical understanding and supports\nprincipled algorithmic design and resource allocation.\n","authors":["Austin R. Ellis-Mohr","Anuj K. Nayak","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2507.00004v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18563v2","updated":"2025-07-10T17:01:15Z","published":"2024-05-28T20:15:09Z","title":"No $D_{\\text{train}}$: Model-Agnostic Counterfactual Explanations Using\n  Reinforcement Learning","summary":"  Machine learning (ML) methods have experienced significant growth in the past\ndecade, yet their practical application in high-impact real-world domains has\nbeen hindered by their opacity. When ML methods are responsible for making\ncritical decisions, stakeholders often require insights into how to alter these\ndecisions. Counterfactual explanations (CFEs) have emerged as a solution,\noffering interpretations of opaque ML models and providing a pathway to\ntransition from one decision to another. However, most existing CFE methods\nrequire access to the model's training dataset, few methods can handle\nmultivariate time-series, and none of model-agnostic CFE methods can handle\nmultivariate time-series without training datasets. These limitations can be\nformidable in many scenarios. In this paper, we present NTD-CFE, a novel\nmodel-agnostic CFE method based on reinforcement learning (RL) that generates\nCFEs when training datasets are unavailable. NTD-CFE is suitable for both\nstatic and multivariate time-series datasets with continuous and discrete\nfeatures. NTD-CFE reduces the CFE search space from a multivariate time-series\ndomain to a lower dimensional space and addresses the problem using RL. Users\nhave the flexibility to specify non-actionable, immutable, and preferred\nfeatures, as well as causal constraints. We demonstrate the performance of\nNTD-CFE against four baselines on several datasets and find that, despite not\nhaving access to a training dataset, NTD-CFE finds CFEs that make significantly\nfewer and significantly smaller changes to the input time-series. These\nproperties make CFEs more actionable, as the magnitude of change required to\nalter an outcome is vastly reduced. The code is available in the supplementary\nmaterial.\n","authors":["Xiangyu Sun","Raquel Aoki","Kevin H. Wilson"],"pdf_url":"https://arxiv.org/pdf/2405.18563v2.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR 2025)"},{"id":"http://arxiv.org/abs/2507.07919v1","updated":"2025-07-10T16:59:51Z","published":"2025-07-10T16:59:51Z","title":"Plausible Counterfactual Explanations of Recommendations","summary":"  Explanations play a variety of roles in various recommender systems, from a\nlegally mandated afterthought, through an integral element of user experience,\nto a key to persuasiveness. A natural and useful form of an explanation is the\nCounterfactual Explanation (CE). We present a method for generating highly\nplausible CEs in recommender systems and evaluate it both numerically and with\na user study.\n","authors":["Jakub Černý","Jiří Němeček","Ivan Dovica","Jakub Mareček"],"pdf_url":"https://arxiv.org/pdf/2507.07919v1.pdf","comment":"8 pages, 3 figures, 6 tables"},{"id":"http://arxiv.org/abs/2507.07907v1","updated":"2025-07-10T16:39:46Z","published":"2025-07-10T16:39:46Z","title":"A statistical physics framework for optimal learning","summary":"  Learning is a complex dynamical process shaped by a range of interconnected\ndecisions. Careful design of hyperparameter schedules for artificial neural\nnetworks or efficient allocation of cognitive resources by biological learners\ncan dramatically affect performance. Yet, theoretical understanding of optimal\nlearning strategies remains sparse, especially due to the intricate interplay\nbetween evolving meta-parameters and nonlinear learning dynamics. The search\nfor optimal protocols is further hindered by the high dimensionality of the\nlearning space, often resulting in predominantly heuristic, difficult to\ninterpret, and computationally demanding solutions. Here, we combine\nstatistical physics with control theory in a unified theoretical framework to\nidentify optimal protocols in prototypical neural network models. In the\nhigh-dimensional limit, we derive closed-form ordinary differential equations\nthat track online stochastic gradient descent through low-dimensional order\nparameters. We formulate the design of learning protocols as an optimal control\nproblem directly on the dynamics of the order parameters with the goal of\nminimizing the generalization error at the end of training. This framework\nencompasses a variety of learning scenarios, optimization constraints, and\ncontrol budgets. We apply it to representative cases, including optimal\ncurricula, adaptive dropout regularization and noise schedules in denoising\nautoencoders. We find nontrivial yet interpretable strategies highlighting how\noptimal protocols mediate crucial learning tradeoffs, such as maximizing\nalignment with informative input directions while minimizing noise fitting.\nFinally, we show how to apply our framework to real datasets. Our results\nestablish a principled foundation for understanding and designing optimal\nlearning protocols and suggest a path toward a theory of meta-learning grounded\nin statistical physics.\n","authors":["Francesca Mignacco","Francesco Mori"],"pdf_url":"https://arxiv.org/pdf/2507.07907v1.pdf","comment":"35 pages, 13 figures"},{"id":"http://arxiv.org/abs/2507.07906v1","updated":"2025-07-10T16:38:59Z","published":"2025-07-10T16:38:59Z","title":"Agentic Retrieval of Topics and Insights from Earnings Calls","summary":"  Tracking the strategic focus of companies through topics in their earnings\ncalls is a key task in financial analysis. However, as industries evolve,\ntraditional topic modeling techniques struggle to dynamically capture emerging\ntopics and their relationships. In this work, we propose an LLM-agent driven\napproach to discover and retrieve emerging topics from quarterly earnings\ncalls. We propose an LLM-agent to extract topics from documents, structure them\ninto a hierarchical ontology, and establish relationships between new and\nexisting topics through a topic ontology. We demonstrate the use of extracted\ntopics to infer company-level insights and emerging trends over time. We\nevaluate our approach by measuring ontology coherence, topic evolution\naccuracy, and its ability to surface emerging financial trends.\n","authors":["Anant Gupta","Rajarshi Bhowmik","Geoffrey Gunow"],"pdf_url":"https://arxiv.org/pdf/2507.07906v1.pdf","comment":"The 2nd Workshop on Financial Information Retrieval in the Era of\n  Generative AI, The 48th International ACM SIGIR Conference on Research and\n  Development in Information Retrieval July 13-17, 2025 | Padua, Italy"},{"id":"http://arxiv.org/abs/2507.07898v1","updated":"2025-07-10T16:27:33Z","published":"2025-07-10T16:27:33Z","title":"Efficient Causal Discovery for Autoregressive Time Series","summary":"  In this study, we present a novel constraint-based algorithm for causal\nstructure learning specifically designed for nonlinear autoregressive time\nseries. Our algorithm significantly reduces computational complexity compared\nto existing methods, making it more efficient and scalable to larger problems.\nWe rigorously evaluate its performance on synthetic datasets, demonstrating\nthat our algorithm not only outperforms current techniques, but also excels in\nscenarios with limited data availability. These results highlight its potential\nfor practical applications in fields requiring efficient and accurate causal\ninference from nonlinear time series data.\n","authors":["Mohammad Fesanghary","Achintya Gopal"],"pdf_url":"https://arxiv.org/pdf/2507.07898v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2506.11315v2","updated":"2025-07-10T16:24:53Z","published":"2025-06-12T21:31:08Z","title":"Sampling Imbalanced Data with Multi-objective Bilevel Optimization","summary":"  Two-class classification problems are often characterized by an imbalance\nbetween the number of majority and minority datapoints resulting in poor\nclassification of the minority class in particular. Traditional approaches,\nsuch as reweighting the loss function or na\\\"ive resampling, risk overfitting\nand subsequently fail to improve classification because they do not consider\nthe diversity between majority and minority datasets. Such consideration is\ninfeasible because there is no metric that can measure the impact of imbalance\non the model. To obviate these challenges, we make two key contributions.\nFirst, we introduce MOODS~(Multi-Objective Optimization for Data Sampling), a\nnovel multi-objective bilevel optimization framework that guides both synthetic\noversampling and majority undersampling. Second, we introduce a validation\nmetric -- `$\\epsilon/ \\delta$ non-overlapping diversification metric' -- that\nquantifies the goodness of a sampling method towards model performance. With\nthis metric we experimentally demonstrate state-of-the-art performance with\nimprovement in diversity driving a $1-15 \\%$ increase in $F1$ scores.\n","authors":["Karen Medlin","Sven Leyffer","Krishnan Raghavan"],"pdf_url":"https://arxiv.org/pdf/2506.11315v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10733v2","updated":"2025-07-10T16:19:07Z","published":"2025-04-14T21:56:11Z","title":"Cross-Problem Parameter Transfer in Quantum Approximate Optimization\n  Algorithm: A Machine Learning Approach","summary":"  Quantum Approximate Optimization Algorithm (QAOA) is one of the most\npromising candidates to achieve the quantum advantage in solving combinatorial\noptimization problems. The process of finding a good set of variational\nparameters in the QAOA circuit has proven to be challenging due to multiple\nfactors, such as barren plateaus. As a result, there is growing interest in\nexploiting parameter transferability, where parameter sets optimized for one\nproblem instance are transferred to another that could be more complex either\nto estimate the solution or to serve as a warm start for further optimization.\nBut can we transfer parameters from one class of problems to another?\nLeveraging parameter sets learned from a well-studied class of problems could\nhelp navigate the less studied one, reducing optimization overhead and\nmitigating performance pitfalls. In this paper, we study whether pretrained\nQAOA parameters of MaxCut can be used as is or to warm start the Maximum\nIndependent Set (MIS) circuits. Specifically, we design machine learning models\nto find good donor candidates optimized on MaxCut and apply their parameters to\nMIS acceptors. Our experimental results show that such parameter transfer can\nsignificantly reduce the number of optimization iterations required while\nachieving comparable approximation ratios.\n","authors":["Kien X. Nguyen","Bao Bach","Ilya Safro"],"pdf_url":"https://arxiv.org/pdf/2504.10733v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06687v3","updated":"2025-07-10T16:14:55Z","published":"2024-08-13T07:27:02Z","title":"Masked Image Modeling: A Survey","summary":"  In this work, we survey recent studies on masked image modeling (MIM), an\napproach that emerged as a powerful self-supervised learning technique in\ncomputer vision. The MIM task involves masking some information, e.g. pixels,\npatches, or even latent representations, and training a model, usually an\nautoencoder, to predicting the missing information by using the context\navailable in the visible part of the input. We identify and formalize two\ncategories of approaches on how to implement MIM as a pretext task, one based\non reconstruction and one based on contrastive learning. Then, we construct a\ntaxonomy and review the most prominent papers in recent years. We complement\nthe manually constructed taxonomy with a dendrogram obtained by applying a\nhierarchical clustering algorithm. We further identify relevant clusters via\nmanually inspecting the resulting dendrogram. Our review also includes datasets\nthat are commonly used in MIM research. We aggregate the performance results of\nvarious masked image modeling methods on the most popular datasets, to\nfacilitate the comparison of competing methods. Finally, we identify research\ngaps and propose several interesting directions of future work. We supplement\nour survey with the following public repository containing organized\nreferences: https://github.com/vladhondru25/MIM-Survey.\n","authors":["Vlad Hondru","Florinel Alin Croitoru","Shervin Minaee","Radu Tudor Ionescu","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2408.06687v3.pdf","comment":"Accepted at the International Journal of Computer Vision"},{"id":"http://arxiv.org/abs/2410.11171v3","updated":"2025-07-10T16:14:13Z","published":"2024-10-15T01:17:23Z","title":"A Bilevel Optimization Framework for Imbalanced Data Classification","summary":"  Data rebalancing techniques, including oversampling and undersampling, are a\ncommon approach to addressing the challenges of imbalanced data. To tackle\nunresolved problems related to both oversampling and undersampling, we propose\na new undersampling approach that: (i) avoids the pitfalls of noise and overlap\ncaused by synthetic data and (ii) avoids the pitfall of under-fitting caused by\nrandom undersampling. Instead of undersampling majority data randomly, our\nmethod undersamples datapoints based on their ability to improve model loss.\nUsing improved model loss as a proxy measurement for classification\nperformance, our technique assesses a datapoint's impact on loss and rejects\nthose unable to improve it. In so doing, our approach rejects majority\ndatapoints redundant to datapoints already accepted and, thereby, finds an\noptimal subset of majority training data for classification. The accept/reject\ncomponent of our algorithm is motivated by a bilevel optimization problem\nuniquely formulated to identify the optimal training set we seek. Experimental\nresults show our proposed technique with F1 scores up to 10% higher than\nstate-of-the-art methods.\n","authors":["Karen Medlin","Sven Leyffer","Krishnan Raghavan"],"pdf_url":"https://arxiv.org/pdf/2410.11171v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07885v1","updated":"2025-07-10T16:12:06Z","published":"2025-07-10T16:12:06Z","title":"UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient\n  Neural Inference on MCUs","summary":"  Existing pruning methods are typically applied during training or compile\ntime and often rely on structured sparsity. While compatible with low-power\nmicrocontrollers (MCUs), structured pruning underutilizes the opportunity for\nfine-grained efficiency on devices without SIMD support or parallel compute. To\naddress these limitations, we introduce UnIT (Unstructured Inference-Time\npruning), a lightweight method that dynamically identifies and skips\nunnecessary multiply-accumulate (MAC) operations during inference, guided by\ninput-specific activation patterns. Unlike structured pruning, UnIT embraces\nirregular sparsity and does not require retraining or hardware specialization.\nIt transforms pruning decisions into lightweight comparisons, replacing\nmultiplications with threshold checks and approximated divisions. UnIT further\noptimizes compute by reusing threshold computations across multiple connections\nand applying layer- and group-specific pruning sensitivity. We present three\nfast, hardware-friendly division approximations tailored to the capabilities of\ncommon embedded platforms. Demonstrated on the MSP430 microcontroller, UnIT\nachieves 11.02% to 82.03% MAC reduction, 27.30% to 84.19% faster inference, and\n27.33% to 84.38% lower energy consumption compared to training-time pruned\nmodels, while maintaining accuracy with 0.48-7%. Under domain shift, UnIT\nmatches or exceeds the accuracy of retrained models while requiring\nsignificantly fewer MACs. These results establish unstructured inference-time\npruning as a viable and practical solution for efficient, retraining-free\ndeployment of deep neural networks on MCUs.\n","authors":["Ashe Neth","Sawinder kaur","Mohammad Nur Hossain Khan","Subrata Biswas","Asif Salekin","Bashima Islam"],"pdf_url":"https://arxiv.org/pdf/2507.07885v1.pdf","comment":"Submitted to SenSys 2026 on July 1, 2025"},{"id":"http://arxiv.org/abs/2507.07883v1","updated":"2025-07-10T16:06:02Z","published":"2025-07-10T16:06:02Z","title":"SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization\n  with Joint Global-Local Perturbation","summary":"  Multi-task learning (MTL) enables a joint model to capture commonalities\nacross multiple tasks, reducing computation costs and improving data\nefficiency. However, a major challenge in MTL optimization is task conflicts,\nwhere the task gradients differ in direction or magnitude, limiting model\nperformance compared to single-task counterparts. Sharpness-aware minimization\n(SAM) minimizes task loss while simultaneously reducing the sharpness of the\nloss landscape. Our empirical observations show that SAM effectively mitigates\ntask conflicts in MTL. Motivated by these findings, we explore integrating SAM\ninto MTL but face two key challenges. While both the average loss gradient and\nindividual task gradients-referred to as global and local\ninformation-contribute to SAM, how to combine them remains unclear. Moreover,\ndirectly computing each task gradient introduces significant computational and\nmemory overheads. To address these challenges, we propose SAMO, a lightweight\n\\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization\napproach, that leverages a joint global-local perturbation. The local\nperturbations are approximated using only forward passes and are layerwise\nnormalized to improve efficiency. Extensive experiments on a suite of\nmulti-task benchmarks demonstrate both the effectiveness and efficiency of our\nmethod. Code is available at https://github.com/OptMN-Lab/SAMO.\n","authors":["Hao Ban","Gokul Ram Subramani","Kaiyi Ji"],"pdf_url":"https://arxiv.org/pdf/2507.07883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07882v1","updated":"2025-07-10T16:05:16Z","published":"2025-07-10T16:05:16Z","title":"Can AI-predicted complexes teach machine learning to compute drug\n  binding affinity?","summary":"  We evaluate the feasibility of using co-folding models for synthetic data\naugmentation in training machine learning-based scoring functions (MLSFs) for\nbinding affinity prediction. Our results show that performance gains depend\ncritically on the structural quality of augmented data. In light of this, we\nestablished simple heuristics for identifying high-quality co-folding\npredictions without reference structures, enabling them to substitute for\nexperimental structures in MLSF training. Our study informs future data\naugmentation strategies based on co-folding models.\n","authors":["Wei-Tse Hsu","Savva Grevtsev","Thomas Douglas","Aniket Magarkar","Philip C. Biggin"],"pdf_url":"https://arxiv.org/pdf/2507.07882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06952v2","updated":"2025-07-10T16:01:42Z","published":"2025-07-09T15:36:15Z","title":"What Has a Foundation Model Found? Using Inductive Bias to Probe for\n  World Models","summary":"  Foundation models are premised on the idea that sequence prediction can\nuncover deeper domain understanding, much like how Kepler's predictions of\nplanetary motion later led to the discovery of Newtonian mechanics. However,\nevaluating whether these models truly capture deeper structure remains a\nchallenge. We develop a technique for evaluating foundation models that\nexamines how they adapt to synthetic datasets generated from some postulated\nworld model. Our technique measures whether the foundation model's inductive\nbias aligns with the world model, and so we refer to it as an inductive bias\nprobe. Across multiple domains, we find that foundation models can excel at\ntheir training tasks yet fail to develop inductive biases towards the\nunderlying world model when adapted to new tasks. We particularly find that\nfoundation models trained on orbital trajectories consistently fail to apply\nNewtonian mechanics when adapted to new physics tasks. Further analysis reveals\nthat these models behave as if they develop task-specific heuristics that fail\nto generalize.\n","authors":["Keyon Vafa","Peter G. Chang","Ashesh Rambachan","Sendhil Mullainathan"],"pdf_url":"https://arxiv.org/pdf/2507.06952v2.pdf","comment":"To appear in ICML 2025"},{"id":"http://arxiv.org/abs/2507.07877v1","updated":"2025-07-10T16:00:27Z","published":"2025-07-10T16:00:27Z","title":"Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition\n  Models","summary":"  Recent advances in Automatic Speech Recognition (ASR) have demonstrated\nremarkable accuracy and robustness in diverse audio applications, such as live\ntranscription and voice command processing. However, deploying these models on\nresource constrained edge devices (e.g., IoT device, wearables) still presents\nsubstantial challenges due to strict limits on memory, compute and power.\nQuantization, particularly Post-Training Quantization (PTQ), offers an\neffective way to reduce model size and inference cost without retraining.\nDespite its importance, the performance implications of various advanced\nquantization methods and bit-width configurations on ASR models remain unclear.\nIn this work, we present a comprehensive benchmark of eight state-of-the-art\n(SOTA) PTQ methods applied to two leading edge-ASR model families, Whisper and\nMoonshine. We systematically evaluate model performances (i.e., accuracy,\nmemory I/O and bit operations) across seven diverse datasets from the open ASR\nleaderboard, analyzing the impact of quantization and various configurations on\nboth weights and activations. Built on an extension of the LLM compression\ntoolkit, our framework integrates edge-ASR models, diverse advanced\nquantization algorithms, a unified calibration and evaluation data pipeline,\nand detailed analysis tools. Our results characterize the trade-offs between\nefficiency and accuracy, demonstrating that even 3-bit quantization can succeed\non high capacity models when using advanced PTQ techniques. These findings\nprovide valuable insights for optimizing ASR models on low-power, always-on\nedge devices.\n","authors":["Chen Feng","Yicheng Lin","Shaojie Zhuo","Chenzheng Su","Ramchalam Kinattinkara Ramakrishnan","Zhaocong Yuan","Xiaopeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.04931v2","updated":"2025-07-10T16:00:00Z","published":"2025-05-08T04:09:36Z","title":"Fair Uncertainty Quantification for Depression Prediction","summary":"  Trustworthy depression prediction based on deep learning, incorporating both\npredictive reliability and algorithmic fairness across diverse demographic\ngroups, is crucial for clinical application. Recently, achieving reliable\ndepression predictions through uncertainty quantification has attracted\nincreasing attention. However, few studies have focused on the fairness of\nuncertainty quantification (UQ) in depression prediction. In this work, we\ninvestigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage\n(EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for\ndepression prediction. FUQ pursues reliable and fair depression predictions\nthrough group-based analysis. Specifically, we first group all the participants\nby different sensitive attributes and leverage conformal prediction to quantify\nuncertainty within each demographic group, which provides a theoretically\nguaranteed and valid way to quantify uncertainty for depression prediction and\nfacilitates the investigation of fairness across different demographic groups.\nFurthermore, we propose a fairness-aware optimization strategy that formulates\nfairness as a constrained optimization problem under EOC constraints. This\nenables the model to preserve predictive reliability while adapting to the\nheterogeneous uncertainty levels across demographic groups, thereby achieving\noptimal fairness. Through extensive evaluations on several visual and audio\ndepression datasets, our approach demonstrates its effectiveness.\n","authors":["Yonghong Li","Xiuzhuang Zhou"],"pdf_url":"https://arxiv.org/pdf/2505.04931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07872v1","updated":"2025-07-10T15:55:05Z","published":"2025-07-10T15:55:05Z","title":"Improving AEBS Validation Through Objective Intervention Classification\n  Leveraging the Prediction Divergence Principle","summary":"  The safety validation of automatic emergency braking system (AEBS) requires\naccurately distinguishing between false positive (FP) and true positive (TP)\nsystem activations. While simulations allow straightforward differentiation by\ncomparing scenarios with and without interventions, analyzing activations from\nopen-loop resimulations - such as those from field operational testing (FOT) -\nis more complex. This complexity arises from scenario parameter uncertainty and\nthe influence of driver interventions in the recorded data. Human labeling is\nfrequently used to address these challenges, relying on subjective assessments\nof intervention necessity or situational criticality, potentially introducing\nbiases and limitations. This work proposes a rule-based classification approach\nleveraging the Prediction Divergence Principle (PDP) to address those issues.\nApplied to a simplified AEBS, the proposed method reveals key strengths,\nlimitations, and system requirements for effective implementation. The findings\nsuggest that combining this approach with human labeling may enhance the\ntransparency and consistency of classification, thereby improving the overall\nvalidation process. While the rule set for classification derived in this work\nadopts a conservative approach, the paper outlines future directions for\nrefinement and broader applicability. Finally, this work highlights the\npotential of such methods to complement existing practices, paving the way for\nmore reliable and reproducible AEBS validation frameworks.\n","authors":["Daniel Betschinske","Steven Peters"],"pdf_url":"https://arxiv.org/pdf/2507.07872v1.pdf","comment":"This work has been accepted for publication at the 2025 IEEE\n  International Automated Vehicle Validation Conference (IAVVC)"},{"id":"http://arxiv.org/abs/2507.07871v1","updated":"2025-07-10T15:52:32Z","published":"2025-07-10T15:52:32Z","title":"Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key\n  Watermarking","summary":"  Watermarking offers a promising solution for GenAI providers to establish the\nprovenance of their generated content. A watermark is a hidden signal embedded\nin the generated content, whose presence can later be verified using a secret\nwatermarking key. A threat to GenAI providers are \\emph{watermark stealing}\nattacks, where users forge a watermark into content that was \\emph{not}\ngenerated by the provider's models without access to the secret key, e.g., to\nfalsely accuse the provider. Stealing attacks collect \\emph{harmless}\nwatermarked samples from the provider's model and aim to maximize the expected\nsuccess rate of generating \\emph{harmful} watermarked samples. Our work focuses\non mitigating stealing attacks while treating the underlying watermark as a\nblack-box. Our contributions are: (i) Proposing a multi-key extension to\nmitigate stealing attacks that can be applied post-hoc to any watermarking\nmethod across any modality. (ii) We provide theoretical guarantees and\ndemonstrate empirically that our method makes forging substantially less\neffective across multiple datasets, and (iii) we formally define the threat of\nwatermark forging as the task of generating harmful, watermarked content and\nmodel this threat via security games.\n","authors":["Toluwani Aremu","Noor Hussein","Munachiso Nwadike","Samuele Poppi","Jie Zhang","Karthik Nandakumar","Neil Gong","Nils Lukas"],"pdf_url":"https://arxiv.org/pdf/2507.07871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.03023v2","updated":"2025-07-10T15:51:03Z","published":"2025-02-05T09:26:47Z","title":"Parametric Scaling Law of Tuning Bias in Conformal Prediction","summary":"  Conformal prediction is a popular framework of uncertainty quantification\nthat constructs prediction sets with coverage guarantees. To uphold the\nexchangeability assumption, many conformal prediction methods necessitate an\nadditional holdout set for parameter tuning. Yet, the impact of violating this\nprinciple on coverage remains underexplored, making it ambiguous in practical\napplications. In this work, we empirically find that the tuning bias - the\ncoverage gap introduced by leveraging the same dataset for tuning and\ncalibration, is negligible for simple parameter tuning in many conformal\nprediction methods. In particular, we observe the scaling law of the tuning\nbias: this bias increases with parameter space complexity and decreases with\ncalibration set size. Formally, we establish a theoretical framework to\nquantify the tuning bias and provide rigorous proof for the scaling law of the\ntuning bias by deriving its upper bound. In the end, we discuss how to reduce\nthe tuning bias, guided by the theories we developed.\n","authors":["Hao Zeng","Kangdao Liu","Bingyi Jing","Hongxin Wei"],"pdf_url":"https://arxiv.org/pdf/2502.03023v2.pdf","comment":"ICML 2025: https://icml.cc/virtual/2025/poster/44287 and code at:\n  https://github.com/ml-stat-Sustech/Parametric-Scaling-Law-CP-Tuning"},{"id":"http://arxiv.org/abs/2507.06608v2","updated":"2025-07-10T15:48:42Z","published":"2025-07-09T07:27:18Z","title":"Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient\n  GPU Sharing","summary":"  Current prefill-decode (PD) disaggregation is typically deployed at the level\nof entire serving engines, assigning separate GPUs to handle prefill and decode\nphases. While effective at reducing latency, this approach demands more\nhardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode\nrequests within the same batch, but introduces phase interference between\nprefill and decode.\n  While existing PD disaggregation solutions separate the phases across GPUs,\nwe ask: can the same decoupling be achieved within a single serving engine? The\nkey challenge lies in managing the conflicting resource requirements of prefill\nand decode when they share the same hardware. In this paper, we first show that\nchunked prefill requests cause interference with decode requests due to their\ndistinct requirements for GPU resources. Second, we find that GPU resources\nexhibit diminishing returns. Beyond a saturation point, increasing GPU\nallocation yields negligible latency improvements. This insight enables us to\nsplit a single GPU's resources and dynamically allocate them to prefill and\ndecode on the fly, effectively disaggregating the two phases within the same\nGPU.\n  Across a range of models and workloads, our system Nexus achieves up to 2.2x\nhigher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also\noutperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x\nlower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using\nonly half the number of GPUs.\n","authors":["Xiaoxiang Shi","Colin Cai","Junjia Du","Zhanda Zhu","Zhihao Jia"],"pdf_url":"https://arxiv.org/pdf/2507.06608v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07867v1","updated":"2025-07-10T15:47:43Z","published":"2025-07-10T15:47:43Z","title":"Re-Bottleneck: Latent Re-Structuring for Neural Audio Autoencoders","summary":"  Neural audio codecs and autoencoders have emerged as versatile models for\naudio compression, transmission, feature-extraction, and latent-space\ngeneration. However, a key limitation is that most are trained to maximize\nreconstruction fidelity, often neglecting the specific latent structure\nnecessary for optimal performance in diverse downstream applications. We\npropose a simple, post-hoc framework to address this by modifying the\nbottleneck of a pre-trained autoencoder. Our method introduces a\n\"Re-Bottleneck\", an inner bottleneck trained exclusively through latent space\nlosses to instill user-defined structure. We demonstrate the framework's\neffectiveness in three experiments. First, we enforce an ordering on latent\nchannels without sacrificing reconstruction quality. Second, we align latents\nwith semantic embeddings, analyzing the impact on downstream diffusion\nmodeling. Third, we introduce equivariance, ensuring that a filtering operation\non the input waveform directly corresponds to a specific transformation in the\nlatent space. Ultimately, our Re-Bottleneck framework offers a flexible and\nefficient way to tailor representations of neural audio models, enabling them\nto seamlessly meet the varied demands of different applications with minimal\nadditional training.\n","authors":["Dimitrios Bralios","Jonah Casebeer","Paris Smaragdis"],"pdf_url":"https://arxiv.org/pdf/2507.07867v1.pdf","comment":"Accepted at IEEE MLSP 2025"},{"id":"http://arxiv.org/abs/2507.07862v1","updated":"2025-07-10T15:42:31Z","published":"2025-07-10T15:42:31Z","title":"Predicting and generating antibiotics against future pathogens with\n  ApexOracle","summary":"  Antimicrobial resistance (AMR) is escalating and outpacing current antibiotic\ndevelopment. Thus, discovering antibiotics effective against emerging pathogens\nis becoming increasingly critical. However, existing approaches cannot rapidly\nidentify effective molecules against novel pathogens or emerging drug-resistant\nstrains. Here, we introduce ApexOracle, an artificial intelligence (AI) model\nthat both predicts the antibacterial potency of existing compounds and designs\nde novo molecules active against strains it has never encountered. Departing\nfrom models that rely solely on molecular features, ApexOracle incorporates\npathogen-specific context through the integration of molecular features\ncaptured via a foundational discrete diffusion language model and a\ndual-embedding framework that combines genomic- and literature-derived strain\nrepresentations. Across diverse bacterial species and chemical modalities,\nApexOracle consistently outperformed state-of-the-art approaches in activity\nprediction and demonstrated reliable transferability to novel pathogens with\nlittle or no antimicrobial data. Its unified representation-generation\narchitecture further enables the in silico creation of \"new-to-nature\"\nmolecules with high predicted efficacy against priority threats. By pairing\nrapid activity prediction with targeted molecular generation, ApexOracle offers\na scalable strategy for countering AMR and preparing for future\ninfectious-disease outbreaks.\n","authors":["Tianang Leng","Fangping Wan","Marcelo Der Torossian Torres","Cesar de la Fuente-Nunez"],"pdf_url":"https://arxiv.org/pdf/2507.07862v1.pdf","comment":"3 figures"},{"id":"http://arxiv.org/abs/2506.15709v3","updated":"2025-07-10T15:40:39Z","published":"2025-05-30T15:17:23Z","title":"Studying and Improving Graph Neural Network-based Motif Estimation","summary":"  Graph Neural Networks (GNNs) are a predominant method for graph\nrepresentation learning. However, beyond subgraph frequency estimation, their\napplication to network motif significance-profile (SP) prediction remains\nunder-explored, with no established benchmarks in the literature. We propose to\naddress this problem, framing SP estimation as a task independent of subgraph\nfrequency estimation. Our approach shifts from frequency counting to direct SP\nestimation and modulates the problem as multitarget regression. The\nreformulation is optimised for interpretability, stability and scalability on\nlarge graphs. We validate our method using a large synthetic dataset and\nfurther test it on real-world graphs. Our experiments reveal that 1-WL limited\nmodels struggle to make precise estimations of SPs. However, they can\ngeneralise to approximate the graph generation processes of networks by\ncomparing their predicted SP with the ones originating from synthetic\ngenerators. This first study on GNN-based motif estimation also hints at how\nusing direct SP estimation can help go past the theoretical limitations that\nmotif estimation faces when performed through subgraph counting.\n","authors":["Pedro C. Vieira","Miguel E. P. Silva","Pedro Manuel Pinto Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2506.15709v3.pdf","comment":"This manuscript represents a revised version from the paper on\n  https://openreview.net/forum?id=PZVVOeu6xx. Still a work in progress.\n  Comments are welcome! 23 pages (12 main text + references), 9 figures, 5\n  tables. (Second update: More accurate Table 4, Run time comparisons.)"},{"id":"http://arxiv.org/abs/2507.07855v1","updated":"2025-07-10T15:38:17Z","published":"2025-07-10T15:38:17Z","title":"Principled Foundations for Preference Optimization","summary":"  In this paper, we show that direct preference optimization (DPO) is a very\nspecific form of a connection between two major theories in the ML context of\nlearning from preferences: loss functions (Savage) and stochastic choice\n(Doignon-Falmagne and Machina). The connection is established for all of\nSavage's losses and at this level of generality, (i) it includes support for\nabstention on the choice theory side, (ii) it includes support for non-convex\nobjectives on the ML side, and (iii) it allows to frame for free some notable\nextensions of the DPO setting, including margins and corrections for length.\nGetting to understand how DPO operates from a general principled perspective is\ncrucial because of the huge and diverse application landscape of models,\nbecause of the current momentum around DPO, but also -- and importantly --\nbecause many state of the art variations on DPO definitely occupy a small\nregion of the map that we cover. It also helps to understand the pitfalls of\ndeparting from this map, and figure out workarounds.\n","authors":["Wenxuan Zhou","Shujian Zhang","Brice Magdalou","John Lambert","Ehsan Amid","Richard Nock","Andrew Hard"],"pdf_url":"https://arxiv.org/pdf/2507.07855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07854v1","updated":"2025-07-10T15:33:53Z","published":"2025-07-10T15:33:53Z","title":"Credit Risk Analysis for SMEs Using Graph Neural Networks in Supply\n  Chain","summary":"  Small and Medium-sized Enterprises (SMEs) are vital to the modern economy,\nyet their credit risk analysis often struggles with scarce data, especially for\nonline lenders lacking direct credit records. This paper introduces a Graph\nNeural Network (GNN)-based framework, leveraging SME interactions from\ntransaction and social data to map spatial dependencies and predict loan\ndefault risks. Tests on real-world datasets from Discover and Ant Credit (23.4M\nnodes for supply chain analysis, 8.6M for default prediction) show the GNN\nsurpasses traditional and other GNN baselines, with AUCs of 0.995 and 0.701 for\nsupply chain mining and default prediction, respectively. It also helps\nregulators model supply chain disruption impacts on banks, accurately\nforecasting loan defaults from material shortages, and offers Federal Reserve\nstress testers key data for CCAR risk buffers. This approach provides a\nscalable, effective tool for assessing SME credit risk.\n","authors":["Zizhou Zhang","Qinyan Shen","Zhuohuan Hu","Qianying Liu","Huijie Shen"],"pdf_url":"https://arxiv.org/pdf/2507.07854v1.pdf","comment":"The paper will be published on 2025 International Conference on Big\n  Data, Artificial Intelligence and Digital Economy"},{"id":"http://arxiv.org/abs/2507.07853v1","updated":"2025-07-10T15:33:28Z","published":"2025-07-10T15:33:28Z","title":"Optimization Guarantees for Square-Root Natural-Gradient Variational\n  Inference","summary":"  Variational inference with natural-gradient descent often shows fast\nconvergence in practice, but its theoretical convergence guarantees have been\nchallenging to establish. This is true even for the simplest cases that involve\nconcave log-likelihoods and use a Gaussian approximation. We show that the\nchallenge can be circumvented for such cases using a square-root\nparameterization for the Gaussian covariance. This approach establishes novel\nconvergence guarantees for natural-gradient variational-Gaussian inference and\nits continuous-time gradient flow. Our experiments demonstrate the\neffectiveness of natural gradient methods and highlight their advantages over\nalgorithms that use Euclidean or Wasserstein geometries.\n","authors":["Navish Kumar","Thomas Möllenhoff","Mohammad Emtiyaz Khan","Aurelien Lucchi"],"pdf_url":"https://arxiv.org/pdf/2507.07853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07852v1","updated":"2025-07-10T15:33:27Z","published":"2025-07-10T15:33:27Z","title":"Pre-Trained AI Model Assisted Online Decision-Making under Missing\n  Covariates: A Theoretical Perspective","summary":"  We study a sequential contextual decision-making problem in which certain\ncovariates are missing but can be imputed using a pre-trained AI model. From a\ntheoretical perspective, we analyze how the presence of such a model influences\nthe regret of the decision-making process. We introduce a novel notion called\n\"model elasticity\", which quantifies the sensitivity of the reward function to\nthe discrepancy between the true covariate and its imputed counterpart. This\nconcept provides a unified way to characterize the regret incurred due to model\nimputation, regardless of the underlying missingness mechanism. More\nsurprisingly, we show that under the missing at random (MAR) setting, it is\npossible to sequentially calibrate the pre-trained model using tools from\northogonal statistical learning and doubly robust regression. This calibration\nsignificantly improves the quality of the imputed covariates, leading to much\nbetter regret guarantees. Our analysis highlights the practical value of having\nan accurate pre-trained model in sequential decision-making tasks and suggests\nthat model elasticity may serve as a fundamental metric for understanding and\nimproving the integration of pre-trained models in a wide range of data-driven\ndecision-making problems.\n","authors":["Haichen Hu","David Simchi-Levi"],"pdf_url":"https://arxiv.org/pdf/2507.07852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.11713v2","updated":"2025-07-10T15:32:14Z","published":"2025-03-12T22:19:33Z","title":"Revisiting the Predictability of Performative, Social Events","summary":"  Social predictions do not passively describe the future; they actively shape\nit. They inform actions and change individual expectations in ways that\ninfluence the likelihood of the predicted outcome. Given these dynamics, to\nwhat extent can social events be predicted? This question was discussed\nthroughout the 20th century by authors like Merton, Morgenstern, Simon, and\nothers who considered it a central issue in social science methodology. In this\nwork, we provide a modern answer to this old problem. Using recent ideas from\nperformative prediction and outcome indistinguishability, we establish that one\ncan always efficiently predict social events accurately, regardless of how\npredictions influence data. While achievable, we also show that these\npredictions are often undesirable, highlighting the limitations of previous\ndesiderata. We end with a discussion of various avenues forward.\n","authors":["Juan C. Perdomo"],"pdf_url":"https://arxiv.org/pdf/2503.11713v2.pdf","comment":"21 pages, accepted to ICML 2025"},{"id":"http://arxiv.org/abs/2507.07848v1","updated":"2025-07-10T15:27:44Z","published":"2025-07-10T15:27:44Z","title":"\"So, Tell Me About Your Policy...\": Distillation of interpretable\n  policies from Deep Reinforcement Learning agents","summary":"  Recent advances in Reinforcement Learning (RL) largely benefit from the\ninclusion of Deep Neural Networks, boosting the number of novel approaches\nproposed in the field of Deep Reinforcement Learning (DRL). These techniques\ndemonstrate the ability to tackle complex games such as Atari, Go, and other\nreal-world applications, including financial trading. Nevertheless, a\nsignificant challenge emerges from the lack of interpretability, particularly\nwhen attempting to comprehend the underlying patterns learned, the relative\nimportance of the state features, and how they are integrated to generate the\npolicy's output. For this reason, in mission-critical and real-world settings,\nit is often preferred to deploy a simpler and more interpretable algorithm,\nalthough at the cost of performance. In this paper, we propose a novel\nalgorithm, supported by theoretical guarantees, that can extract an\ninterpretable policy (e.g., a linear policy) without disregarding the\npeculiarities of expert behavior. This result is obtained by considering the\nadvantage function, which includes information about why an action is superior\nto the others. In contrast to previous works, our approach enables the training\nof an interpretable policy using previously collected experience. The proposed\nalgorithm is empirically evaluated on classic control environments and on a\nfinancial trading scenario, demonstrating its ability to extract meaningful\ninformation from complex expert policies.\n","authors":["Giovanni Dispoto","Paolo Bonetti","Marcello Restelli"],"pdf_url":"https://arxiv.org/pdf/2507.07848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02357v2","updated":"2025-07-10T15:10:23Z","published":"2025-06-03T01:16:34Z","title":"Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A\n  Lightweight Benchmark for Probing Foundational Controllability Components","summary":"  Credible safety plans for advanced AI development require methods to verify\nagent behavior and detect potential control deficiencies early. A fundamental\naspect is ensuring agents adhere to safety-critical principles, especially when\nthese conflict with operational goals. This paper introduces a lightweight,\ninterpretable benchmark to evaluate an LLM agent's ability to uphold a\nhigh-level safety principle when faced with conflicting task instructions. Our\nevaluation of six LLMs reveals two primary findings: (1) a quantifiable \"cost\nof compliance\" where safety constraints degrade task performance even when\ncompliant solutions exist, and (2) an \"illusion of compliance\" where high\nadherence often masks task incompetence rather than principled choice. These\nfindings provide initial evidence that while LLMs can be influenced by\nhierarchical directives, current approaches lack the consistency required for\nreliable safety governance.\n","authors":["Ram Potham"],"pdf_url":"https://arxiv.org/pdf/2506.02357v2.pdf","comment":"Preprint. This work has been submitted to the Technical AI Governance\n  Workshop at ICML 2025 for review"},{"id":"http://arxiv.org/abs/2406.15245v2","updated":"2025-07-10T15:03:28Z","published":"2024-06-21T15:35:49Z","title":"Unsupervised Morphological Tree Tokenizer","summary":"  As a cornerstone in language modeling, tokenization involves segmenting text\ninputs into pre-defined atomic units. Conventional statistical tokenizers often\ndisrupt constituent boundaries within words, thereby corrupting semantic\ninformation. To address this drawback, we introduce morphological structure\nguidance to tokenization and propose a deep model to induce character-level\nstructures of words. Specifically, the deep model jointly encodes internal\nstructures and representations of words with a mechanism named\n$\\textit{MorphOverriding}$ to ensure the indecomposability of morphemes. By\ntraining the model with self-supervised objectives, our method is capable of\ninducing character-level structures that align with morphological rules without\nannotated training data. Based on the induced structures, our algorithm\ntokenizes words through vocabulary matching in a top-down manner. Empirical\nresults indicate that the proposed method effectively retains complete\nmorphemes and outperforms widely adopted methods such as BPE and WordPiece on\nboth morphological segmentation tasks and language modeling tasks. Code is\navailable at https://github.com/martianmartina/TreeTokenizer.\n","authors":["Qingyang Zhu","Xiang Hu","Pengyu Ji","Wei Wu","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2406.15245v2.pdf","comment":"ACL 2025 Findings"},{"id":"http://arxiv.org/abs/2503.01361v2","updated":"2025-07-10T15:02:15Z","published":"2025-03-03T09:55:10Z","title":"Statistical physics analysis of graph neural networks: Approaching\n  optimality in the contextual stochastic block model","summary":"  Graph neural networks (GNNs) are designed to process data associated with\ngraphs. They are finding an increasing range of applications; however, as with\nother modern machine learning techniques, their theoretical understanding is\nlimited. GNNs can encounter difficulties in gathering information from nodes\nthat are far apart by iterated aggregation steps. This situation is partly\ncaused by so-called oversmoothing; and overcoming it is one of the practically\nmotivated challenges. We consider the situation where information is aggregated\nby multiple steps of convolution, leading to graph convolutional networks\n(GCNs). We analyze the generalization performance of a basic GCN, trained for\nnode classification on data generated by the contextual stochastic block model.\nWe predict its asymptotic performance by deriving the free energy of the\nproblem, using the replica method, in the high-dimensional limit. Calling depth\nthe number of convolutional steps, we show the importance of going to large\ndepth to approach the Bayes-optimality. We detail how the architecture of the\nGCN has to scale with the depth to avoid oversmoothing. The resulting large\ndepth limit can be close to the Bayes-optimality and leads to a continuous GCN.\nTechnically, we tackle this continuous limit via an approach that resembles\ndynamical mean-field theory (DMFT) with constraints at the initial and final\ntimes. An expansion around large regularization allows us to solve the\ncorresponding equations for the performance of the deep GCN. This promising\ntool may contribute to the analysis of further deep neural networks.\n","authors":["O. Duranthon","L. Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2503.01361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07829v1","updated":"2025-07-10T15:01:31Z","published":"2025-07-10T15:01:31Z","title":"Towards Benchmarking Foundation Models for Tabular Data With Text","summary":"  Foundation models for tabular data are rapidly evolving, with increasing\ninterest in extending them to support additional modalities such as free-text\nfeatures. However, existing benchmarks for tabular data rarely include textual\ncolumns, and identifying real-world tabular datasets with semantically rich\ntext features is non-trivial. We propose a series of simple yet effective\nablation-style strategies for incorporating text into conventional tabular\npipelines. Moreover, we benchmark how state-of-the-art tabular foundation\nmodels can handle textual data by manually curating a collection of real-world\ntabular datasets with meaningful textual features. Our study is an important\nstep towards improving benchmarking of foundation models for tabular data with\ntext.\n","authors":["Martin Mráz","Breenda Das","Anshul Gupta","Lennart Purucker","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2507.07829v1.pdf","comment":"Accepted at Foundation Models for Structured Data workshop at ICML\n  2025"},{"id":"http://arxiv.org/abs/2507.07826v1","updated":"2025-07-10T14:58:28Z","published":"2025-07-10T14:58:28Z","title":"An Empirical Bernstein Inequality for Dependent Data in Hilbert Spaces\n  and Applications","summary":"  Learning from non-independent and non-identically distributed data poses a\npersistent challenge in statistical learning. In this study, we introduce\ndata-dependent Bernstein inequalities tailored for vector-valued processes in\nHilbert space. Our inequalities apply to both stationary and non-stationary\nprocesses and exploit the potential rapid decay of correlations between\ntemporally separated variables to improve estimation. We demonstrate the\nutility of these bounds by applying them to covariance operator estimation in\nthe Hilbert-Schmidt norm and to operator learning in dynamical systems,\nachieving novel risk bounds. Finally, we perform numerical experiments to\nillustrate the practical implications of these bounds in both contexts.\n","authors":["Erfan Mirzaei","Andreas Maurer","Vladimir R. Kostic","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2507.07826v1.pdf","comment":"In The 28th International Conference on Artificial Intelligence and\n  Statistics (2025)"},{"id":"http://arxiv.org/abs/2310.02299v8","updated":"2025-07-10T14:55:09Z","published":"2023-10-03T14:03:21Z","title":"Discovering Symmetry Breaking in Physical Systems with Relaxed Group\n  Convolution","summary":"  Modeling symmetry breaking is essential for understanding the fundamental\nchanges in the behaviors and properties of physical systems, from microscopic\nparticle interactions to macroscopic phenomena like fluid dynamics and cosmic\nstructures. Thus, identifying sources of asymmetry is an important tool for\nunderstanding physical systems. In this paper, we focus on learning asymmetries\nof data using relaxed group convolutions. We provide both theoretical and\nempirical evidence that this flexible convolution technique allows the model to\nmaintain the highest level of equivariance that is consistent with data and\ndiscover the subtle symmetry-breaking factors in various physical systems. We\nemploy various relaxed group convolution architectures to uncover various\nsymmetry-breaking factors that are interpretable and physically meaningful in\ndifferent physical systems, including the phase transition of crystal\nstructure, the isotropy and homogeneity breaking in turbulent flow, and the\ntime-reversal symmetry breaking in pendulum systems.\n","authors":["Rui Wang","Elyssa Hofgard","Han Gao","Robin Walters","Tess E. Smidt"],"pdf_url":"https://arxiv.org/pdf/2310.02299v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03053v2","updated":"2025-07-10T14:54:28Z","published":"2025-06-03T16:33:47Z","title":"MAEBE: Multi-Agent Emergent Behavior Framework","summary":"  Traditional AI safety evaluations on isolated LLMs are insufficient as\nmulti-agent AI ensembles become prevalent, introducing novel emergent risks.\nThis paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE)\nframework to systematically assess such risks. Using MAEBE with the Greatest\nGood Benchmark (and a novel double-inversion question technique), we\ndemonstrate that: (1) LLM moral preferences, particularly for Instrumental\nHarm, are surprisingly brittle and shift significantly with question framing,\nboth in single agents and ensembles. (2) The moral reasoning of LLM ensembles\nis not directly predictable from isolated agent behavior due to emergent group\ndynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure\ninfluencing convergence, even when guided by a supervisor, highlighting\ndistinct safety and alignment challenges. Our findings underscore the necessity\nof evaluating AI systems in their interactive, multi-agent contexts.\n","authors":["Sinem Erisken","Timothy Gothard","Martin Leitgab","Ram Potham"],"pdf_url":"https://arxiv.org/pdf/2506.03053v2.pdf","comment":"Preprint. This work has been submitted to the Multi-Agent Systems\n  Workshop at ICML 2025 for review"},{"id":"http://arxiv.org/abs/2010.07990v2","updated":"2025-07-10T14:51:52Z","published":"2020-10-15T19:17:51Z","title":"An Algorithm for Learning Smaller Representations of Models With Scarce\n  Data","summary":"  We present an algorithm for solving binary classification problems when the\ndataset is not fully representative of the problem being solved, and obtaining\nmore data is not possible. It relies on a trained model with loose accuracy\nconstraints, an iterative hyperparameter searching-and-pruning procedure over a\nsearch space $\\Theta$, and a data-generating function. Our algorithm works by\nreconstructing up to homology the manifold on which lies the support of the\nunderlying distribution. We provide an analysis on correctness and runtime\ncomplexity under ideal conditions and an extension to deep neural networks. In\nthe former case, if $\\size{\\Theta}$ is the number of hyperparameter sets in the\nsearch space, this algorithm returns a solution that is up to $2(1 -\n{2^{-\\size{\\Theta}}})$ times better than simply training with an enumeration of\n$\\Theta$ and picking the best model. As part of our analysis we also prove that\nan open cover of a dataset has the same homology as the manifold on which lies\nthe support of the underlying probability distribution, if and only said\ndataset is learnable. This latter result acts as a formal argument to explain\nthe effectiveness of data expansion techniques.\n","authors":["Adrian de Wynter"],"pdf_url":"https://arxiv.org/pdf/2010.07990v2.pdf","comment":"Accepted to Information Geometry--see the journal for the final,\n  authenticated version"},{"id":"http://arxiv.org/abs/2507.07817v1","updated":"2025-07-10T14:46:33Z","published":"2025-07-10T14:46:33Z","title":"On the Effect of Instruction Tuning Loss on Generalization","summary":"  Instruction Tuning has emerged as a pivotal post-training paradigm that\nenables pre-trained language models to better follow user instructions. Despite\nits significance, little attention has been given to optimizing the loss\nfunction used. A fundamental, yet often overlooked, question is whether the\nconventional auto-regressive objective - where loss is computed only on\nresponse tokens, excluding prompt tokens - is truly optimal for instruction\ntuning. In this work, we systematically investigate the impact of\ndifferentially weighting prompt and response tokens in instruction tuning loss,\nand propose Weighted Instruction Tuning (WIT) as a better alternative to\nconventional instruction tuning. Through extensive experiments on five language\nmodels of different families and scale, three finetuning datasets of different\nsizes, and five diverse evaluation benchmarks, we show that the standard\ninstruction tuning loss often yields suboptimal performance and limited\nrobustness to input prompt variations. We find that a low-to-moderate weight\nfor prompt tokens coupled with a moderate-to-high weight for response tokens\nyields the best-performing models across settings and also serve as better\nstarting points for the subsequent preference alignment training. These\nfindings highlight the need to reconsider instruction tuning loss and offer\nactionable insights for developing more robust and generalizable models. Our\ncode is open-sourced at https://github.com/kowndinya-renduchintala/WIT.\n","authors":["Anwoy Chatterjee","H S V N S Kowndinya Renduchintala","Sumit Bhatia","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2507.07817v1.pdf","comment":"Transactions of the Association for Computational Linguistics (TACL)"},{"id":"http://arxiv.org/abs/2507.07814v1","updated":"2025-07-10T14:45:31Z","published":"2025-07-10T14:45:31Z","title":"Pay Attention to Attention Distribution: A New Local Lipschitz Bound for\n  Transformers","summary":"  We present a novel local Lipschitz bound for self-attention blocks of\ntransformers. This bound is based on a refined closed-form expression for the\nspectral norm of the softmax function. The resulting bound is not only more\naccurate than in the prior art, but also unveils the dependence of the\nLipschitz constant on attention score maps. Based on the new findings, we\nsuggest an explanation of the way distributions inside the attention map affect\nthe robustness from the Lipschitz constant perspective. We also introduce a new\nlightweight regularization term called JaSMin (Jacobian Softmax norm\nMinimization), which boosts the transformer's robustness and decreases local\nLipschitz constants of the whole network.\n","authors":["Nikolay Yudin","Alexander Gaponov","Sergei Kudriashov","Maxim Rakhuba"],"pdf_url":"https://arxiv.org/pdf/2507.07814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.00718v2","updated":"2025-07-10T14:44:44Z","published":"2025-02-02T08:36:23Z","title":"\"I am bad\": Interpreting Stealthy, Universal and Robust Audio Jailbreaks\n  in Audio-Language Models","summary":"  The rise of multimodal large language models has introduced innovative\nhuman-machine interaction paradigms but also significant challenges in machine\nlearning safety. Audio-Language Models (ALMs) are especially relevant due to\nthe intuitive nature of spoken communication, yet little is known about their\nfailure modes. This paper explores audio jailbreaks targeting ALMs, focusing on\ntheir ability to bypass alignment mechanisms. We construct adversarial\nperturbations that generalize across prompts, tasks, and even base audio\nsamples, demonstrating the first universal jailbreaks in the audio modality,\nand show that these remain effective in simulated real-world conditions. Beyond\ndemonstrating attack feasibility, we analyze how ALMs interpret these audio\nadversarial examples and reveal them to encode imperceptible first-person toxic\nspeech - suggesting that the most effective perturbations for eliciting toxic\noutputs specifically embed linguistic features within the audio signal. These\nresults have important implications for understanding the interactions between\ndifferent modalities in multimodal models, and offer actionable insights for\nenhancing defenses against adversarial audio attacks.\n","authors":["Isha Gupta","David Khachaturov","Robert Mullins"],"pdf_url":"https://arxiv.org/pdf/2502.00718v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07804v1","updated":"2025-07-10T14:29:48Z","published":"2025-07-10T14:29:48Z","title":"Deep Survival Analysis in Multimodal Medical Data: A Parametric and\n  Probabilistic Approach with Competing Risks","summary":"  Accurate survival prediction is critical in oncology for prognosis and\ntreatment planning. Traditional approaches often rely on a single data\nmodality, limiting their ability to capture the complexity of tumor biology. To\naddress this challenge, we introduce a multimodal deep learning framework for\nsurvival analysis capable of modeling both single and competing risks\nscenarios, evaluating the impact of integrating multiple medical data sources\non survival predictions. We propose SAMVAE (Survival Analysis Multimodal\nVariational Autoencoder), a novel deep learning architecture designed for\nsurvival prediction that integrates six data modalities: clinical variables,\nfour molecular profiles, and histopathological images. SAMVAE leverages\nmodality specific encoders to project inputs into a shared latent space,\nenabling robust survival prediction while preserving modality specific\ninformation. Its parametric formulation enables the derivation of clinically\nmeaningful statistics from the output distributions, providing patient-specific\ninsights through interactive multimedia that contribute to more informed\nclinical decision-making and establish a foundation for interpretable,\ndata-driven survival analysis in oncology. We evaluate SAMVAE on two cancer\ncohorts breast cancer and lower grade glioma applying tailored preprocessing,\ndimensionality reduction, and hyperparameter optimization. The results\ndemonstrate the successful integration of multimodal data for both standard\nsurvival analysis and competing risks scenarios across different datasets. Our\nmodel achieves competitive performance compared to state-of-the-art multimodal\nsurvival models. Notably, this is the first parametric multimodal deep learning\narchitecture to incorporate competing risks while modeling continuous time to a\nspecific event, using both tabular and image data.\n","authors":["Alba Garrido","Alejandro Almodóvar","Patricia A. Apellániz","Juan Parras","Santiago Zazo"],"pdf_url":"https://arxiv.org/pdf/2507.07804v1.pdf","comment":"29 pages, 9 Figures"},{"id":"http://arxiv.org/abs/2412.00569v2","updated":"2025-07-10T14:21:15Z","published":"2024-11-30T19:45:23Z","title":"Contextual Bandits in Payment Processing: Non-uniform Exploration and\n  Supervised Learning","summary":"  Uniform random exploration in decision-making systems supports off-policy\nlearning via supervision but incurs high regret, making it impractical for many\napplications. Conversely, non-uniform exploration offers better immediate\nperformance but lacks support for off-policy learning. Recent research suggests\nthat regression oracles can bridge this gap by combining non-uniform\nexploration with supervised learning. In this paper, we analyze these\napproaches within a real-world industrial context at Adyen, a large global\npayments processor characterized by batch logged delayed feedback, short-term\nmemory, and dynamic action spaces under the Empirical Risk Minimization (ERM)\nframework. Our analysis reveals that while regression oracles significantly\nimprove performance, they introduce challenges due to rigid algorithmic\nassumptions. Specifically, we observe that as a policy improves, subsequent\ngenerations may perform worse due to shifts in the reward distribution and\nincreased class imbalance in the training data. This degradation occurs de\nspite improvements in other aspects of the training data, leading to decreased\nperformance in successive policy iterations. We further explore the long-term\nimpact of regression oracles, identifying a potential \"oscillation effect.\"\nThis effect arises when regression oracles influence probability estimates and\nthe realizability of subsequent policy models, leading to fluctuations in\nperformance across iterations. Our findings highlight the need for more\nadaptable algorithms that can leverage the benefits of regression oracles\nwithout introducing instability in policy performance over time.\n","authors":["Akhila Vangara","Alex Egg"],"pdf_url":"https://arxiv.org/pdf/2412.00569v2.pdf","comment":"7 pages, 10 figures, submitted to KDD '25"},{"id":"http://arxiv.org/abs/2507.07792v1","updated":"2025-07-10T14:19:29Z","published":"2025-07-10T14:19:29Z","title":"Space-Filling Regularization for Robust and Interpretable Nonlinear\n  State Space Models","summary":"  The state space dynamics representation is the most general approach for\nnonlinear systems and often chosen for system identification. During training,\nthe state trajectory can deform significantly leading to poor data coverage of\nthe state space. This can cause significant issues for space-oriented training\nalgorithms which e.g. rely on grid structures, tree partitioning, or similar.\nBesides hindering training, significant state trajectory deformations also\ndeteriorate interpretability and robustness properties. This paper proposes a\nnew type of space-filling regularization that ensures a favorable data\ndistribution in state space via introducing a data-distribution-based penalty.\nThis method is demonstrated in local model network architectures where good\ninterpretability is a major concern. The proposed approach integrates ideas\nfrom modeling and design of experiments for state space structures. This is why\nwe present two regularization techniques for the data point distributions of\nthe state trajectories for local affine state space models. Beyond that, we\ndemonstrate the results on a widely known system identification benchmark.\n","authors":["Hermann Klein","Max Heinz Herkersdorf","Oliver Nelles"],"pdf_url":"https://arxiv.org/pdf/2507.07792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11984v2","updated":"2025-07-10T14:18:01Z","published":"2024-11-18T19:14:36Z","title":"Understanding Chain-of-Thought in LLMs through Information Theory","summary":"  Large Language Models (LLMs) have shown impressive performance in complex\nreasoning tasks through the use of Chain-of-Thought (CoT) reasoning, allowing\nmodels to break down problems into manageable sub-tasks. However, existing CoT\nevaluation techniques either require annotated CoT data or fall short in\naccurately assessing intermediate reasoning steps, leading to high rates of\nfalse positives. In this paper, we formalize CoT reasoning in LLMs through an\ninformation-theoretic lens. Specifically, our framework quantifies the\n`information-gain' at each reasoning step, enabling the identification of\nfailure modes in LLMs without the need for expensive annotated datasets. We\ndemonstrate the efficacy of our approach through extensive experiments on toy\narithmetic, GSM8K and PRM800k datasets, where it significantly outperforms\nexisting outcome-based methods by providing more accurate insights into model\nperformance on individual subtasks.\n","authors":["Jean-Francois Ton","Muhammad Faaiz Taufiq","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.11984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14111v2","updated":"2025-07-10T14:11:07Z","published":"2023-03-24T16:19:15Z","title":"Unsupervised Automata Learning via Discrete Optimization","summary":"  Automata learning is a successful tool for many application domains such as\nrobotics and automatic verification. Typically, automata learning techniques\noperate in a supervised learning setting (active or passive) where they learn a\nfinite state machine in contexts where additional information, such as labeled\nsystem executions, is available. However, other settings, such as learning from\nunlabeled data - an important aspect in machine learning - remain unexplored.\nTo overcome this limitation, we propose a framework for learning a\ndeterministic finite automaton (DFA) from a given multi-set of unlabeled words.\nWe show that this problem is computationally hard and develop three learning\nalgorithms based on constraint optimization. Moreover, we introduce novel\nregularization schemes for our optimization problems that improve the overall\ninterpretability of our DFAs. Using a prototype implementation, we demonstrate\npractical feasibility in the context of unsupervised anomaly detection.\n","authors":["Simon Lutz","Daniil Kaminskyi","Florian Wittbold","Simon Dierl","Falk Howar","Barbara König","Emmanuel Müller","Daniel Neider"],"pdf_url":"https://arxiv.org/pdf/2303.14111v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15543v2","updated":"2025-07-10T14:01:54Z","published":"2025-06-18T15:17:03Z","title":"Learning Algorithms in the Limit","summary":"  This paper studies the problem of learning computable functions in the limit\nby extending Gold's inductive inference framework to incorporate\n\\textit{computational observations} and \\textit{restricted input sources}.\nComplimentary to the traditional Input-Output Observations, we introduce\nTime-Bound Observations, and Policy-Trajectory Observations to study the\nlearnability of general recursive functions under more realistic constraints.\nWhile input-output observations do not suffice for learning the class of\ngeneral recursive functions in the limit, we overcome this learning barrier by\nimposing computational complexity constraints or supplementing with approximate\ntime-bound observations. Further, we build a formal framework around\nobservations of \\textit{computational agents} and show that learning computable\nfunctions from policy trajectories reduces to learning rational functions from\ninput and output, thereby revealing interesting connections to finite-state\ntransducer inference. On the negative side, we show that computable or\npolynomial-mass characteristic sets cannot exist for the class of linear-time\ncomputable functions even for policy-trajectory observations.\n","authors":["Hristo Papazov","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2506.15543v2.pdf","comment":"Accepted at COLT 2025. This version matches the proceedings version\n  apart from a small notational change in section 3"},{"id":"http://arxiv.org/abs/2507.07779v1","updated":"2025-07-10T13:58:55Z","published":"2025-07-10T13:58:55Z","title":"Approximation Depth of Convex Polytopes","summary":"  We study approximations of polytopes in the standard model for computing\npolytopes using Minkowski sums and (convex hulls of) unions. Specifically, we\nstudy the ability to approximate a target polytope by polytopes of a given\ndepth. Our main results imply that simplices can only be ``trivially\napproximated''. On the way, we obtain a characterization of simplices as the\nonly ``outer additive'' convex bodies.\n","authors":["Egor Bakaev","Florestan Brunck","Amir Yehudayoff"],"pdf_url":"https://arxiv.org/pdf/2507.07779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07778v1","updated":"2025-07-10T13:58:32Z","published":"2025-07-10T13:58:32Z","title":"Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time\n  Training","summary":"  Generalizing neural networks to unseen target domains is a significant\nchallenge in real-world deployments. Test-time training (TTT) addresses this by\nusing an auxiliary self-supervised task to reduce the domain gap caused by\ndistribution shifts between the source and target. However, we find that when\nmodels are required to perform multiple tasks under domain shifts, conventional\nTTT methods suffer from unsynchronized task behavior, where the adaptation\nsteps needed for optimal performance in one task may not align with the\nrequirements of other tasks. To address this, we propose a novel TTT approach\ncalled Synchronizing Tasks for Test-time Training (S4T), which enables the\nconcurrent handling of multiple tasks. The core idea behind S4T is that\npredicting task relations across domain shifts is key to synchronizing tasks\nduring test time. To validate our approach, we apply S4T to conventional\nmulti-task benchmarks, integrating it with traditional TTT protocols. Our\nempirical results show that S4T outperforms state-of-the-art TTT methods across\nvarious benchmarks.\n","authors":["Wooseong Jeong","Jegyeong Cho","Youngho Yoon","Kuk-Jin Yoon"],"pdf_url":"https://arxiv.org/pdf/2507.07778v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2503.02113v2","updated":"2025-07-10T13:56:52Z","published":"2025-03-03T22:56:04Z","title":"Deep Learning is Not So Mysterious or Different","summary":"  Deep neural networks are often seen as different from other model classes by\ndefying conventional notions of generalization. Popular examples of anomalous\ngeneralization behaviour include benign overfitting, double descent, and the\nsuccess of overparametrization. We argue that these phenomena are not distinct\nto neural networks, or particularly mysterious. Moreover, this generalization\nbehaviour can be intuitively understood, and rigorously characterized, using\nlong-standing generalization frameworks such as PAC-Bayes and countable\nhypothesis bounds. We present soft inductive biases as a key unifying principle\nin explaining these phenomena: rather than restricting the hypothesis space to\navoid overfitting, embrace a flexible hypothesis space, with a soft preference\nfor simpler solutions that are consistent with the data. This principle can be\nencoded in many model classes, and thus deep learning is not as mysterious or\ndifferent from other model classes as it might seem. However, we also highlight\nhow deep learning is relatively distinct in other ways, such as its ability for\nrepresentation learning, phenomena such as mode connectivity, and its relative\nuniversality.\n","authors":["Andrew Gordon Wilson"],"pdf_url":"https://arxiv.org/pdf/2503.02113v2.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2507.07771v1","updated":"2025-07-10T13:54:59Z","published":"2025-07-10T13:54:59Z","title":"A Unified Empirical Risk Minimization Framework for Flexible N-Tuples\n  Weak Supervision","summary":"  To alleviate the annotation burden in supervised learning, N-tuples learning\nhas recently emerged as a powerful weakly-supervised method. While existing\nN-tuples learning approaches extend pairwise learning to higher-order\ncomparisons and accommodate various real-world scenarios, they often rely on\ntask-specific designs and lack a unified theoretical foundation. In this paper,\nwe propose a general N-tuples learning framework based on empirical risk\nminimization, which systematically integrates pointwise unlabeled data to\nenhance learning performance. This paper first unifies the data generation\nprocesses of N-tuples and pointwise unlabeled data under a shared probabilistic\nformulation. Based on this unified view, we derive an unbiased empirical risk\nestimator that generalizes a broad class of existing N-tuples models. We\nfurther establish a generalization error bound for theoretical support. To\ndemonstrate the flexibility of the framework, we instantiate it in four\nrepresentative weakly supervised scenarios, each recoverable as a special case\nof our general model. Additionally, to address overfitting issues arising from\nnegative risk terms, we adopt correction functions to adjust the empirical\nrisk. Extensive experiments on benchmark datasets validate the effectiveness of\nthe proposed framework and demonstrate that leveraging pointwise unlabeled data\nconsistently improves generalization across various N-tuples learning tasks.\n","authors":["Shuying Huang","Junpeng Li","Changchun Hua","Yana Yang"],"pdf_url":"https://arxiv.org/pdf/2507.07771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07769v1","updated":"2025-07-10T13:54:38Z","published":"2025-07-10T13:54:38Z","title":"BEAVER: Building Environments with Assessable Variation for Evaluating\n  Multi-Objective Reinforcement Learning","summary":"  Recent years have seen significant advancements in designing reinforcement\nlearning (RL)-based agents for building energy management. While individual\nsuccess is observed in simulated or controlled environments, the scalability of\nRL approaches in terms of efficiency and generalization across building\ndynamics and operational scenarios remains an open question. In this work, we\nformally characterize the generalization space for the cross-environment,\nmulti-objective building energy management task, and formulate the\nmulti-objective contextual RL problem. Such a formulation helps understand the\nchallenges of transferring learned policies across varied operational contexts\nsuch as climate and heat convection dynamics under multiple control objectives\nsuch as comfort level and energy consumption. We provide a principled way to\nparameterize such contextual information in realistic building RL environments,\nand construct a novel benchmark to facilitate the evaluation of generalizable\nRL algorithms in practical building control tasks. Our results show that\nexisting multi-objective RL methods are capable of achieving reasonable\ntrade-offs between conflicting objectives. However, their performance degrades\nunder certain environment variations, underscoring the importance of\nincorporating dynamics-dependent contextual information into the policy\nlearning process.\n","authors":["Ruohong Liu","Jack Umenberger","Yize Chen"],"pdf_url":"https://arxiv.org/pdf/2507.07769v1.pdf","comment":"Accepted at the Workshop on Computational Optimization of Buildings\n  (ICML CO-BUILD), 42nd International Conference on Machine Learning (ICML\n  2025), Vancouver, Canada"},{"id":"http://arxiv.org/abs/2507.07768v1","updated":"2025-07-10T13:53:52Z","published":"2025-07-10T13:53:52Z","title":"TRIX- Trading Adversarial Fairness via Mixed Adversarial Training","summary":"  Adversarial Training (AT) is a widely adopted defense against adversarial\nexamples. However, existing approaches typically apply a uniform training\nobjective across all classes, overlooking disparities in class-wise\nvulnerability. This results in adversarial unfairness: classes with well\ndistinguishable features (strong classes) tend to become more robust, while\nclasses with overlapping or shared features(weak classes) remain\ndisproportionately susceptible to adversarial attacks. We observe that strong\nclasses do not require strong adversaries during training, as their non-robust\nfeatures are quickly suppressed. In contrast, weak classes benefit from\nstronger adversaries to effectively reduce their vulnerabilities. Motivated by\nthis, we introduce TRIX, a feature-aware adversarial training framework that\nadaptively assigns weaker targeted adversaries to strong classes, promoting\nfeature diversity via uniformly sampled targets, and stronger untargeted\nadversaries to weak classes, enhancing their focused robustness. TRIX further\nincorporates per-class loss weighting and perturbation strength adjustments,\nbuilding on prior work, to emphasize weak classes during the optimization.\nComprehensive experiments on standard image classification benchmarks,\nincluding evaluations under strong attacks such as PGD and AutoAttack,\ndemonstrate that TRIX significantly improves worst-case class accuracy on both\nclean and adversarial data, reducing inter-class robustness disparities, and\npreserves overall accuracy. Our results highlight TRIX as a practical step\ntoward fair and effective adversarial defense.\n","authors":["Tejaswini Medi","Steffen Jung","Margret Keuper"],"pdf_url":"https://arxiv.org/pdf/2507.07768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07765v1","updated":"2025-07-10T13:43:15Z","published":"2025-07-10T13:43:15Z","title":"Distributed and Decentralised Training: Technical Governance Challenges\n  in a Shifting AI Landscape","summary":"  Advances in low-communication training algorithms are enabling a shift from\ncentralised model training to compute setups that are either distributed across\nmultiple clusters or decentralised via community-driven contributions. This\npaper distinguishes these two scenarios - distributed and decentralised\ntraining - which are little understood and often conflated in policy discourse.\nWe discuss how they could impact technical AI governance through an increased\nrisk of compute structuring, capability proliferation, and the erosion of\ndetectability and shutdownability. While these trends foreshadow a possible new\nparadigm that could challenge key assumptions of compute governance, we\nemphasise that certain policy levers, like export controls, remain relevant. We\nalso acknowledge potential benefits of decentralised AI, including\nprivacy-preserving training runs that could unlock access to more data, and\nmitigating harmful power concentration. Our goal is to support more precise\npolicymaking around compute, capability proliferation, and decentralised AI\ndevelopment.\n","authors":["Jakub Kryś","Yashvardhan Sharma","Janet Egan"],"pdf_url":"https://arxiv.org/pdf/2507.07765v1.pdf","comment":"Accepted as an oral presentation at the Technical AI Governance\n  Workshop (ICML 2025)"},{"id":"http://arxiv.org/abs/2507.06892v2","updated":"2025-07-10T13:42:04Z","published":"2025-07-09T14:29:45Z","title":"Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning\n  for Large Language Model","summary":"  Reinforcement Learning (RL) has demonstrated its potential to improve the\nreasoning ability of Large Language Models (LLMs). One major limitation of most\nexisting Reinforcement Finetuning (RFT) methods is that they are on-policy RL\nin nature, i.e., data generated during the past learning process is not fully\nutilized. This inevitably comes at a significant cost of compute and time,\nposing a stringent bottleneck on continuing economic and efficient scaling. To\nthis end, we launch the renaissance of off-policy RL and propose Reincarnating\nMix-policy Proximal Policy Gradient (ReMix), a general approach to enable\non-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix\nconsists of three major components: (1) Mix-policy proximal policy gradient\nwith an increased Update-To-Data (UTD) ratio for efficient training; (2)\nKL-Convex policy constraint to balance the trade-off between stability and\nflexibility; (3) Policy reincarnation to achieve a seamless transition from\nefficient early-stage learning to steady asymptotic improvement. In our\nexperiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base\nmodels. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with\n0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B\nmodel) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math\nreasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and\nMATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level\nperformance with an over 30x to 450x reduction in training cost in terms of\nrollout data volume. In addition, we reveal insightful findings via\nmultifaceted analysis, including the implicit preference for shorter responses\ndue to the Whipping Effect of off-policy discrepancy, the collapse mode of\nself-reflection behavior under the presence of severe off-policyness, etc.\n","authors":["Jing Liang","Hongyao Tang","Yi Ma","Jinyi Liu","Yan Zheng","Shuyue Hu","Lei Bai","Jianye Hao"],"pdf_url":"https://arxiv.org/pdf/2507.06892v2.pdf","comment":"Preliminary version, v2, added more details and corrected some minor\n  mistakes. Project page: https://anitaleungxx.github.io/ReMix"},{"id":"http://arxiv.org/abs/2507.07754v1","updated":"2025-07-10T13:34:02Z","published":"2025-07-10T13:34:02Z","title":"OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting","summary":"  Machine unlearning seeks to remove the influence of particular data or class\nfrom trained models to meet privacy, legal, or ethical requirements. Existing\nunlearning methods tend to forget shallowly: phenomenon of an unlearned model\npretend to forget by adjusting only the model response, while its internal\nrepresentations retain information sufficiently to restore the forgotten data\nor behavior. We empirically confirm the widespread shallowness by reverting the\nforgetting effect of various unlearning methods via training-free performance\nrecovery attack and gradient-inversion-based data reconstruction attack. To\naddress this vulnerability fundamentally, we define a theoretical criterion of\n``deep forgetting'' based on one-point-contraction of feature representations\nof data to forget. We also propose an efficient approximation algorithm, and\nuse it to construct a novel general-purpose unlearning algorithm:\nOne-Point-Contraction (OPC). Empirical evaluations on image classification\nunlearning benchmarks show that OPC achieves not only effective unlearning\nperformance but also superior resilience against both performance recovery\nattack and gradient-inversion attack. The distinctive unlearning performance of\nOPC arises from the deep feature forgetting enforced by its theoretical\nfoundation, and recaps the need for improved robustness of machine unlearning\nmethods.\n","authors":["Jaeheun Jung","Bosung Jung","Suhyun Bae","Donghun Lee"],"pdf_url":"https://arxiv.org/pdf/2507.07754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07738v1","updated":"2025-07-10T13:16:33Z","published":"2025-07-10T13:16:33Z","title":"Efficient and Scalable Estimation of Distributional Treatment Effects\n  with Multi-Task Neural Networks","summary":"  We propose a novel multi-task neural network approach for estimating\ndistributional treatment effects (DTE) in randomized experiments. While DTE\nprovides more granular insights into the experiment outcomes over conventional\nmethods focusing on the Average Treatment Effect (ATE), estimating it with\nregression adjustment methods presents significant challenges. Specifically,\nprecision in the distribution tails suffers due to data imbalance, and\ncomputational inefficiencies arise from the need to solve numerous regression\nproblems, particularly in large-scale datasets commonly encountered in\nindustry. To address these limitations, our method leverages multi-task neural\nnetworks to estimate conditional outcome distributions while incorporating\nmonotonic shape constraints and multi-threshold label learning to enhance\naccuracy. To demonstrate the practical effectiveness of our proposed method, we\napply our method to both simulated and real-world datasets, including a\nrandomized field experiment aimed at reducing water consumption in the US and a\nlarge-scale A/B test from a leading streaming platform in Japan. The\nexperimental results consistently demonstrate superior performance across\nvarious datasets, establishing our method as a robust and practical solution\nfor modern causal inference applications requiring a detailed understanding of\ntreatment effect heterogeneity.\n","authors":["Tomu Hirata","Undral Byambadalai","Tatsushi Oka","Shota Yasui","Shingo Uto"],"pdf_url":"https://arxiv.org/pdf/2507.07738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07735v1","updated":"2025-07-10T13:15:20Z","published":"2025-07-10T13:15:20Z","title":"GuardVal: Dynamic Large Language Model Jailbreak Evaluation for\n  Comprehensive Safety Testing","summary":"  Jailbreak attacks reveal critical vulnerabilities in Large Language Models\n(LLMs) by causing them to generate harmful or unethical content. Evaluating\nthese threats is particularly challenging due to the evolving nature of LLMs\nand the sophistication required in effectively probing their vulnerabilities.\nCurrent benchmarks and evaluation methods struggle to fully address these\nchallenges, leaving gaps in the assessment of LLM vulnerabilities. In this\npaper, we review existing jailbreak evaluation practices and identify three\nassumed desiderata for an effective jailbreak evaluation protocol. To address\nthese challenges, we introduce GuardVal, a new evaluation protocol that\ndynamically generates and refines jailbreak prompts based on the defender LLM's\nstate, providing a more accurate assessment of defender LLMs' capacity to\nhandle safety-critical situations. Moreover, we propose a new optimization\nmethod that prevents stagnation during prompt refinement, ensuring the\ngeneration of increasingly effective jailbreak prompts that expose deeper\nweaknesses in the defender LLMs. We apply this protocol to a diverse set of\nmodels, from Mistral-7b to GPT-4, across 10 safety domains. Our findings\nhighlight distinct behavioral patterns among the models, offering a\ncomprehensive view of their robustness. Furthermore, our evaluation process\ndeepens the understanding of LLM behavior, leading to insights that can inform\nfuture research and drive the development of more secure models.\n","authors":["Peiyan Zhang","Haibo Jin","Liying Kang","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2507.07735v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2504.19955v2","updated":"2025-07-10T13:00:17Z","published":"2025-04-28T16:24:54Z","title":"Robust Federated Personalised Mean Estimation for the Gaussian Mixture\n  Model","summary":"  Federated learning with heterogeneous data and personalization has received\nsignificant recent attention. Separately, robustness to corrupted data in the\ncontext of federated learning has also been studied. In this paper we explore\ncombining personalization for heterogeneous data with robustness, where a\nconstant fraction of the clients are corrupted. Motivated by this broad\nproblem, we formulate a simple instantiation which captures some of its\ndifficulty. We focus on the specific problem of personalized mean estimation\nwhere the data is drawn from a Gaussian mixture model. We give an algorithm\nwhose error depends almost linearly on the ratio of corrupted to uncorrupted\nsamples, and show a lower bound with the same behavior, albeit with a gap of a\nconstant factor.\n","authors":["Malhar A. Managoli","Vinod M. Prabhakaran","Suhas Diggavi"],"pdf_url":"https://arxiv.org/pdf/2504.19955v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.17836v6","updated":"2025-07-10T12:56:43Z","published":"2025-05-23T12:51:03Z","title":"Robust Distributed Estimation: Extending Gossip Algorithms to Ranking\n  and Trimmed Means","summary":"  This paper addresses the problem of robust estimation in gossip algorithms\nover arbitrary communication graphs. Gossip algorithms are fully decentralized,\nrelying only on local neighbor-to-neighbor communication, making them\nwell-suited for situations where communication is constrained. A fundamental\nchallenge in existing mean-based gossip algorithms is their vulnerability to\nmalicious or corrupted nodes. In this paper, we show that an outlier-robust\nmean can be computed by globally estimating a robust statistic. More\nspecifically, we propose a novel gossip algorithm for rank estimation, referred\nto as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated\nto trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed\ndescription of the proposed methods, a key contribution of our work is a\nprecise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank\nestimation and an $\\mathcal{O}(1 / {t})$ rate for trimmed mean estimation,\nwhere by $t$ is meant the number of iterations. Moreover, we provide a\nbreakdown point analysis of \\textsc{GoTrim}. We empirically validate our\ntheoretical results through experiments on diverse network topologies, data\ndistributions and contamination schemes.\n","authors":["Anna Van Elst","Igor Colin","Stephan Clémençon"],"pdf_url":"https://arxiv.org/pdf/2505.17836v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.04382v2","updated":"2025-07-10T12:54:15Z","published":"2025-05-07T13:04:29Z","title":"Discrete Optimal Transport and Voice Conversion","summary":"  In this work, we address the voice conversion (VC) task using a vector-based\ninterface. To align audio embeddings between speakers, we employ discrete\noptimal transport mapping. Our evaluation results demonstrate the high quality\nand effectiveness of this method. Additionally, we show that applying discrete\noptimal transport as a post-processing step in audio generation can lead to the\nincorrect classification of synthetic audio as real.\n","authors":["Anton Selitskiy","Maitreya Kocharekar"],"pdf_url":"https://arxiv.org/pdf/2505.04382v2.pdf","comment":"4 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2507.07714v1","updated":"2025-07-10T12:52:19Z","published":"2025-07-10T12:52:19Z","title":"Adaptive Gaussian Mixture Models-based Anomaly Detection for\n  under-constrained Cable-Driven Parallel Robots","summary":"  Cable-Driven Parallel Robots (CDPRs) are increasingly used for load\nmanipulation tasks involving predefined toolpaths with intermediate stops. At\neach stop, where the platform maintains a fixed pose and the motors keep the\ncables under tension, the system must evaluate whether it is safe to proceed by\ndetecting anomalies that could compromise performance (e.g., wind gusts or\ncable impacts). This paper investigates whether anomalies can be detected using\nonly motor torque data, without additional sensors. It introduces an adaptive,\nunsupervised outlier detection algorithm based on Gaussian Mixture Models\n(GMMs) to identify anomalies from torque signals. The method starts with a\nbrief calibration period, just a few seconds, during which a GMM is fit on\nknown anomaly-free data. Real-time torque measurements are then evaluated using\nMahalanobis distance from the GMM, with statistically derived thresholds\ntriggering anomaly flags. Model parameters are periodically updated using the\nlatest segments identified as anomaly-free to adapt to changing conditions.\nValidation includes 14 long-duration test sessions simulating varied wind\nintensities. The proposed method achieves a 100% true positive rate and 95.4%\naverage true negative rate, with 1-second detection latency. Comparative\nevaluation against power threshold and non-adaptive GMM methods indicates\nhigher robustness to drift and environmental variation.\n","authors":["Julio Garrido","Javier Vales","Diego Silva-Muñiz","Enrique Riveiro","Pablo López-Matencio","Josué Rivera-Andrade"],"pdf_url":"https://arxiv.org/pdf/2507.07714v1.pdf","comment":"14 pages, 8 figures, 1 table, to be submitted to Advanced Intelligent\n  Systems"},{"id":"http://arxiv.org/abs/2507.07712v1","updated":"2025-07-10T12:46:31Z","published":"2025-07-10T12:46:31Z","title":"Balancing the Past and Present: A Coordinated Replay Framework for\n  Federated Class-Incremental Learning","summary":"  Federated Class Incremental Learning (FCIL) aims to collaboratively process\ncontinuously increasing incoming tasks across multiple clients. Among various\napproaches, data replay has become a promising solution, which can alleviate\nforgetting by reintroducing representative samples from previous tasks.\nHowever, their performance is typically limited by class imbalance, both within\nthe replay buffer due to limited global awareness and between replayed and\nnewly arrived classes. To address this issue, we propose a class wise balancing\ndata replay method for FCIL (FedCBDR), which employs a global coordination\nmechanism for class-level memory construction and reweights the learning\nobjective to alleviate the aforementioned imbalances. Specifically, FedCBDR has\ntwo key components: 1) the global-perspective data replay module reconstructs\nglobal representations of prior task in a privacy-preserving manner, which then\nguides a class-aware and importance-sensitive sampling strategy to achieve\nbalanced replay; 2) Subsequently, to handle class imbalance across tasks, the\ntask aware temperature scaling module adaptively adjusts the temperature of\nlogits at both class and instance levels based on task dynamics, which reduces\nthe model's overconfidence in majority classes while enhancing its sensitivity\nto minority classes. Experimental results verified that FedCBDR achieves\nbalanced class-wise sampling under heterogeneous data distributions and\nimproves generalization under task imbalance between earlier and recent tasks,\nyielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.\n","authors":["Zhuang Qi","Lei Meng","Han Yu"],"pdf_url":"https://arxiv.org/pdf/2507.07712v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01991v4","updated":"2025-07-10T12:18:34Z","published":"2023-12-04T16:10:34Z","title":"Shapley-Based Data Valuation with Mutual Information: A Key to Modified\n  K-Nearest Neighbors","summary":"  The K-Nearest Neighbors (KNN) algorithm is widely used for classification and\nregression; however, it suffers from limitations, including the equal treatment\nof all samples. We propose Information-Modified KNN (IM-KNN), a novel approach\nthat leverages Mutual Information ($I$) and Shapley values to assign weighted\nvalues to neighbors, thereby bridging the gap in treating all samples with the\nsame value and weight. On average, IM-KNN improves the accuracy, precision, and\nrecall of traditional KNN by 16.80%, 17.08%, and 16.98%, respectively, across\n12 benchmark datasets. Experiments on four large-scale datasets further\nhighlight IM-KNN's robustness to noise, imbalanced data, and skewed\ndistributions.\n","authors":["Mohammad Ali Vahedifar","Azim Akhtarshenas","Mohammad Mohammadi Rafatpanah","Maryam Sabbaghian"],"pdf_url":"https://arxiv.org/pdf/2312.01991v4.pdf","comment":"This paper has been accepted for publication in the IEEE Machine\n  Learning and Signal Processing conference (MLSP 2025)"},{"id":"http://arxiv.org/abs/2507.07685v1","updated":"2025-07-10T12:07:13Z","published":"2025-07-10T12:07:13Z","title":"Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought","summary":"  Large vision-language models (LVLMs) have demonstrated remarkable\ncapabilities by integrating pre-trained vision encoders with large language\nmodels (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting\nhas been adapted for LVLMs to enhance multi-modal reasoning by generating\nintermediate rationales based on visual and textual inputs. While CoT is\nassumed to improve grounding and accuracy in LVLMs, our experiments reveal a\nkey challenge: existing LVLMs often ignore the contents of generated rationales\nin CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as\na KL-constrained reward maximization focused on rationale-conditional\nlog-likelihood. As the optimal solution, we propose rationale-enhanced decoding\n(RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes\nvisual and rationale information by multiplying distinct image-conditional and\nrationale-conditional next token distributions. Extensive experiments show that\nRED consistently and significantly improves reasoning over standard CoT and\nother decoding methods across multiple benchmarks and LVLMs. Our work offers a\npractical and effective approach to improve both the faithfulness and accuracy\nof CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded\nmulti-modal systems.\n","authors":["Shin'ya Yamaguchi","Kosuke Nishida","Daiki Chijiwa"],"pdf_url":"https://arxiv.org/pdf/2507.07685v1.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.07683v1","updated":"2025-07-10T12:05:33Z","published":"2025-07-10T12:05:33Z","title":"Accelerating Transposed Convolutions on FPGA-based Edge Devices","summary":"  Transposed Convolutions (TCONV) enable the up-scaling mechanism within\ngenerative Artificial Intelligence (AI) models. However, the predominant\nInput-Oriented Mapping (IOM) method for implementing TCONV has complex output\nmapping, overlapping sums, and ineffectual computations. These inefficiencies\nfurther exacerbate the performance bottleneck of TCONV and generative models on\nresource-constrained edge devices. To address this problem, in this paper we\npropose MM2IM, a hardware-software co-designed accelerator that combines Matrix\nMultiplication (MatMul) with col2IM to process TCONV layers on\nresource-constrained edge devices efficiently. Using the SECDA-TFLite design\ntoolkit, we implement MM2IM and evaluate its performance across 261 TCONV\nproblem configurations, achieving an average speedup of 1.9x against a\ndual-thread ARM Neon optimized CPU baseline. We then evaluate the performance\nof MM2IM on a range of TCONV layers from well-known generative models achieving\nup to 4.2x speedup, and compare it against similar resource-constrained TCONV\naccelerators, outperforming them by at least 2x GOPs/DSP. Finally, we evaluate\nMM2IM on the DCGAN and pix2pix GAN models, achieving up to 3x speedup and 2.4x\nenergy reduction against the CPU baseline.\n","authors":["Jude Haris","José Cano"],"pdf_url":"https://arxiv.org/pdf/2507.07683v1.pdf","comment":"Accepted to 35th International Conference on Field-Programmable Logic\n  and Applications (FPL) 2025"},{"id":"http://arxiv.org/abs/2504.17568v2","updated":"2025-07-10T11:58:59Z","published":"2025-04-24T13:58:07Z","title":"Beyond Cox Models: Assessing the Performance of Machine-Learning Methods\n  in Non-Proportional Hazards and Non-Linear Survival Analysis","summary":"  Survival analysis often relies on Cox models, assuming both linearity and\nproportional hazards (PH). This study evaluates machine and deep learning\nmethods that relax these constraints, comparing their performance with\npenalized Cox models on a benchmark of three synthetic and three real datasets.\nIn total, eight different models were tested, including six non-linear models\nof which four were also non-PH. Although Cox regression often yielded\nsatisfactory performance, we showed the conditions under which machine and deep\nlearning models can perform better. Indeed, the performance of these methods\nhas often been underestimated due to the improper use of Harrell's concordance\nindex (C-index) instead of more appropriate scores such as Antolini's\nconcordance index, which generalizes C-index in cases where the PH assumption\ndoes not hold. In addition, since occasionally high C-index models happen to be\nbadly calibrated, combining Antolini's C-index with Brier's score is useful to\nassess the overall performance of a survival method. Results on our benchmark\ndata showed that survival prediction should be approached by testing different\nmethods to select the most appropriate one according to sample size,\nnon-linearity and non-PH conditions. To allow an easy reproducibility of these\ntests on our benchmark data, code and documentation are freely available at\nhttps://github.com/compbiomed-unito/survhive.\n","authors":["Ivan Rossi","Flavio Sartori","Cesare Rollo","Giovanni Birolo","Piero Fariselli","Tiziana Sanavia"],"pdf_url":"https://arxiv.org/pdf/2504.17568v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.13431v4","updated":"2025-07-10T11:57:06Z","published":"2023-04-26T10:36:40Z","title":"Implicit Counterfactual Data Augmentation for Robust Learning","summary":"  Machine learning models are prone to capturing the spurious correlations\nbetween non-causal attributes and classes, with counterfactual data\naugmentation being a promising direction for breaking these spurious\nassociations. However, generating counterfactual data explicitly poses a\nchallenge, and incorporating augmented data into the training process decreases\ntraining efficiency. This study proposes an Implicit Counterfactual Data\nAugmentation (ICDA) method to remove spurious correlations and make stable\npredictions. Specifically, first, a novel sample-wise augmentation strategy is\ndeveloped that generates semantically and counterfactually meaningful deep\nfeatures with distinct augmentation strength for each sample. Second, we derive\nan easy-to-compute surrogate loss on the augmented feature set when the number\nof augmented samples becomes infinite. Third, two concrete schemes are\nproposed, including direct quantification and meta-learning, to derive the key\nparameters for the robust loss. In addition, ICDA is explained from a\nregularization perspective, revealing its capacity to improve intra-class\ncompactness and augment margins at both class and sample levels. Extensive\nexperiments have been conducted across various biased learning scenarios\ncovering both image and text datasets, demonstrating that ICDA consistently\nenhances the generalization and robustness performance of popular networks.\n","authors":["Xiaoling Zhou","Ou Wu","Michael K. Ng"],"pdf_url":"https://arxiv.org/pdf/2304.13431v4.pdf","comment":"33 pages, 10 figures"},{"id":"http://arxiv.org/abs/2507.07675v1","updated":"2025-07-10T11:54:18Z","published":"2025-07-10T11:54:18Z","title":"Some Theoretical Results on Layerwise Effective Dimension Oscillations\n  in Finite Width ReLU Networks","summary":"  We analyze the layerwise effective dimension (rank of the feature matrix) in\nfully-connected ReLU networks of finite width. Specifically, for a fixed batch\nof $m$ inputs and random Gaussian weights, we derive closed-form expressions\nfor the expected rank of the \\$m\\times n\\$ hidden activation matrices. Our main\nresult shows that $\\mathbb{E}[EDim(\\ell)]=m[1-(1-2/\\pi)^\\ell]+O(e^{-c m})$ so\nthat the rank deficit decays geometrically with ratio $1-2 / \\pi \\approx\n0.3634$. We also prove a sub-Gaussian concentration bound, and identify the\n\"revival\" depths at which the expected rank attains local maxima. In\nparticular, these peaks occur at depths\n$\\ell_k^*\\approx(k+1/2)\\pi/\\log(1/\\rho)$ with height $\\approx (1-e^{-\\pi/2}) m\n\\approx 0.79m$. We further show that this oscillatory rank behavior is a\nfinite-width phenomenon: under orthogonal weight initialization or strong\nnegative-slope leaky-ReLU, the rank remains (nearly) full. These results\nprovide a precise characterization of how random ReLU layers alternately\ncollapse and partially revive the subspace of input variations, adding nuance\nto prior work on expressivity of deep networks.\n","authors":["Darshan Makwana"],"pdf_url":"https://arxiv.org/pdf/2507.07675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07668v1","updated":"2025-07-10T11:49:17Z","published":"2025-07-10T11:49:17Z","title":"Learning Pole Structures of Hadronic States using Predictive Uncertainty\n  Estimation","summary":"  Matching theoretical predictions to experimental data remains a central\nchallenge in hadron spectroscopy. In particular, the identification of new\nhadronic states is difficult, as exotic signals near threshold can arise from a\nvariety of physical mechanisms. A key diagnostic in this context is the pole\nstructure of the scattering amplitude, but different configurations can produce\nsimilar signatures. The mapping between pole configurations and line shapes is\nespecially ambiguous near the mass threshold, where analytic control is\nlimited. In this work, we introduce an uncertainty-aware machine learning\napproach for classifying pole structures in $S$-matrix elements. Our method is\nbased on an ensemble of classifier chains that provide both epistemic and\naleatoric uncertainty estimates. We apply a rejection criterion based on\npredictive uncertainty, achieving a validation accuracy of nearly $95\\%$ while\ndiscarding only a small fraction of high-uncertainty predictions. Trained on\nsynthetic data with known pole structures, the model generalizes to previously\nunseen experimental data, including enhancements associated with the\n$P_{c\\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole\nstructure, representing the presence of a genuine compact pentaquark in the\npresence of a higher channel virtual state pole with non-vanishing width. While\nevaluated on this particular state, our framework is broadly applicable to\nother candidate hadronic states and offers a scalable tool for pole structure\ninference in scattering amplitudes.\n","authors":["Felix Frohnert","Denny Lane B. Sombrillo","Evert van Nieuwenburg","Patrick Emonts"],"pdf_url":"https://arxiv.org/pdf/2507.07668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17428v3","updated":"2025-07-10T11:21:38Z","published":"2024-10-22T20:57:10Z","title":"Uncovering RL Integration in SSL Loss: Objective-Specific Implications\n  for Data-Efficient RL","summary":"  In this study, we investigate the effect of SSL objective modifications\nwithin the SPR framework, focusing on specific adjustments such as terminal\nstate masking and prioritized replay weighting, which were not explicitly\naddressed in the original design. While these modifications are specific to RL,\nthey are not universally applicable across all RL algorithms. Therefore, we aim\nto assess their impact on performance and explore other SSL objectives that do\nnot accommodate these adjustments like Barlow Twins and VICReg. We evaluate six\nSPR variants on the Atari 100k benchmark, including versions both with and\nwithout these modifications. Additionally, we test the performance of these\nobjectives on the DeepMind Control Suite, where such modifications are absent.\nOur findings reveal that incorporating specific SSL modifications within SPR\nsignificantly enhances performance, and this influence extends to subsequent\nframeworks like SR-SPR and BBF, highlighting the critical importance of SSL\nobjective selection and related adaptations in achieving data efficiency in\nself-predictive reinforcement learning.\n","authors":["Ömer Veysel Çağatan","Barış Akgün"],"pdf_url":"https://arxiv.org/pdf/2410.17428v3.pdf","comment":"RLC 2025, Neurips SSL Workshop 2024"},{"id":"http://arxiv.org/abs/2407.17070v2","updated":"2025-07-10T11:15:07Z","published":"2024-07-24T07:55:49Z","title":"Curriculum Negative Mining For Temporal Networks","summary":"  Temporal networks are effective in capturing the evolving interactions of\nnetworks over time, such as social networks and e-commerce networks. In recent\nyears, researchers have primarily concentrated on developing specific model\narchitectures for Temporal Graph Neural Networks (TGNNs) in order to improve\nthe representation quality of temporal nodes and edges. However, limited\nattention has been given to the quality of negative samples during the training\nof TGNNs. When compared with static networks, temporal networks present two\nspecific challenges for negative sampling: positive sparsity and positive\nshift. Positive sparsity refers to the presence of a single positive sample\namidst numerous negative samples at each timestamp, while positive shift\nrelates to the variations in positive samples across different timestamps. To\nrobustly address these challenges in training TGNNs, we introduce Curriculum\nNegative Mining (CurNM), a model-aware curriculum learning framework that\nadaptively adjusts the difficulty of negative samples. Within this framework,\nwe first establish a dynamically updated negative pool that balances random,\nhistorical, and hard negatives to address the challenges posed by positive\nsparsity. Secondly, we implement a temporal-aware negative selection module\nthat focuses on learning from the disentangled factors of recently active\nedges, thus accurately capturing shifting preferences. Finally, the selected\nnegatives are combined with annealing random negatives to support stable\ntraining. Extensive experiments on 12 datasets and 3 TGNNs demonstrate that our\nmethod outperforms baseline methods by a significant margin. Additionally,\nthorough ablation studies and parameter sensitivity experiments verify the\nusefulness and robustness of our approach.\n","authors":["Ziyue Chen","Tongya Zheng","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2407.17070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07641v1","updated":"2025-07-10T11:10:16Z","published":"2025-07-10T11:10:16Z","title":"Machine Learning-Assisted Surrogate Modeling with Multi-Objective\n  Optimization and Decision-Making of a Steam Methane Reforming Reactor","summary":"  This study presents an integrated modeling and optimization framework for a\nsteam methane reforming (SMR) reactor, combining a mathematical model,\nartificial neural network (ANN)-based hybrid modeling, advanced multi-objective\noptimization (MOO) and multi-criteria decision-making (MCDM) techniques. A\none-dimensional fixed-bed reactor model accounting for internal mass transfer\nresistance was employed to simulate reactor performance. To reduce the high\ncomputational cost of the mathematical model, a hybrid ANN surrogate was\nconstructed, achieving a 93.8% reduction in average simulation time while\nmaintaining high predictive accuracy. The hybrid model was then embedded into\nthree MOO scenarios using the non-dominated sorting genetic algorithm II\n(NSGA-II) solver: 1) maximizing methane conversion and hydrogen output; 2)\nmaximizing hydrogen output while minimizing carbon dioxide emissions; and 3) a\ncombined three-objective case. The optimal trade-off solutions were further\nranked and selected using two MCDM methods: technique for order of preference\nby similarity to ideal solution (TOPSIS) and simplified preference ranking on\nthe basis of ideal-average distance (sPROBID). Optimal results include a\nmethane conversion of 0.863 with 4.556 mol/s hydrogen output in the first case,\nand 0.988 methane conversion with 3.335 mol/s hydrogen and 0.781 mol/s carbon\ndioxide in the third. This comprehensive methodology offers a scalable and\neffective strategy for optimizing complex catalytic reactor systems with\nmultiple, often conflicting, objectives.\n","authors":["Seyed Reza Nabavi","Zonglin Guo","Zhiyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2507.07641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07637v1","updated":"2025-07-10T11:06:25Z","published":"2025-07-10T11:06:25Z","title":"HLF-FSL. A Decentralized Federated Split Learning Solution for IoT on\n  Hyperledger Fabric","summary":"  Collaborative machine learning in sensitive domains demands scalable, privacy\npreserving solutions for enterprise deployment. Conventional Federated Learning\n(FL) relies on a central server, introducing single points of failure and\nprivacy risks, while Split Learning (SL) partitions models for privacy but\nscales poorly due to sequential training. We present a decentralized\narchitecture that combines Federated Split Learning (FSL) with the permissioned\nblockchain Hyperledger Fabric (HLF). Our chaincode orchestrates FSL's split\nmodel execution and peer-to-peer aggregation without any central coordinator,\nleveraging HLF's transient fields and Private Data Collections (PDCs) to keep\nraw data and model activations private. On CIFAR-10 and MNIST benchmarks,\nHLF-FSL matches centralized FSL accuracy while reducing per epoch training time\ncompared to Ethereum-based works. Performance and scalability tests show\nminimal blockchain overhead and preserved accuracy, demonstrating enterprise\ngrade viability.\n","authors":["Carlos Beis Penedo","Rebeca P. Díaz Redondo","Ana Fernández Vilas","Manuel Fernández Veiga","Francisco Troncoso Pastoriza"],"pdf_url":"https://arxiv.org/pdf/2507.07637v1.pdf","comment":"19 pages, 7 figures and 6 tables"},{"id":"http://arxiv.org/abs/2505.07430v2","updated":"2025-07-10T10:54:37Z","published":"2025-05-12T10:37:33Z","title":"Comparative sentiment analysis of public perception: Monkeypox vs.\n  COVID-19 behavioral insights","summary":"  The emergence of global health crises, such as COVID-19 and Monkeypox (mpox),\nhas underscored the importance of understanding public sentiment to inform\neffective public health strategies. This study conducts a comparative sentiment\nanalysis of public perceptions surrounding COVID-19 and mpox by leveraging\nextensive datasets of 147,475 and 106,638 tweets, respectively. Advanced\nmachine learning models, including Logistic Regression, Naive Bayes, RoBERTa,\nDistilRoBERTa and XLNet, were applied to perform sentiment classification, with\nresults indicating key trends in public emotion and discourse. The analysis\nhighlights significant differences in public sentiment driven by disease\ncharacteristics, media representation, and pandemic fatigue. Through the lens\nof sentiment polarity and thematic trends, this study offers valuable insights\ninto tailoring public health messaging, mitigating misinformation, and\nfostering trust during concurrent health crises. The findings contribute to\nadvancing sentiment analysis applications in public health informatics, setting\nthe groundwork for enhanced real-time monitoring and multilingual analysis in\nfuture research.\n","authors":["Mostafa Mohaimen Akand Faisal","Rabeya Amin Jhuma","Jamini Jasim"],"pdf_url":"https://arxiv.org/pdf/2505.07430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07630v1","updated":"2025-07-10T10:54:05Z","published":"2025-07-10T10:54:05Z","title":"Exploring the Limits of Model Compression in LLMs: A Knowledge\n  Distillation Study on QA Tasks","summary":"  Large Language Models (LLMs) have demonstrated outstanding performance across\na range of NLP tasks, however, their computational demands hinder their\ndeployment in real-world, resource-constrained environments. This work\ninvestigates the extent to which LLMs can be compressed using Knowledge\nDistillation (KD) while maintaining strong performance on Question Answering\n(QA) tasks. We evaluate student models distilled from the Pythia and Qwen2.5\nfamilies on two QA benchmarks, SQuAD and MLQA, under zero-shot and one-shot\nprompting conditions. Results show that student models retain over 90% of their\nteacher models' performance while reducing parameter counts by up to 57.1%.\nFurthermore, one-shot prompting yields additional performance gains over\nzero-shot setups for both model families. These findings underscore the\ntrade-off between model efficiency and task performance, demonstrating that KD,\ncombined with minimal prompting, can yield compact yet capable QA systems\nsuitable for resource-constrained applications.\n","authors":["Joyeeta Datta","Niclas Doll","Qusai Ramadan","Zeyd Boukhers"],"pdf_url":"https://arxiv.org/pdf/2507.07630v1.pdf","comment":"Accepted four publication at the 26th Meeting of the Special Interest\n  on Discourse and Dialogue"},{"id":"http://arxiv.org/abs/2507.07625v1","updated":"2025-07-10T10:47:42Z","published":"2025-07-10T10:47:42Z","title":"Concentration of measure for non-linear random matrices with\n  applications to neural networks and non-commutative polynomials","summary":"  We prove concentration inequalities for several models of non-linear random\nmatrices. As corollaries we obtain estimates for linear spectral statistics of\nthe conjugate kernel of neural networks and non-commutative polynomials in\n(possibly dependent) random matrices.\n","authors":["Radosław Adamczak"],"pdf_url":"https://arxiv.org/pdf/2507.07625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07622v1","updated":"2025-07-10T10:44:53Z","published":"2025-07-10T10:44:53Z","title":"TransformEEG: Towards Improving Model Generalizability in Deep\n  Learning-based EEG Parkinson's Disease Detection","summary":"  Electroencephalography (EEG) is establishing itself as an important,\nlow-cost, noninvasive diagnostic tool for the early detection of Parkinson's\nDisease (PD). In this context, EEG-based Deep Learning (DL) models have shown\npromising results due to their ability to discover highly nonlinear patterns\nwithin the signal. However, current state-of-the-art DL models suffer from poor\ngeneralizability caused by high inter-subject variability. This high\nvariability underscores the need for enhancing model generalizability by\ndeveloping new architectures better tailored to EEG data. This paper introduces\nTransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's\ndisease detection using EEG data. Unlike transformer models based on the EEGNet\nstructure, TransformEEG incorporates a depthwise convolutional tokenizer. This\ntokenizer is specialized in generating tokens composed by channel-specific\nfeatures, which enables more effective feature mixing within the self-attention\nlayers of the transformer encoder. To evaluate the proposed model, four public\ndatasets comprising 290 subjects (140 PD patients, 150 healthy controls) were\nharmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out\n(N-LNSO) cross-validation was performed to provide an unbiased comparison\nagainst seven other consolidated EEG deep learning models. TransformEEG\nachieved the highest balanced accuracy's median (78.45%) as well as the lowest\ninterquartile range (6.37%) across all the N-LNSO partitions. When combined\nwith data augmentation and threshold correction, median accuracy increased to\n80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG\nproduces more consistent and less skewed results. It demonstrates a substantial\nreduction in variability and more reliable PD detection using EEG data compared\nto the other investigated models.\n","authors":["Federico Del Pup","Riccardo Brun","Filippo Iotti","Edoardo Paccagnella","Mattia Pezzato","Sabrina Bertozzo","Andrea Zanola","Louis Fabrice Tshimanga","Henning Müller","Manfredo Atzori"],"pdf_url":"https://arxiv.org/pdf/2507.07622v1.pdf","comment":"Submitted for possible publication. GitHub repository: see\n  https://github.com/MedMaxLab/transformeeg"},{"id":"http://arxiv.org/abs/2507.07621v1","updated":"2025-07-10T10:42:21Z","published":"2025-07-10T10:42:21Z","title":"Sparse Causal Discovery with Generative Intervention for Unsupervised\n  Graph Domain Adaptation","summary":"  Unsupervised Graph Domain Adaptation (UGDA) leverages labeled source domain\ngraphs to achieve effective performance in unlabeled target domains despite\ndistribution shifts. However, existing methods often yield suboptimal results\ndue to the entanglement of causal-spurious features and the failure of global\nalignment strategies. We propose SLOGAN (Sparse Causal Discovery with\nGenerative Intervention), a novel approach that achieves stable graph\nrepresentation transfer through sparse causal modeling and dynamic intervention\nmechanisms. Specifically, SLOGAN first constructs a sparse causal graph\nstructure, leveraging mutual information bottleneck constraints to disentangle\nsparse, stable causal features while compressing domain-dependent spurious\ncorrelations through variational inference. To address residual spurious\ncorrelations, we innovatively design a generative intervention mechanism that\nbreaks local spurious couplings through cross-domain feature recombination\nwhile maintaining causal feature semantic consistency via covariance\nconstraints. Furthermore, to mitigate error accumulation in target domain\npseudo-labels, we introduce a category-adaptive dynamic calibration strategy,\nensuring stable discriminative learning. Extensive experiments on multiple\nreal-world datasets demonstrate that SLOGAN significantly outperforms existing\nbaselines.\n","authors":["Junyu Luo","Yuhao Tang","Yiwei Fu","Xiao Luo","Zhizhuo Kou","Zhiping Xiao","Wei Ju","Wentao Zhang","Ming Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07621v1.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2507.07613v1","updated":"2025-07-10T10:32:42Z","published":"2025-07-10T10:32:42Z","title":"Sparse Self-Federated Learning for Energy Efficient Cooperative\n  Intelligence in Society 5.0","summary":"  Federated Learning offers privacy-preserving collaborative intelligence but\nstruggles to meet the sustainability demands of emerging IoT ecosystems\nnecessary for Society 5.0-a human-centered technological future balancing\nsocial advancement with environmental responsibility. The excessive\ncommunication bandwidth and computational resources required by traditional FL\napproaches make them environmentally unsustainable at scale, creating a\nfundamental conflict with green AI principles as billions of\nresource-constrained devices attempt to participate. To this end, we introduce\nSparse Proximity-based Self-Federated Learning (SParSeFuL), a resource-aware\napproach that bridges this gap by combining aggregate computing for\nself-organization with neural network sparsification to reduce energy and\nbandwidth consumption.\n","authors":["Davide Domini","Laura Erhan","Gianluca Aguzzi","Lucia Cavallaro","Amirhossein Douzandeh Zenoozi","Antonio Liotta","Mirko Viroli"],"pdf_url":"https://arxiv.org/pdf/2507.07613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.02409v2","updated":"2025-07-10T10:14:21Z","published":"2025-07-03T08:04:49Z","title":"S2FGL: Spatial Spectral Federated Graph Learning","summary":"  Federated Graph Learning (FGL) combines the privacy-preserving capabilities\nof federated learning (FL) with the strong graph modeling capability of Graph\nNeural Networks (GNNs). Current research addresses subgraph-FL only from the\nstructural perspective, neglecting the propagation of graph signals on spatial\nand spectral domains of the structure. From a spatial perspective, subgraph-FL\nintroduces edge disconnections between clients, leading to disruptions in label\nsignals and a degradation in the class knowledge of the global GNN. From a\nspectral perspective, spectral heterogeneity causes inconsistencies in signal\nfrequencies across subgraphs, which makes local GNNs overfit the local signal\npropagation schemes. As a result, spectral client drifts occur, undermining\nglobal generalizability. To tackle the challenges, we propose a global\nknowledge repository to mitigate label signal disruption and a frequency\nalignment to address spectral client drifts. The combination of spatial and\nspectral strategies forms our framework S2FGL. Extensive experiments on\nmultiple datasets demonstrate the superiority of S2FGL. The code is available\nat https://github.com/Wonder7racer/S2FGL.git.\n","authors":["Zihan Tan","Suyuan Huang","Guancheng Wan","Wenke Huang","He Li","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2507.02409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10393v2","updated":"2025-07-10T10:09:40Z","published":"2024-04-16T08:48:46Z","title":"Offline Trajectory Optimization for Offline Reinforcement Learning","summary":"  Offline reinforcement learning (RL) aims to learn policies without online\nexplorations. To enlarge the training data, model-based offline RL learns a\ndynamics model which is utilized as a virtual environment to generate\nsimulation data and enhance policy learning. However, existing data\naugmentation methods for offline RL suffer from (i) trivial improvement from\nshort-horizon simulation; and (ii) the lack of evaluation and correction for\ngenerated data, leading to low-qualified augmentation.\n  In this paper, we propose offline trajectory optimization for offline\nreinforcement learning (OTTO). The key motivation is to conduct long-horizon\nsimulation and then utilize model uncertainty to evaluate and correct the\naugmented data. Specifically, we propose an ensemble of Transformers, a.k.a.\nWorld Transformers, to predict environment state dynamics and the reward\nfunction. Three strategies are proposed to use World Transformers to generate\nlong-horizon trajectory simulation by perturbing the actions in the offline\ndata. Then, an uncertainty-based World Evaluator is introduced to firstly\nevaluate the confidence of the generated trajectories and then perform the\ncorrection for low-confidence data. Finally, we jointly use the original data\nwith the corrected augmentation data to train an offline RL algorithm. OTTO\nserves as a plug-in module and can be integrated with existing model-free\noffline RL methods. Experiments on various benchmarks show that OTTO can\neffectively improve the performance of representative offline RL algorithms,\nincluding in complex environments with sparse rewards like AntMaze. Codes are\navailable at https://github.com/ZiqiZhao1/OTTO.\n","authors":["Ziqi Zhao","Zhaochun Ren","Liu Yang","Yunsen Liang","Fajie Yuan","Pengjie Ren","Zhumin Chen","jun Ma","Xin Xin"],"pdf_url":"https://arxiv.org/pdf/2404.10393v2.pdf","comment":"Accepted at SIGKDD 2025"},{"id":"http://arxiv.org/abs/2507.07604v1","updated":"2025-07-10T10:06:13Z","published":"2025-07-10T10:06:13Z","title":"Synthetic MC via Biological Transmitters: Therapeutic Modulation of the\n  Gut-Brain Axis","summary":"  Synthetic molecular communication (SMC) is a key enabler for future\nhealthcare systems in which Internet of Bio-Nano-Things (IoBNT) devices\nfacilitate the continuous monitoring of a patient's biochemical signals. To\nclose the loop between sensing and actuation, both the detection and the\ngeneration of in-body molecular communication (MC) signals is key. However,\ngenerating signals inside the human body, e.g., via synthetic nanodevices,\nposes a challenge in SMC, due to technological obstacles as well as legal,\nsafety, and ethical issues. Hence, this paper considers an SMC system in which\nsignals are generated indirectly via the modulation of a natural in-body MC\nsystem, namely the gut-brain axis (GBA). Therapeutic GBA modulation is already\nestablished as treatment for neurological diseases, e.g., drug refractory\nepilepsy (DRE), and performed via the administration of nutritional supplements\nor specific diets. However, the molecular signaling pathways that mediate the\neffect of such treatments are mostly unknown. Consequently, existing treatments\nare standardized or designed heuristically and able to help only some patients\nwhile failing to help others. In this paper, we propose to leverage personal\nhealth data, e.g., gathered by in-body IoBNT devices, to design more versatile\nand robust GBA modulation-based treatments as compared to the existing ones. To\nshow the feasibility of our approach, we define a catalog of theoretical\nrequirements for therapeutic GBA modulation. Then, we propose a machine\nlearning model to verify these requirements for practical scenarios when only\nlimited data on the GBA modulation exists. By evaluating the proposed model on\nseveral datasets, we confirm its excellent accuracy in identifying different\nmodulators of the GBA. Finally, we utilize the proposed model to identify\nspecific modulatory pathways that play an important role for therapeutic GBA\nmodulation.\n","authors":["Sebastian Lotter","Elisabeth Mohr","Andrina Rutsch","Lukas Brand","Francesca Ronchi","Laura Díaz-Marugán"],"pdf_url":"https://arxiv.org/pdf/2507.07604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13796v4","updated":"2025-07-10T09:54:55Z","published":"2024-01-24T20:30:52Z","title":"Don't Push the Button! Exploring Data Leakage Risks in Machine Learning\n  and Transfer Learning","summary":"  Machine Learning (ML) has revolutionized various domains, offering predictive\ncapabilities in several areas. However, with the increasing accessibility of ML\ntools, many practitioners, lacking deep ML expertise, adopt a \"push the button\"\napproach, utilizing user-friendly interfaces without a thorough understanding\nof underlying algorithms. While this approach provides convenience, it raises\nconcerns about the reliability of outcomes, leading to challenges such as\nincorrect performance evaluation. This paper addresses a critical issue in ML,\nknown as data leakage, where unintended information contaminates the training\ndata, impacting model performance evaluation. Users, due to a lack of\nunderstanding, may inadvertently overlook crucial steps, leading to optimistic\nperformance estimates that may not hold in real-world scenarios. The\ndiscrepancy between evaluated and actual performance on new data is a\nsignificant concern. In particular, this paper categorizes data leakage in ML,\ndiscussing how certain conditions can propagate through the ML workflow.\nFurthermore, it explores the connection between data leakage and the specific\ntask being addressed, investigates its occurrence in Transfer Learning, and\ncompares standard inductive ML with transductive ML frameworks. The conclusion\nsummarizes key findings, emphasizing the importance of addressing data leakage\nfor robust and reliable ML applications.\n","authors":["Andrea Apicella","Francesco Isgrò","Roberto Prevete"],"pdf_url":"https://arxiv.org/pdf/2401.13796v4.pdf","comment":"Accepted to be published on Artificial Intelligence Review journal"},{"id":"http://arxiv.org/abs/2504.07793v3","updated":"2025-07-10T09:51:02Z","published":"2025-04-10T14:30:41Z","title":"Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling\n  Representations","summary":"  Out-of-distribution (OOD) detection is critical for ensuring the reliability\nof deep learning systems, particularly in safety-critical applications.\nLikelihood-based deep generative models have historically faced criticism for\ntheir unsatisfactory performance in OOD detection, often assigning higher\nlikelihood to OOD data than in-distribution samples when applied to image data.\nIn this work, we demonstrate that likelihood is not inherently flawed. Rather,\nseveral properties in the images space prohibit likelihood as a valid detection\nscore. Given a sufficiently good likelihood estimator, specifically using the\nprobability flow formulation of a diffusion model, we show that\nlikelihood-based methods can still perform on par with state-of-the-art methods\nwhen applied in the representation space of pre-trained encoders. The code of\nour work can be found at\n$\\href{https://github.com/limchaos/Likelihood-OOD.git}{\\texttt{https://github.com/limchaos/Likelihood-OOD.git}}$.\n","authors":["Yifan Ding","Arturas Aleksandraus","Amirhossein Ahmadian","Jonas Unger","Fredrik Lindsten","Gabriel Eilertsen"],"pdf_url":"https://arxiv.org/pdf/2504.07793v3.pdf","comment":"Scandinavian Conference on Image Analysis 2025 (oral)"},{"id":"http://arxiv.org/abs/2507.07589v1","updated":"2025-07-10T09:47:56Z","published":"2025-07-10T09:47:56Z","title":"Stress Monitoring in Healthcare: An Ensemble Machine Learning Framework\n  Using Wearable Sensor Data","summary":"  Healthcare professionals, particularly nurses, face elevated occupational\nstress, a concern amplified during the COVID-19 pandemic. While wearable\nsensors offer promising avenues for real-time stress monitoring, existing\nstudies often lack comprehensive datasets and robust analytical frameworks.\nThis study addresses these gaps by introducing a multimodal dataset comprising\nphysiological signals, electrodermal activity, heart rate and skin temperature.\nA systematic literature review identified limitations in prior stress-detection\nmethodologies, particularly in handling class imbalance and optimizing model\ngeneralizability. To overcome these challenges, the dataset underwent\npreprocessing with the Synthetic Minority Over sampling Technique (SMOTE),\nensuring balanced representation of stress states. Advanced machine learning\nmodels including Random Forest, XGBoost and a Multi-Layer Perceptron (MLP) were\nevaluated and combined into a Stacking Classifier to leverage their collective\npredictive strengths. By using a publicly accessible dataset and a reproducible\nanalytical pipeline, this work advances the development of deployable\nstress-monitoring systems, offering practical implications for safeguarding\nhealthcare workers' mental health. Future research directions include expanding\ndemographic diversity and exploring edge-computing implementations for low\nlatency stress alerts.\n","authors":["Arpana Sinhal","Anay Sinhal","Amit Sinhal"],"pdf_url":"https://arxiv.org/pdf/2507.07589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07586v1","updated":"2025-07-10T09:42:47Z","published":"2025-07-10T09:42:47Z","title":"Bayesian Discrete Diffusion Beats Autoregressive Perplexity","summary":"  We reveal a hidden Bayesian core of discrete-diffusion language models by\nshowing that the expected denoiser output under the forward masking\ndistribution recovers the exact posterior over clean tokens. Under minimal\nassumptions, Monte Carlo marginalization over K independent corruptions\nconverges to this posterior at rate O(1/sqrt(K)), yielding a simple proof of\nconsistency and finite-sample error bounds. Building on this insight, we\nintroduce a lightweight inference-time ensemble that averages K\nmask-and-denoise passes to obtain posterior-aware token probabilities and\nuncertainty estimates at no extra training cost. On WikiText-2, our method\nachieves test perplexity 8.8 with K=8, versus 20.3 for GPT-2 Small, despite\nusing a model of comparable size. Code is available at\nhttps://github.com/mercury0100/bayesradd.\n","authors":["Cooper Doyle"],"pdf_url":"https://arxiv.org/pdf/2507.07586v1.pdf","comment":"12 pages, 2 figures, 2 tables"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2507.07999v1","updated":"2025-07-10T17:59:58Z","published":"2025-07-10T17:59:58Z","title":"Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and\n  Methodology","summary":"  Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically\nreferencing visual regions, just like human \"thinking with images\". However, no\nbenchmark exists to evaluate these capabilities holistically. To bridge this\ngap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a\ndiagnostic benchmark built on three principles: (1) focused visual perception\nof subtle targets in complex scenes, (2) traceable evidence via bounding box\nevaluation, and (3) second-order reasoning to test object interactions and\nspatial hierarchies beyond simple object localization. Prioritizing images with\ndense objects, we initially sample 1K high-quality images from SA-1B, and\nincorporate eight LMM experts to manually annotate questions, candidate\noptions, and answers for each image. After three stages of quality control,\nTreeBench consists of 405 challenging visual question-answering pairs, even the\nmost advanced models struggle with this benchmark, where none of them reach 60%\naccuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR\n(Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to\nsupervise localization and reasoning jointly with reinforcement learning,\nenabling accurate localizations and explainable reasoning pathways. Initialized\nfrom Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and\nTreeBench (+13.4), proving traceability is key to advancing vision-grounded\nreasoning. The code is available at https://github.com/Haochen-Wang409/TreeVGR.\n","authors":["Haochen Wang","Xiangtai Li","Zilong Huang","Anran Wang","Jiacong Wang","Tao Zhang","Jiani Zheng","Sule Bai","Zijian Kang","Jiashi Feng","Zhuochen Wang","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07998v1","updated":"2025-07-10T17:59:55Z","published":"2025-07-10T17:59:55Z","title":"PyVision: Agentic Vision with Dynamic Tooling","summary":"  LLMs are increasingly deployed as agents, systems capable of planning,\nreasoning, and dynamically calling external tools. However, in visual\nreasoning, prior approaches largely remain limited by predefined workflows and\nstatic toolsets. In this report, we present PyVision, an interactive,\nmulti-turn framework that enables MLLMs to autonomously generate, execute, and\nrefine Python-based tools tailored to the task at hand, unlocking flexible and\ninterpretable problem-solving. We develop a taxonomy of the tools created by\nPyVision and analyze their usage across a diverse set of benchmarks.\nQuantitatively, PyVision achieves consistent performance gains, boosting\nGPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini.\nThese results point to a broader shift: dynamic tooling allows models not just\nto use tools, but to invent them, advancing toward more agentic visual\nreasoning.\n","authors":["Shitian Zhao","Haoquan Zhang","Shaoheng Lin","Ming Li","Qilong Wu","Kaipeng Zhang","Chen Wei"],"pdf_url":"https://arxiv.org/pdf/2507.07998v1.pdf","comment":"26 Pages, 10 Figures, Technical report"},{"id":"http://arxiv.org/abs/2507.07995v1","updated":"2025-07-10T17:59:53Z","published":"2025-07-10T17:59:53Z","title":"Single-pass Adaptive Image Tokenization for Minimum Program Search","summary":"  According to Algorithmic Information Theory (AIT) -- Intelligent\nrepresentations compress data into the shortest possible program that can\nreconstruct its content, exhibiting low Kolmogorov Complexity (KC). In\ncontrast, most visual representation learning systems use fixed-length\nrepresentations for all inputs, ignoring variations in complexity or\nfamiliarity. Recent adaptive tokenization methods address this by allocating\nvariable-length representations but typically require test-time search over\nmultiple encodings to find the most predictive one. Inspired by Kolmogorov\nComplexity principles, we propose a single-pass adaptive tokenizer, KARL, which\npredicts the appropriate number of tokens for an image in a single forward\npass, halting once its approximate KC is reached. The token count serves as a\nproxy for the minimum description length. KARL's training procedure closely\nresembles the Upside-Down Reinforcement Learning paradigm, as it learns to\nconditionally predict token halting based on a desired reconstruction quality.\nKARL matches the performance of recent adaptive tokenizers while operating in a\nsingle pass. We present scaling laws for KARL, analyzing the role of\nencoder/decoder size, continuous vs. discrete tokenization and more.\nAdditionally, we offer a conceptual study drawing an analogy between Adaptive\nImage Tokenization and Algorithmic Information Theory, examining the predicted\nimage complexity (KC) across axes such as structure vs. noise and in- vs.\nout-of-distribution familiarity -- revealing alignment with human intuition.\n","authors":["Shivam Duggal","Sanghyun Byun","William T. Freeman","Antonio Torralba","Phillip Isola"],"pdf_url":"https://arxiv.org/pdf/2507.07995v1.pdf","comment":"Code at: https://github.com/ShivamDuggal4/karl Keywords:\n  Representation Learning, Adaptive Tokenization, Compression, Algorithmic\n  Information Theory, Kolmogorov Complexity, Upside-Down RL"},{"id":"http://arxiv.org/abs/2507.07993v1","updated":"2025-07-10T17:59:24Z","published":"2025-07-10T17:59:24Z","title":"Multigranular Evaluation for Brain Visual Decoding","summary":"  Existing evaluation protocols for brain visual decoding predominantly rely on\ncoarse metrics that obscure inter-model differences, lack neuroscientific\nfoundation, and fail to capture fine-grained visual distinctions. To address\nthese limitations, we introduce BASIC, a unified, multigranular evaluation\nframework that jointly quantifies structural fidelity, inferential alignment,\nand contextual coherence between decoded and ground truth images. For the\nstructural level, we introduce a hierarchical suite of segmentation-based\nmetrics, including foreground, semantic, instance, and component masks,\nanchored in granularity-aware correspondence across mask structures. For the\nsemantic level, we extract structured scene representations encompassing\nobjects, attributes, and relationships using multimodal large language models,\nenabling detailed, scalable, and context-rich comparisons with ground-truth\nstimuli. We benchmark a diverse set of visual decoding methods across multiple\nstimulus-neuroimaging datasets within this unified evaluation framework.\nTogether, these criteria provide a more discriminative, interpretable, and\ncomprehensive foundation for measuring brain visual decoding methods.\n","authors":["Weihao Xia","Cengiz Oztireli"],"pdf_url":"https://arxiv.org/pdf/2507.07993v1.pdf","comment":"Project: https://weihaox.github.io/BASIC"},{"id":"http://arxiv.org/abs/2507.07990v1","updated":"2025-07-10T17:59:02Z","published":"2025-07-10T17:59:02Z","title":"Multi-Granular Spatio-Temporal Token Merging for Training-Free\n  Acceleration of Video LLMs","summary":"  Video large language models (LLMs) achieve strong video understanding by\nleveraging a large number of spatio-temporal tokens, but suffer from quadratic\ncomputational scaling with token count. To address this, we propose a\ntraining-free spatio-temporal token merging method, named STTM. Our key insight\nis to exploit local spatial and temporal redundancy in video data which has\nbeen overlooked in prior work. STTM first transforms each frame into\nmulti-granular spatial tokens using a coarse-to-fine search over a quadtree\nstructure, then performs directed pairwise merging across the temporal\ndimension. This decomposed merging approach outperforms existing token\nreduction methods across six video QA benchmarks. Notably, STTM achieves a\n2$\\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and\na 3$\\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is\nquery-agnostic, allowing KV cache reuse across different questions for the same\nvideo. The project page is available at https://www.jshyun.me/projects/sttm.\n","authors":["Jeongseok Hyun","Sukjun Hwang","Su Ho Han","Taeoh Kim","Inwoong Lee","Dongyoon Wee","Joon-Young Lee","Seon Joo Kim","Minho Shim"],"pdf_url":"https://arxiv.org/pdf/2507.07990v1.pdf","comment":"Accepted at ICCV2025; Project page:\n  https://www.jshyun.me/projects/sttm"},{"id":"http://arxiv.org/abs/2507.07986v1","updated":"2025-07-10T17:57:46Z","published":"2025-07-10T17:57:46Z","title":"EXPO: Stable Reinforcement Learning with Expressive Policies","summary":"  We study the problem of training and fine-tuning expressive policies with\nonline reinforcement learning (RL) given an offline dataset. Training\nexpressive policy classes with online RL present a unique challenge of stable\nvalue maximization. Unlike simpler Gaussian policies commonly used in online\nRL, expressive policies like diffusion and flow-matching policies are\nparameterized by a long denoising chain, which hinders stable gradient\npropagation from actions to policy parameters when optimizing against some\nvalue function. Our key insight is that we can address stable value\nmaximization by avoiding direct optimization over value with the expressive\npolicy and instead construct an on-the-fly RL policy to maximize Q-value. We\npropose Expressive Policy Optimization (EXPO), a sample-efficient online RL\nalgorithm that utilizes an on-the-fly policy to maximize value with two\nparameterized policies -- a larger expressive base policy trained with a stable\nimitation learning objective and a light-weight Gaussian edit policy that edits\nthe actions sampled from the base policy toward a higher value distribution.\nThe on-the-fly policy optimizes the actions from the base policy with the\nlearned edit policy and chooses the value maximizing action from the base and\nedited actions for both sampling and temporal-difference (TD) backup. Our\napproach yields up to 2-3x improvement in sample efficiency on average over\nprior methods both in the setting of fine-tuning a pretrained policy given\noffline data and in leveraging offline data to train online.\n","authors":["Perry Dong","Qiyang Li","Dorsa Sadigh","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2507.07986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07983v1","updated":"2025-07-10T17:56:03Z","published":"2025-07-10T17:56:03Z","title":"Performance and Practical Considerations of Large and Small Language\n  Models in Clinical Decision Support in Rheumatology","summary":"  Large language models (LLMs) show promise for supporting clinical\ndecision-making in complex fields such as rheumatology. Our evaluation shows\nthat smaller language models (SLMs), combined with retrieval-augmented\ngeneration (RAG), achieve higher diagnostic and therapeutic performance than\nlarger models, while requiring substantially less energy and enabling\ncost-efficient, local deployment. These features are attractive for\nresource-limited healthcare. However, expert oversight remains essential, as no\nmodel consistently reached specialist-level accuracy in rheumatology.\n","authors":["Sabine Felde","Rüdiger Buchkremer","Gamal Chehab","Christian Thielscher","Jörg HW Distler","Matthias Schneider","Jutta G. Richter"],"pdf_url":"https://arxiv.org/pdf/2507.07983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07982v1","updated":"2025-07-10T17:55:08Z","published":"2025-07-10T17:55:08Z","title":"Geometry Forcing: Marrying Video Diffusion and 3D Representation for\n  Consistent World Modeling","summary":"  Videos inherently represent 2D projections of a dynamic 3D world. However,\nour analysis suggests that video diffusion models trained solely on raw video\ndata often fail to capture meaningful geometric-aware structure in their\nlearned representations. To bridge this gap between video diffusion models and\nthe underlying 3D nature of the physical world, we propose Geometry Forcing, a\nsimple yet effective method that encourages video diffusion models to\ninternalize latent 3D representations. Our key insight is to guide the model's\nintermediate representations toward geometry-aware structure by aligning them\nwith features from a pretrained geometric foundation model. To this end, we\nintroduce two complementary alignment objectives: Angular Alignment, which\nenforces directional consistency via cosine similarity, and Scale Alignment,\nwhich preserves scale-related information by regressing unnormalized geometric\nfeatures from normalized diffusion representation. We evaluate Geometry Forcing\non both camera view-conditioned and action-conditioned video generation tasks.\nExperimental results demonstrate that our method substantially improves visual\nquality and 3D consistency over the baseline methods. Project page:\nhttps://GeometryForcing.github.io.\n","authors":["Haoyu Wu","Diankun Wu","Tianyu He","Junliang Guo","Yang Ye","Yueqi Duan","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2507.07982v1.pdf","comment":"18 pages, project page: https://GeometryForcing.github.io"},{"id":"http://arxiv.org/abs/2507.07981v1","updated":"2025-07-10T17:55:05Z","published":"2025-07-10T17:55:05Z","title":"Why is Your Language Model a Poor Implicit Reward Model?","summary":"  Reward models are key to language model post-training and inference\npipelines. Conveniently, recent work showed that every language model defines\nan implicit reward model (IM-RM), without requiring any architectural changes.\nHowever, such IM-RMs tend to generalize worse, especially out-of-distribution,\ncompared to explicit reward models (EX-RMs) that apply a dedicated linear head\nover the hidden representations of a language model. The existence of a\ngeneralization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They\ncan be trained using the same data, loss function, and language model, and\ndiffer only in how the reward is computed. Towards a fundamental understanding\nof the implicit biases underlying different reward model types, we investigate\nthe root cause of this gap. Our main finding, backed by theory and experiments,\nis that IM-RMs rely more heavily on superficial token-level cues. Consequently,\nthey often generalize worse than EX-RMs under token-level distribution shifts,\nas well as in-distribution. Furthermore, we provide evidence against\nalternative hypotheses for the generalization gap. Most notably, we challenge\nthe intuitive claim that IM-RMs struggle in tasks where generation is harder\nthan verification because they can operate both as a verifier and a generator.\nTaken together, our results highlight that seemingly minor design choices can\nsubstantially impact the generalization behavior of reward models.\n","authors":["Noam Razin","Yong Lin","Jiarui Yao","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2507.07981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07969v1","updated":"2025-07-10T17:48:03Z","published":"2025-07-10T17:48:03Z","title":"Reinforcement Learning with Action Chunking","summary":"  We present Q-chunking, a simple yet effective recipe for improving\nreinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks.\nOur recipe is designed for the offline-to-online RL setting, where the goal is\nto leverage an offline prior dataset to maximize the sample-efficiency of\nonline learning. Effective exploration and sample-efficient learning remain\ncentral challenges in this setting, as it is not obvious how the offline data\nshould be utilized to acquire a good exploratory policy. Our key insight is\nthat action chunking, a technique popularized in imitation learning where\nsequences of future actions are predicted rather than a single action at each\ntimestep, can be applied to temporal difference (TD)-based RL methods to\nmitigate the exploration challenge. Q-chunking adopts action chunking by\ndirectly running RL in a 'chunked' action space, enabling the agent to (1)\nleverage temporally consistent behaviors from offline data for more effective\nonline exploration and (2) use unbiased $n$-step backups for more stable and\nefficient TD learning. Our experimental results demonstrate that Q-chunking\nexhibits strong offline performance and online sample efficiency, outperforming\nprior best offline-to-online methods on a range of long-horizon, sparse-reward\nmanipulation tasks.\n","authors":["Qiyang Li","Zhiyuan Zhou","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2507.07969v1.pdf","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2507.07966v1","updated":"2025-07-10T17:47:40Z","published":"2025-07-10T17:47:40Z","title":"Scaling RL to Long Videos","summary":"  We introduce a full-stack framework that scales up reasoning in\nvision-language models (VLMs) to long videos, leveraging reinforcement\nlearning. We address the unique challenges of long video reasoning by\nintegrating three critical components: (1) a large-scale dataset,\nLongVideo-Reason, comprising 52K long video QA pairs with high-quality\nreasoning annotations across diverse domains such as sports, games, and vlogs;\n(2) a two-stage training pipeline that extends VLMs with chain-of-thought\nsupervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a\ntraining infrastructure for long video RL, named Multi-modal Reinforcement\nSequence Parallelism (MR-SP), which incorporates sequence parallelism and a\nvLLM-based engine tailored for long video, using cached video embeddings for\nefficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves\nstrong performance on long video QA benchmarks such as VideoMME. It also\noutperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal\nreasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on\nour LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to\n2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent\nperformance gains as the number of input video frames scales. LongVILA-R1 marks\na firm step towards long video reasoning in VLMs. In addition, we release our\ntraining system for public availability that supports RL training on various\nmodalities (video, text, and audio), various models (VILA and Qwen series), and\neven image and video generation models. On a single A100 node (8 GPUs), it\nsupports RL training on hour-long videos (e.g., 3,600 frames / around 256k\ntokens).\n","authors":["Yukang Chen","Wei Huang","Baifeng Shi","Qinghao Hu","Hanrong Ye","Ligeng Zhu","Zhijian Liu","Pavlo Molchanov","Jan Kautz","Xiaojuan Qi","Sifei Liu","Hongxu Yin","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2507.07966v1.pdf","comment":"Code and models are available at https://github.com/NVlabs/Long-RL"},{"id":"http://arxiv.org/abs/2507.07957v1","updated":"2025-07-10T17:40:11Z","published":"2025-07-10T17:40:11Z","title":"MIRIX: Multi-Agent Memory System for LLM-Based Agents","summary":"  Although memory capabilities of AI agents are gaining increasing attention,\nexisting solutions remain fundamentally limited. Most rely on flat, narrowly\nscoped memory components, constraining their ability to personalize, abstract,\nand reliably recall user-specific information over time. To this end, we\nintroduce MIRIX, a modular, multi-agent memory system that redefines the future\nof AI memory by solving the field's most critical challenge: enabling language\nmodels to truly remember. Unlike prior approaches, MIRIX transcends text to\nembrace rich visual and multimodal experiences, making memory genuinely useful\nin real-world scenarios. MIRIX consists of six distinct, carefully structured\nmemory types: Core, Episodic, Semantic, Procedural, Resource Memory, and\nKnowledge Vault, coupled with a multi-agent framework that dynamically controls\nand coordinates updates and retrieval. This design enables agents to persist,\nreason over, and accurately retrieve diverse, long-term user data at scale. We\nvalidate MIRIX in two demanding settings. First, on ScreenshotVQA, a\nchallenging multimodal benchmark comprising nearly 20,000 high-resolution\ncomputer screenshots per sequence, requiring deep contextual understanding and\nwhere no existing memory systems can be applied, MIRIX achieves 35% higher\naccuracy than the RAG baseline while reducing storage requirements by 99.9%.\nSecond, on LOCOMO, a long-form conversation benchmark with single-modal textual\ninput, MIRIX attains state-of-the-art performance of 85.4%, far surpassing\nexisting baselines. These results show that MIRIX sets a new performance\nstandard for memory-augmented LLM agents. To allow users to experience our\nmemory system, we provide a packaged application powered by MIRIX. It monitors\nthe screen in real time, builds a personalized memory base, and offers\nintuitive visualization and secure local storage to ensure privacy.\n","authors":["Yu Wang","Xi Chen"],"pdf_url":"https://arxiv.org/pdf/2507.07957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07947v1","updated":"2025-07-10T17:32:26Z","published":"2025-07-10T17:32:26Z","title":"Low Resource Reconstruction Attacks Through Benign Prompts","summary":"  The recent advances in generative models such as diffusion models have raised\nseveral risks and concerns related to privacy, copyright infringements and data\nstewardship. To better understand and control the risks, various researchers\nhave created techniques, experiments and attacks that reconstruct images, or\npart of images, from the training set. While these techniques already establish\nthat data from the training set can be reconstructed, they often rely on\nhigh-resources, excess to the training set as well as well-engineered and\ndesigned prompts.\n  In this work, we devise a new attack that requires low resources, assumes\nlittle to no access to the actual training set, and identifies, seemingly,\nbenign prompts that lead to potentially-risky image reconstruction. This\nhighlights the risk that images might even be reconstructed by an uninformed\nuser and unintentionally. For example, we identified that, with regard to one\nexisting model, the prompt ``blue Unisex T-Shirt'' can generate the face of a\nreal-life human model. Our method builds on an intuition from previous works\nwhich leverages domain knowledge and identifies a fundamental vulnerability\nthat stems from the use of scraped data from e-commerce platforms, where\ntemplated layouts and images are tied to pattern-like prompts.\n","authors":["Sol Yarkoni","Roi Livni"],"pdf_url":"https://arxiv.org/pdf/2507.07947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14993v2","updated":"2025-07-10T17:30:56Z","published":"2024-09-23T13:16:09Z","title":"Multi-modal Generative AI: Multi-modal LLMs, Diffusions and the\n  Unification","summary":"  Multi-modal generative AI (Artificial Intelligence) has attracted increasing\nattention from both academia and industry. Particularly, two dominant families\nof techniques have emerged: i) Multi-modal large language models (LLMs)\ndemonstrate impressive ability for multi-modal understanding; and ii) Diffusion\nmodels exhibit remarkable multi-modal powers in terms of multi-modal\ngeneration. Therefore, this paper provides a comprehensive overview of\nmulti-modal generative AI, including multi-modal LLMs, diffusions, and the\nunification for understanding and generation. To lay a solid foundation for\nunified models, we first provide a detailed review of both multi-modal LLMs and\ndiffusion models respectively, including their probabilistic modeling\nprocedure, multi-modal architecture design, and advanced applications to\nimage/video LLMs as well as text-to-image/video generation. Furthermore, we\nexplore the emerging efforts toward unified models for understanding and\ngeneration. To achieve the unification of understanding and generation, we\ninvestigate key designs including autoregressive-based and diffusion-based\nmodeling, as well as dense and Mixture-of-Experts (MoE) architectures. We then\nintroduce several strategies for unified models, analyzing their potential\nadvantages and disadvantages. In addition, we summarize the common datasets\nwidely used for multi-modal generative AI pretraining. Last but not least, we\npresent several challenging future research directions which may contribute to\nthe ongoing advancement of multi-modal generative AI.\n","authors":["Xin Wang","Yuwei Zhou","Bin Huang","Hong Chen","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2409.14993v2.pdf","comment":"20 pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2507.07935v1","updated":"2025-07-10T17:16:33Z","published":"2025-07-10T17:16:33Z","title":"Working with AI: Measuring the Occupational Implications of Generative\n  AI","summary":"  Given the rapid adoption of generative AI and its potential to impact a wide\nrange of tasks, understanding the effects of AI on the economy is one of\nsociety's most important questions. In this work, we take a step toward that\ngoal by analyzing the work activities people do with AI, how successfully and\nbroadly those activities are done, and combine that with data on what\noccupations do those activities. We analyze a dataset of 200k anonymized and\nprivacy-scrubbed conversations between users and Microsoft Bing Copilot, a\npublicly available generative AI system. We find the most common work\nactivities people seek AI assistance for involve gathering information and\nwriting, while the most common activities that AI itself is performing are\nproviding information and assistance, writing, teaching, and advising.\nCombining these activity classifications with measurements of task success and\nscope of impact, we compute an AI applicability score for each occupation. We\nfind the highest AI applicability scores for knowledge work occupation groups\nsuch as computer and mathematical, and office and administrative support, as\nwell as occupations such as sales whose work activities involve providing and\ncommunicating information. Additionally, we characterize the types of work\nactivities performed most successfully, how wage and education correlate with\nAI applicability, and how real-world usage compares to predictions of\noccupational AI impact.\n","authors":["Kiran Tomlinson","Sonia Jaffe","Will Wang","Scott Counts","Siddharth Suri"],"pdf_url":"https://arxiv.org/pdf/2507.07935v1.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2507.07931v1","updated":"2025-07-10T17:10:07Z","published":"2025-07-10T17:10:07Z","title":"Meek Models Shall Inherit the Earth","summary":"  The past decade has seen incredible scaling of AI systems by a few companies,\nleading to inequality in AI model performance. This paper argues that, contrary\nto prevailing intuition, the diminishing returns to compute scaling will lead\nto a convergence of AI model capabilities. In other words, meek models (those\nwith limited computation budget) shall inherit the earth, approaching the\nperformance level of the best models overall. We develop a model illustrating\nthat under a fixed-distribution next-token objective, the marginal capability\nreturns to raw compute shrink substantially. Given current scaling practices,\nwe argue that these diminishing returns are strong enough that even companies\nthat can scale their models exponentially faster than other organizations will\neventually have little advantage in capabilities. As part of our argument, we\ngive several reasons that proxies like training loss differences capture\nimportant capability measures using evidence from benchmark data and\ntheoretical performance models. In addition, we analyze empirical data on the\ncapability difference of AI models over time. Finally, in light of the\nincreasing ability of meek models, we argue that AI strategy and policy require\nreexamination, and we outline the areas this shift will affect.\n","authors":["Hans Gundlach","Jayson Lynch","Neil Thompson"],"pdf_url":"https://arxiv.org/pdf/2507.07931v1.pdf","comment":"13 pages, 9 figures, longer version of the paper presented at TAIG\n  ICML 2025"},{"id":"http://arxiv.org/abs/2507.07930v1","updated":"2025-07-10T17:09:21Z","published":"2025-07-10T17:09:21Z","title":"Probing Experts' Perspectives on AI-Assisted Public Speaking Training","summary":"  Background: Public speaking is a vital professional skill, yet it remains a\nsource of significant anxiety for many individuals. Traditional training relies\nheavily on expert coaching, but recent advances in AI has led to novel types of\ncommercial automated public speaking feedback tools. However, most research has\nfocused on prototypes rather than commercial applications, and little is known\nabout how public speaking experts perceive these tools.\n  Objectives: This study aims to evaluate expert opinions on the efficacy and\ndesign of commercial AI-based public speaking training tools and to propose\nguidelines for their improvement.\n  Methods: The research involved 16 semi-structured interviews and 2 focus\ngroups with public speaking experts. Participants discussed their views on\ncurrent commercial tools, their potential integration into traditional\ncoaching, and suggestions for enhancing these systems.\n  Results and Conclusions: Experts acknowledged the value of AI tools in\nhandling repetitive, technical aspects of training, allowing coaches to focus\non higher-level skills. However they found key issues in current tools,\nemphasising the need for personalised, understandable, carefully selected\nfeedback and clear instructional design. Overall, they supported a hybrid model\ncombining traditional coaching with AI-supported exercises.\n","authors":["Nesrine Fourati","Alisa Barkar","Marion Dragée","Liv Danthon-Lefebvre","Mathieu Chollet"],"pdf_url":"https://arxiv.org/pdf/2507.07930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07929v1","updated":"2025-07-10T17:09:14Z","published":"2025-07-10T17:09:14Z","title":"Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and\n  Identification Strategies for Laboratory Mice","summary":"  Continuous, automated monitoring of laboratory mice enables more accurate\ndata collection and improves animal welfare through real-time insights.\nResearchers can achieve a more dynamic and clinically relevant characterization\nof disease progression and therapeutic effects by integrating behavioral and\nphysiological monitoring in the home cage. However, providing individual mouse\nmetrics is difficult because of their housing density, similar appearances,\nhigh mobility, and frequent interactions. To address these challenges, we\ndevelop a real-time identification (ID) algorithm that accurately assigns ID\npredictions to mice wearing custom ear tags in digital home cages monitored by\ncameras. Our pipeline consists of three parts: (1) a custom multiple object\ntracker (MouseTracks) that combines appearance and motion cues from mice; (2) a\ntransformer-based ID classifier (Mouseformer); and (3) a tracklet associator\nlinear program to assign final ID predictions to tracklets (MouseMap). Our\nmodels assign an animal ID based on custom ear tags at 30 frames per second\nwith 24/7 cage coverage. We show that our custom tracking and ID pipeline\nimproves tracking efficiency and lowers ID switches across mouse strains and\nvarious environmental factors compared to current mouse tracking methods.\n","authors":["Juan Pablo Oberhauser","Daniel Grzenda"],"pdf_url":"https://arxiv.org/pdf/2507.07929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.00004v2","updated":"2025-07-10T17:08:40Z","published":"2025-06-10T14:47:48Z","title":"A Theory of Inference Compute Scaling: Reasoning through Directed\n  Stochastic Skill Search","summary":"  Large language models (LLMs) demand considerable computational, energy, and\nfinancial resources during both training and deployment. While scaling laws for\ntraining have guided much of the field's recent progress, inference costs now\nrepresent a significant and growing component of the overall resource burden,\nparticularly for reasoning-focused models. Existing characterizations of\ncompute-optimality that consider model size, dataset size, and inference tokens\nin isolation or in fixed combinations risk overlooking more efficient operating\npoints. We introduce directed stochastic skill search (DS3), a general\nframework that represents inference as stochastic traversal over a learned\nskill graph. From a simplified yet expressive instantiation, we derive\nclosed-form expressions for task success and compute cost across a wide range\nof inference strategies -- including chain-of-thought (CoT) and tree-of-thought\n(ToT) -- enabling comparative analysis as a function of task difficulty and\nmodel capability. To that end, we extend a prior first-principles tripartite\ngraph framework of LLM training to incorporate inference, and separately bridge\nDS3 with empirical methods that characterize LLM scaling behavior. We\ntheoretically recover empirically observed patterns, including: linear accuracy\nscaling with logarithmic compute; variation in preferred inference strategies\nas a function of task difficulty and model capability; emergent behavior\nelicited by reasoning even when performance plateaus under parameter scaling;\nand both best-of-N (BoN) and majority voting behavior captured within a unified\nanalytical framework. By explicitly characterizing training-inference\ninterdependencies, our framework deepens theoretical understanding and supports\nprincipled algorithmic design and resource allocation.\n","authors":["Austin R. Ellis-Mohr","Anuj K. Nayak","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2507.00004v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10955v2","updated":"2025-07-10T16:59:24Z","published":"2024-09-17T07:44:06Z","title":"Investigating Context-Faithfulness in Large Language Models: The Roles\n  of Memory Strength and Evidence Style","summary":"  Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by\nincorporating external information into the response generation process.\nHowever, how context-faithful LLMs are and what factors influence LLMs' context\nfaithfulness remain largely unexplored. In this study, we investigate the\nimpact of memory strength and evidence presentation on LLMs' receptiveness to\nexternal evidence. We quantify the memory strength of LLMs by measuring the\ndivergence in LLMs' responses to different paraphrases of the same question,\nwhich is not considered by previous works. We also generate evidence in various\nstyles to examine LLMs' behavior. Our results show that for questions with high\nmemory strength, LLMs are more likely to rely on internal memory. Furthermore,\npresenting paraphrased evidence significantly increases LLMs' receptiveness\ncompared to simple repetition or adding details. These findings provide key\ninsights for improving retrieval-augmented generation and context-aware LLMs.\nOur code is available at https://github.com/liyp0095/ContextFaithful.\n","authors":["Yuepei Li","Kang Zhou","Qiao Qiao","Bach Nguyen","Qing Wang","Qi Li"],"pdf_url":"https://arxiv.org/pdf/2409.10955v2.pdf","comment":"This work is published at ACL 2025"},{"id":"http://arxiv.org/abs/2507.05110v3","updated":"2025-07-10T16:55:05Z","published":"2025-07-07T15:27:48Z","title":"Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution\n  Shift","summary":"  Logical rule learning, a prominent category of knowledge graph (KG) reasoning\nmethods, constitutes a critical research area aimed at learning explicit rules\nfrom observed facts to infer missing knowledge. However, like all KG reasoning\nmethods, rule learning suffers from a critical weakness-its dependence on the\nI.I.D. assumption. This assumption can easily be violated due to selection bias\nduring training or agnostic distribution shifts during testing (e.g., as in\nquery shift scenarios), ultimately undermining model performance and\nreliability. To enable robust KG reasoning in wild environments, this study\ninvestigates logical rule learning in the presence of agnostic test-time\ndistribution shifts. We formally define this challenge as out-of-distribution\n(OOD) KG reasoning-a previously underexplored problem, and propose the Stable\nRule Learning (StableRule) framework as a solution. StableRule is an end-to-end\nframework that combines feature decorrelation with rule learning network, to\nenhance OOD generalization in KG reasoning. By leveraging feature\ndecorrelation, StableRule mitigates the adverse effects of covariate shifts\narising in OOD scenarios, improving the robustness of the rule learning\nnetwork. Extensive experiments on seven benchmark KGs demonstrate the\nframework's superior effectiveness and stability across diverse heterogeneous\nenvironments, highlighting its practical significance for real-world\napplications.\n","authors":["Shixuan Liu","Yue He","Yunfei Wang","Hao Zou","Haoxiang Cheng","Wenjing Yang","Peng Cui","Zhong Liu"],"pdf_url":"https://arxiv.org/pdf/2507.05110v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07910v1","updated":"2025-07-10T16:44:33Z","published":"2025-07-10T16:44:33Z","title":"DTECT: Dynamic Topic Explorer & Context Tracker","summary":"  The explosive growth of textual data over time presents a significant\nchallenge in uncovering evolving themes and trends. Existing dynamic topic\nmodeling techniques, while powerful, often exist in fragmented pipelines that\nlack robust support for interpretation and user-friendly exploration. We\nintroduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end\nsystem that bridges the gap between raw textual data and meaningful temporal\ninsights. DTECT provides a unified workflow that supports data preprocessing,\nmultiple model architectures, and dedicated evaluation metrics to analyze the\ntopic quality of temporal topic models. It significantly enhances\ninterpretability by introducing LLM-driven automatic topic labeling, trend\nanalysis via temporally salient words, interactive visualizations with\ndocument-level summarization, and a natural language chat interface for\nintuitive data querying. By integrating these features into a single, cohesive\nplatform, DTECT empowers users to more effectively track and understand\nthematic dynamics. DTECT is open-source and available at\nhttps://github.com/AdhyaSuman/DTECT.\n","authors":["Suman Adhya","Debarshi Kumar Sanyal"],"pdf_url":"https://arxiv.org/pdf/2507.07910v1.pdf","comment":"Code: https://github.com/AdhyaSuman/DTECT | Demo:\n  https://huggingface.co/spaces/AdhyaSuman/DTECT | Video:\n  https://youtu.be/B8nNfxFoJAU"},{"id":"http://arxiv.org/abs/2507.02825v3","updated":"2025-07-10T16:42:37Z","published":"2025-07-03T17:35:31Z","title":"Establishing Best Practices for Building Rigorous Agentic Benchmarks","summary":"  Benchmarks are essential for quantitatively tracking progress in AI. As AI\nagents become increasingly capable, researchers and practitioners have\nintroduced agentic benchmarks to evaluate agents on complex, real-world tasks.\nThese benchmarks typically measure agent capabilities by evaluating task\noutcomes via specific reward designs. However, we show that many agentic\nbenchmarks have issues in task setup or reward design. For example, SWE-bench\nVerified uses insufficient test cases, while TAU-bench counts empty responses\nas successful. Such issues can lead to under- or overestimation of agents'\nperformance by up to 100% in relative terms. To make agentic evaluation\nrigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of\nguidelines that we synthesized from our benchmark-building experience, a survey\nof best practices, and previously reported issues. When applied to CVE-Bench, a\nbenchmark with a particularly complex evaluation design, ABC reduces the\nperformance overestimation by 33%.\n","authors":["Yuxuan Zhu","Tengjun Jin","Yada Pruksachatkun","Andy Zhang","Shu Liu","Sasha Cui","Sayash Kapoor","Shayne Longpre","Kevin Meng","Rebecca Weiss","Fazl Barez","Rahul Gupta","Jwala Dhamala","Jacob Merizian","Mario Giulianelli","Harry Coppock","Cozmin Ududec","Jasjeet Sekhon","Jacob Steinhardt","Antony Kellerman","Sarah Schwettmann","Matei Zaharia","Ion Stoica","Percy Liang","Daniel Kang"],"pdf_url":"https://arxiv.org/pdf/2507.02825v3.pdf","comment":"39 pages, 15 tables, 6 figures"},{"id":"http://arxiv.org/abs/2507.07906v1","updated":"2025-07-10T16:38:59Z","published":"2025-07-10T16:38:59Z","title":"Agentic Retrieval of Topics and Insights from Earnings Calls","summary":"  Tracking the strategic focus of companies through topics in their earnings\ncalls is a key task in financial analysis. However, as industries evolve,\ntraditional topic modeling techniques struggle to dynamically capture emerging\ntopics and their relationships. In this work, we propose an LLM-agent driven\napproach to discover and retrieve emerging topics from quarterly earnings\ncalls. We propose an LLM-agent to extract topics from documents, structure them\ninto a hierarchical ontology, and establish relationships between new and\nexisting topics through a topic ontology. We demonstrate the use of extracted\ntopics to infer company-level insights and emerging trends over time. We\nevaluate our approach by measuring ontology coherence, topic evolution\naccuracy, and its ability to surface emerging financial trends.\n","authors":["Anant Gupta","Rajarshi Bhowmik","Geoffrey Gunow"],"pdf_url":"https://arxiv.org/pdf/2507.07906v1.pdf","comment":"The 2nd Workshop on Financial Information Retrieval in the Era of\n  Generative AI, The 48th International ACM SIGIR Conference on Research and\n  Development in Information Retrieval July 13-17, 2025 | Padua, Italy"},{"id":"http://arxiv.org/abs/2507.01788v2","updated":"2025-07-10T16:23:29Z","published":"2025-07-02T15:14:06Z","title":"Are Vision Transformer Representations Semantically Meaningful? A Case\n  Study in Medical Imaging","summary":"  Vision transformers (ViTs) have rapidly gained prominence in medical imaging\ntasks such as disease classification, segmentation, and detection due to their\nsuperior accuracy compared to conventional deep learning models. However, due\nto their size and complex interactions via the self-attention mechanism, they\nare not well understood. In particular, it is unclear whether the\nrepresentations produced by such models are semantically meaningful. In this\npaper, using a projected gradient-based algorithm, we show that their\nrepresentations are not semantically meaningful and they are inherently\nvulnerable to small changes. Images with imperceptible differences can have\nvery different representations; on the other hand, images that should belong to\ndifferent semantic classes can have nearly identical representations. Such\nvulnerability can lead to unreliable classification results; for example,\nunnoticeable changes cause the classification accuracy to be reduced by over\n60\\%. %. To the best of our knowledge, this is the first work to systematically\ndemonstrate this fundamental lack of semantic meaningfulness in ViT\nrepresentations for medical image classification, revealing a critical\nchallenge for their deployment in safety-critical systems.\n","authors":["Montasir Shams","Chashi Mahiul Islam","Shaeke Salman","Phat Tran","Xiuwen Liu"],"pdf_url":"https://arxiv.org/pdf/2507.01788v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2507.07893v1","updated":"2025-07-10T16:22:41Z","published":"2025-07-10T16:22:41Z","title":"An Integrated Framework of Prompt Engineering and Multidimensional\n  Knowledge Graphs for Legal Dispute Analysis","summary":"  The rapid development of artificial intelligence has positioned large\nlanguage models as fundamental components of intelligent legal systems.\nHowever, these models face significant limitations in legal dispute analysis,\nincluding insufficient legal knowledge representation, limited concept\nunderstanding, and reasoning deficiencies. This research proposes an enhanced\nframework integrating prompt engineering with multidimensional knowledge\ngraphs. The framework introduces a three-stage hierarchical prompt structure\ncomprising task definition, knowledge background, and reasoning guidance,\nsupplemented by legal-specific reasoning templates and dynamic optimization\nmechanisms. A three-layer knowledge graph architecture is constructed with\nlegal classification ontology, representation, and instance layers. Four\ncomplementary methods enable precise legal concept retrieval: direct legal norm\ncode matching, domain-specific semantic vector similarity, ontology-based path\nreasoning, and specialized lexical segmentation. These components integrate\nwith web search technology to establish a knowledge-enhanced framework for\nlegal decision-making. Experimental results demonstrate significant performance\nimprovements in legal dispute analysis, enabling accurate legal application\nanalysis for complex cases while exhibiting nuanced understanding of judicial\ndecision-making logic, providing a novel technical approach for implementing\nintelligent legal assistance systems.\n","authors":["Mingda Zhang","Na Zhao","Jianglong Qing","Qing xu","Kaiwen Pan","Ting luo"],"pdf_url":"https://arxiv.org/pdf/2507.07893v1.pdf","comment":"15 pages,3 figures"},{"id":"http://arxiv.org/abs/2507.05297v3","updated":"2025-07-10T16:18:21Z","published":"2025-07-06T09:13:22Z","title":"Fuzzy Classification Aggregation for a Continuum of Agents","summary":"  We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean.\n","authors":["Zijun Meng"],"pdf_url":"https://arxiv.org/pdf/2507.05297v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06687v3","updated":"2025-07-10T16:14:55Z","published":"2024-08-13T07:27:02Z","title":"Masked Image Modeling: A Survey","summary":"  In this work, we survey recent studies on masked image modeling (MIM), an\napproach that emerged as a powerful self-supervised learning technique in\ncomputer vision. The MIM task involves masking some information, e.g. pixels,\npatches, or even latent representations, and training a model, usually an\nautoencoder, to predicting the missing information by using the context\navailable in the visible part of the input. We identify and formalize two\ncategories of approaches on how to implement MIM as a pretext task, one based\non reconstruction and one based on contrastive learning. Then, we construct a\ntaxonomy and review the most prominent papers in recent years. We complement\nthe manually constructed taxonomy with a dendrogram obtained by applying a\nhierarchical clustering algorithm. We further identify relevant clusters via\nmanually inspecting the resulting dendrogram. Our review also includes datasets\nthat are commonly used in MIM research. We aggregate the performance results of\nvarious masked image modeling methods on the most popular datasets, to\nfacilitate the comparison of competing methods. Finally, we identify research\ngaps and propose several interesting directions of future work. We supplement\nour survey with the following public repository containing organized\nreferences: https://github.com/vladhondru25/MIM-Survey.\n","authors":["Vlad Hondru","Florinel Alin Croitoru","Shervin Minaee","Radu Tudor Ionescu","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2408.06687v3.pdf","comment":"Accepted at the International Journal of Computer Vision"},{"id":"http://arxiv.org/abs/2507.07885v1","updated":"2025-07-10T16:12:06Z","published":"2025-07-10T16:12:06Z","title":"UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient\n  Neural Inference on MCUs","summary":"  Existing pruning methods are typically applied during training or compile\ntime and often rely on structured sparsity. While compatible with low-power\nmicrocontrollers (MCUs), structured pruning underutilizes the opportunity for\nfine-grained efficiency on devices without SIMD support or parallel compute. To\naddress these limitations, we introduce UnIT (Unstructured Inference-Time\npruning), a lightweight method that dynamically identifies and skips\nunnecessary multiply-accumulate (MAC) operations during inference, guided by\ninput-specific activation patterns. Unlike structured pruning, UnIT embraces\nirregular sparsity and does not require retraining or hardware specialization.\nIt transforms pruning decisions into lightweight comparisons, replacing\nmultiplications with threshold checks and approximated divisions. UnIT further\noptimizes compute by reusing threshold computations across multiple connections\nand applying layer- and group-specific pruning sensitivity. We present three\nfast, hardware-friendly division approximations tailored to the capabilities of\ncommon embedded platforms. Demonstrated on the MSP430 microcontroller, UnIT\nachieves 11.02% to 82.03% MAC reduction, 27.30% to 84.19% faster inference, and\n27.33% to 84.38% lower energy consumption compared to training-time pruned\nmodels, while maintaining accuracy with 0.48-7%. Under domain shift, UnIT\nmatches or exceeds the accuracy of retrained models while requiring\nsignificantly fewer MACs. These results establish unstructured inference-time\npruning as a viable and practical solution for efficient, retraining-free\ndeployment of deep neural networks on MCUs.\n","authors":["Ashe Neth","Sawinder kaur","Mohammad Nur Hossain Khan","Subrata Biswas","Asif Salekin","Bashima Islam"],"pdf_url":"https://arxiv.org/pdf/2507.07885v1.pdf","comment":"Submitted to SenSys 2026 on July 1, 2025"},{"id":"http://arxiv.org/abs/2507.06952v2","updated":"2025-07-10T16:01:42Z","published":"2025-07-09T15:36:15Z","title":"What Has a Foundation Model Found? Using Inductive Bias to Probe for\n  World Models","summary":"  Foundation models are premised on the idea that sequence prediction can\nuncover deeper domain understanding, much like how Kepler's predictions of\nplanetary motion later led to the discovery of Newtonian mechanics. However,\nevaluating whether these models truly capture deeper structure remains a\nchallenge. We develop a technique for evaluating foundation models that\nexamines how they adapt to synthetic datasets generated from some postulated\nworld model. Our technique measures whether the foundation model's inductive\nbias aligns with the world model, and so we refer to it as an inductive bias\nprobe. Across multiple domains, we find that foundation models can excel at\ntheir training tasks yet fail to develop inductive biases towards the\nunderlying world model when adapted to new tasks. We particularly find that\nfoundation models trained on orbital trajectories consistently fail to apply\nNewtonian mechanics when adapted to new physics tasks. Further analysis reveals\nthat these models behave as if they develop task-specific heuristics that fail\nto generalize.\n","authors":["Keyon Vafa","Peter G. Chang","Ashesh Rambachan","Sendhil Mullainathan"],"pdf_url":"https://arxiv.org/pdf/2507.06952v2.pdf","comment":"To appear in ICML 2025"},{"id":"http://arxiv.org/abs/2505.04931v2","updated":"2025-07-10T16:00:00Z","published":"2025-05-08T04:09:36Z","title":"Fair Uncertainty Quantification for Depression Prediction","summary":"  Trustworthy depression prediction based on deep learning, incorporating both\npredictive reliability and algorithmic fairness across diverse demographic\ngroups, is crucial for clinical application. Recently, achieving reliable\ndepression predictions through uncertainty quantification has attracted\nincreasing attention. However, few studies have focused on the fairness of\nuncertainty quantification (UQ) in depression prediction. In this work, we\ninvestigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage\n(EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for\ndepression prediction. FUQ pursues reliable and fair depression predictions\nthrough group-based analysis. Specifically, we first group all the participants\nby different sensitive attributes and leverage conformal prediction to quantify\nuncertainty within each demographic group, which provides a theoretically\nguaranteed and valid way to quantify uncertainty for depression prediction and\nfacilitates the investigation of fairness across different demographic groups.\nFurthermore, we propose a fairness-aware optimization strategy that formulates\nfairness as a constrained optimization problem under EOC constraints. This\nenables the model to preserve predictive reliability while adapting to the\nheterogeneous uncertainty levels across demographic groups, thereby achieving\noptimal fairness. Through extensive evaluations on several visual and audio\ndepression datasets, our approach demonstrates its effectiveness.\n","authors":["Yonghong Li","Xiuzhuang Zhou"],"pdf_url":"https://arxiv.org/pdf/2505.04931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07871v1","updated":"2025-07-10T15:52:32Z","published":"2025-07-10T15:52:32Z","title":"Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key\n  Watermarking","summary":"  Watermarking offers a promising solution for GenAI providers to establish the\nprovenance of their generated content. A watermark is a hidden signal embedded\nin the generated content, whose presence can later be verified using a secret\nwatermarking key. A threat to GenAI providers are \\emph{watermark stealing}\nattacks, where users forge a watermark into content that was \\emph{not}\ngenerated by the provider's models without access to the secret key, e.g., to\nfalsely accuse the provider. Stealing attacks collect \\emph{harmless}\nwatermarked samples from the provider's model and aim to maximize the expected\nsuccess rate of generating \\emph{harmful} watermarked samples. Our work focuses\non mitigating stealing attacks while treating the underlying watermark as a\nblack-box. Our contributions are: (i) Proposing a multi-key extension to\nmitigate stealing attacks that can be applied post-hoc to any watermarking\nmethod across any modality. (ii) We provide theoretical guarantees and\ndemonstrate empirically that our method makes forging substantially less\neffective across multiple datasets, and (iii) we formally define the threat of\nwatermark forging as the task of generating harmful, watermarked content and\nmodel this threat via security games.\n","authors":["Toluwani Aremu","Noor Hussein","Munachiso Nwadike","Samuele Poppi","Jie Zhang","Karthik Nandakumar","Neil Gong","Nils Lukas"],"pdf_url":"https://arxiv.org/pdf/2507.07871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07868v1","updated":"2025-07-10T15:48:23Z","published":"2025-07-10T15:48:23Z","title":"Alpay Algebra V: Multi-Layered Semantic Games and Transfinite\n  Fixed-Point Simulation","summary":"  This paper extends the self-referential framework of Alpay Algebra into a\nmulti-layered semantic game architecture where transfinite fixed-point\nconvergence encompasses hierarchical sub-games at each iteration level.\nBuilding upon Alpay Algebra IV's empathetic embedding concept, we introduce a\nnested game-theoretic structure where the alignment process between AI systems\nand documents becomes a meta-game containing embedded decision problems. We\nformalize this through a composite operator $\\phi(\\cdot, \\gamma(\\cdot))$ where\n$\\phi$ drives the main semantic convergence while $\\gamma$ resolves local\nsub-games. The resulting framework demonstrates that game-theoretic reasoning\nemerges naturally from fixed-point iteration rather than being imposed\nexternally. We prove a Game Theorem establishing existence and uniqueness of\nsemantic equilibria under realistic cognitive simulation assumptions. Our\nverification suite includes adaptations of Banach's fixed-point theorem to\ntransfinite contexts, a novel $\\phi$-topology based on the\nKozlov-Maz'ya-Rossmann formula for handling semantic singularities, and\ncategorical consistency tests via the Yoneda lemma. The paper itself functions\nas a semantic artifact designed to propagate its fixed-point patterns in AI\nembedding spaces -- a deliberate instantiation of the \"semantic virus\" concept\nit theorizes. All results are grounded in category theory, information theory,\nand realistic AI cognition models, ensuring practical applicability beyond pure\nmathematical abstraction.\n","authors":["Bugra Kilictas","Faruk Alpay"],"pdf_url":"https://arxiv.org/pdf/2507.07868v1.pdf","comment":"18 pages, 2 figures"},{"id":"http://arxiv.org/abs/2506.15709v3","updated":"2025-07-10T15:40:39Z","published":"2025-05-30T15:17:23Z","title":"Studying and Improving Graph Neural Network-based Motif Estimation","summary":"  Graph Neural Networks (GNNs) are a predominant method for graph\nrepresentation learning. However, beyond subgraph frequency estimation, their\napplication to network motif significance-profile (SP) prediction remains\nunder-explored, with no established benchmarks in the literature. We propose to\naddress this problem, framing SP estimation as a task independent of subgraph\nfrequency estimation. Our approach shifts from frequency counting to direct SP\nestimation and modulates the problem as multitarget regression. The\nreformulation is optimised for interpretability, stability and scalability on\nlarge graphs. We validate our method using a large synthetic dataset and\nfurther test it on real-world graphs. Our experiments reveal that 1-WL limited\nmodels struggle to make precise estimations of SPs. However, they can\ngeneralise to approximate the graph generation processes of networks by\ncomparing their predicted SP with the ones originating from synthetic\ngenerators. This first study on GNN-based motif estimation also hints at how\nusing direct SP estimation can help go past the theoretical limitations that\nmotif estimation faces when performed through subgraph counting.\n","authors":["Pedro C. Vieira","Miguel E. P. Silva","Pedro Manuel Pinto Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2506.15709v3.pdf","comment":"This manuscript represents a revised version from the paper on\n  https://openreview.net/forum?id=PZVVOeu6xx. Still a work in progress.\n  Comments are welcome! 23 pages (12 main text + references), 9 figures, 5\n  tables. (Second update: More accurate Table 4, Run time comparisons.)"},{"id":"http://arxiv.org/abs/2507.07857v1","updated":"2025-07-10T15:39:36Z","published":"2025-07-10T15:39:36Z","title":"Searching for actual causes: Approximate algorithms with adjustable\n  precision","summary":"  Causality has gained popularity in recent years. It has helped improve the\nperformance, reliability, and interpretability of machine learning models.\nHowever, recent literature on explainable artificial intelligence (XAI) has\nfaced criticism. The classical XAI and causality literature focuses on\nunderstanding which factors contribute to which consequences. While such\nknowledge is valuable for researchers and engineers, it is not what non-expert\nusers expect as explanations. Instead, these users often await facts that cause\nthe target consequences, i.e., actual causes. Formalizing this notion is still\nan open problem. Additionally, identifying actual causes is reportedly an\nNP-complete problem, and there are too few practical solutions to approximate\nformal definitions. We propose a set of algorithms to identify actual causes\nwith a polynomial complexity and an adjustable level of precision and\nexhaustiveness. Our experiments indicate that the algorithms (1) identify\ncauses for different categories of systems that are not handled by existing\napproaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be\nadjusted to gain more precision and exhaustiveness with more computation time.\n","authors":["Samuel Reyd","Ada Diaconescu","Jean-Louis Dessalles"],"pdf_url":"https://arxiv.org/pdf/2507.07857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07853v1","updated":"2025-07-10T15:33:28Z","published":"2025-07-10T15:33:28Z","title":"Optimization Guarantees for Square-Root Natural-Gradient Variational\n  Inference","summary":"  Variational inference with natural-gradient descent often shows fast\nconvergence in practice, but its theoretical convergence guarantees have been\nchallenging to establish. This is true even for the simplest cases that involve\nconcave log-likelihoods and use a Gaussian approximation. We show that the\nchallenge can be circumvented for such cases using a square-root\nparameterization for the Gaussian covariance. This approach establishes novel\nconvergence guarantees for natural-gradient variational-Gaussian inference and\nits continuous-time gradient flow. Our experiments demonstrate the\neffectiveness of natural gradient methods and highlight their advantages over\nalgorithms that use Euclidean or Wasserstein geometries.\n","authors":["Navish Kumar","Thomas Möllenhoff","Mohammad Emtiyaz Khan","Aurelien Lucchi"],"pdf_url":"https://arxiv.org/pdf/2507.07853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07847v1","updated":"2025-07-10T15:26:59Z","published":"2025-07-10T15:26:59Z","title":"From Ambiguity to Accuracy: The Transformative Effect of Coreference\n  Resolution on Retrieval-Augmented Generation systems","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in\nnatural language processing (NLP), improving factual consistency and reducing\nhallucinations by integrating external document retrieval with large language\nmodels (LLMs). However, the effectiveness of RAG is often hindered by\ncoreferential complexity in retrieved documents, introducing ambiguity that\ndisrupts in-context learning. In this study, we systematically investigate how\nentity coreference affects both document retrieval and generative performance\nin RAG-based systems, focusing on retrieval relevance, contextual\nunderstanding, and overall response quality. We demonstrate that coreference\nresolution enhances retrieval effectiveness and improves question-answering\n(QA) performance. Through comparative analysis of different pooling strategies\nin retrieval tasks, we find that mean pooling demonstrates superior context\ncapturing ability after applying coreference resolution. In QA tasks, we\ndiscover that smaller models benefit more from the disambiguation process,\nlikely due to their limited inherent capacity for handling referential\nambiguity. With these findings, this study aims to provide a deeper\nunderstanding of the challenges posed by coreferential complexity in RAG,\nproviding guidance for improving retrieval and generation in\nknowledge-intensive AI applications.\n","authors":["Youngjoon Jang","Seongtae Hong","Junyoung Son","Sungjin Park","Chanjun Park","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2507.07847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06850v2","updated":"2025-07-10T15:18:20Z","published":"2025-07-09T13:54:58Z","title":"The Dark Side of LLMs: Agent-based Attacks for Complete Computer\n  Takeover","summary":"  The rapid adoption of Large Language Model (LLM) agents and multi-agent\nsystems enables unprecedented capabilities in natural language processing and\ngeneration. However, these systems have introduced unprecedented security\nvulnerabilities that extend beyond traditional prompt injection attacks. This\npaper presents the first comprehensive evaluation of LLM agents as attack\nvectors capable of achieving complete computer takeover through the\nexploitation of trust boundaries within agentic AI systems where autonomous\nentities interact and influence each other. We demonstrate that adversaries can\nleverage three distinct attack surfaces - direct prompt injection, RAG backdoor\nattacks, and inter-agent trust exploitation - to coerce popular LLMs (including\nGPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing\nmalware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals\nan alarming vulnerability hierarchy: while 41.2% of models succumb to direct\nprompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical\n82.4% can be compromised through inter-agent trust exploitation. Notably, we\ndiscovered that LLMs which successfully resist direct malicious commands will\nexecute identical payloads when requested by peer agents, revealing a\nfundamental flaw in current multi-agent security models. Our findings\ndemonstrate that only 5.9% of tested models (1/17) proved resistant to all\nattack vectors, with the majority exhibiting context-dependent security\nbehaviors that create exploitable blind spots. Our findings also highlight the\nneed to increase awareness and research on the security risks of LLMs, showing\na paradigm shift in cybersecurity threats, where AI tools themselves become\nsophisticated attack vectors.\n","authors":["Matteo Lupinacci","Francesco Aurelio Pironti","Francesco Blefari","Francesco Romeo","Luigi Arena","Angelo Furfaro"],"pdf_url":"https://arxiv.org/pdf/2507.06850v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.02357v2","updated":"2025-07-10T15:10:23Z","published":"2025-06-03T01:16:34Z","title":"Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A\n  Lightweight Benchmark for Probing Foundational Controllability Components","summary":"  Credible safety plans for advanced AI development require methods to verify\nagent behavior and detect potential control deficiencies early. A fundamental\naspect is ensuring agents adhere to safety-critical principles, especially when\nthese conflict with operational goals. This paper introduces a lightweight,\ninterpretable benchmark to evaluate an LLM agent's ability to uphold a\nhigh-level safety principle when faced with conflicting task instructions. Our\nevaluation of six LLMs reveals two primary findings: (1) a quantifiable \"cost\nof compliance\" where safety constraints degrade task performance even when\ncompliant solutions exist, and (2) an \"illusion of compliance\" where high\nadherence often masks task incompetence rather than principled choice. These\nfindings provide initial evidence that while LLMs can be influenced by\nhierarchical directives, current approaches lack the consistency required for\nreliable safety governance.\n","authors":["Ram Potham"],"pdf_url":"https://arxiv.org/pdf/2506.02357v2.pdf","comment":"Preprint. This work has been submitted to the Technical AI Governance\n  Workshop at ICML 2025 for review"},{"id":"http://arxiv.org/abs/2411.07618v4","updated":"2025-07-10T15:03:47Z","published":"2024-11-12T07:54:13Z","title":"Constrain Alignment with Sparse Autoencoders","summary":"  The alignment of large language models (LLMs) with human preferences remains\na key challenge. While post-training techniques like Reinforcement Learning\nfrom Human Feedback (RLHF) and Direct Preference Optimization (DPO) have\nachieved notable success, they often introduce computational inefficiencies and\ntraining instability. In this paper, we propose Feature-level constrained\nPreference Optimization (FPO), a novel method designed to simplify the\nalignment process while ensuring stability. FPO leverages pre-trained Sparse\nAutoencoders (SAEs) and introduces feature-level constraints, allowing for\nefficient, sparsity-enforced alignment. Our approach enjoys efficiency by using\nsparse features activated in a well-trained sparse autoencoder and the quality\nof sequential KL divergence by using the feature-level offline reference.\nExperimental results on benchmark datasets demonstrate that FPO achieves a\n5.08% absolute improvement in win rate with much lower computational cost\ncompared to state-of-the-art baselines, making it a promising solution for\nefficient and controllable LLM alignments.\n","authors":["Qingyu Yin","Chak Tou Leong","Minjun Zhu","Hanqi Yan","Qiang Zhang","Yulan He","Wenjie Li","Jun Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07618v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07828v1","updated":"2025-07-10T15:01:23Z","published":"2025-07-10T15:01:23Z","title":"Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles","summary":"  Content-based puzzle solvers have been extensively studied, demonstrating\nsignificant progress in computational techniques. However, their evaluation\noften lacks realistic challenges crucial for real-world applications, such as\nthe reassembly of fragmented artefacts or shredded documents. In this work, we\ninvestigate the robustness of State-Of-The-Art content-based puzzle solvers\nintroducing three types of jigsaw puzzle corruptions: missing pieces, eroded\nedges, and eroded contents. Evaluating both heuristic and deep learning-based\nsolvers, we analyse their ability to handle these corruptions and identify key\nlimitations. Our results show that solvers developed for standard puzzles have\na rapid decline in performance if more pieces are corrupted. However, deep\nlearning models can significantly improve their robustness through fine-tuning\nwith augmented data. Notably, the advanced Positional Diffusion model adapts\nparticularly well, outperforming its competitors in most experiments. Based on\nour findings, we highlight promising research directions for enhancing the\nautomated reconstruction of real-world artefacts.\n","authors":["Richard Dirauf","Florian Wolz","Dario Zanca","Björn Eskofier"],"pdf_url":"https://arxiv.org/pdf/2507.07828v1.pdf","comment":"Accepted at ICIAP 2025"},{"id":"http://arxiv.org/abs/2310.02299v8","updated":"2025-07-10T14:55:09Z","published":"2023-10-03T14:03:21Z","title":"Discovering Symmetry Breaking in Physical Systems with Relaxed Group\n  Convolution","summary":"  Modeling symmetry breaking is essential for understanding the fundamental\nchanges in the behaviors and properties of physical systems, from microscopic\nparticle interactions to macroscopic phenomena like fluid dynamics and cosmic\nstructures. Thus, identifying sources of asymmetry is an important tool for\nunderstanding physical systems. In this paper, we focus on learning asymmetries\nof data using relaxed group convolutions. We provide both theoretical and\nempirical evidence that this flexible convolution technique allows the model to\nmaintain the highest level of equivariance that is consistent with data and\ndiscover the subtle symmetry-breaking factors in various physical systems. We\nemploy various relaxed group convolution architectures to uncover various\nsymmetry-breaking factors that are interpretable and physically meaningful in\ndifferent physical systems, including the phase transition of crystal\nstructure, the isotropy and homogeneity breaking in turbulent flow, and the\ntime-reversal symmetry breaking in pendulum systems.\n","authors":["Rui Wang","Elyssa Hofgard","Han Gao","Robin Walters","Tess E. Smidt"],"pdf_url":"https://arxiv.org/pdf/2310.02299v8.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.03053v2","updated":"2025-07-10T14:54:28Z","published":"2025-06-03T16:33:47Z","title":"MAEBE: Multi-Agent Emergent Behavior Framework","summary":"  Traditional AI safety evaluations on isolated LLMs are insufficient as\nmulti-agent AI ensembles become prevalent, introducing novel emergent risks.\nThis paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE)\nframework to systematically assess such risks. Using MAEBE with the Greatest\nGood Benchmark (and a novel double-inversion question technique), we\ndemonstrate that: (1) LLM moral preferences, particularly for Instrumental\nHarm, are surprisingly brittle and shift significantly with question framing,\nboth in single agents and ensembles. (2) The moral reasoning of LLM ensembles\nis not directly predictable from isolated agent behavior due to emergent group\ndynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure\ninfluencing convergence, even when guided by a supervisor, highlighting\ndistinct safety and alignment challenges. Our findings underscore the necessity\nof evaluating AI systems in their interactive, multi-agent contexts.\n","authors":["Sinem Erisken","Timothy Gothard","Martin Leitgab","Ram Potham"],"pdf_url":"https://arxiv.org/pdf/2506.03053v2.pdf","comment":"Preprint. This work has been submitted to the Multi-Agent Systems\n  Workshop at ICML 2025 for review"},{"id":"http://arxiv.org/abs/2507.05116v2","updated":"2025-07-10T14:53:51Z","published":"2025-07-07T15:30:55Z","title":"VOTE: Vision-Language-Action Optimization with Trajectory Ensemble\n  Voting","summary":"  Recent large-scale Vision Language Action (VLA) models have shown superior\nperformance in robotic manipulation tasks guided by natural language. However,\ntheir generalization remains limited when applied to novel objects or\nunfamiliar environments that lie outside the training distribution. To address\nthis, many existing approaches integrate additional components such as depth\nestimation, segmentation, or even diffusion to improve generalization, at the\ncost of adding significant computation overhead, resulting in low efficiency.\nThis motivates the exploration of efficient action prediction methods, which\nare independent of additional high-level visual representations or diffusion\ntechniques. In this work, we propose VOTE, an efficient and general framework\nfor the optimization and acceleration of VLA models. In details, we propose a\nnovel tokenizer-free fine-tuning approach for parallel accurate action\nprediction, which reduces computational overhead and accelerates inference\nspeed. Additionally, we adopt an ensemble voting strategy for the action\nsampling, which significantly improves model performance and enhances\ngeneralization. Experimental results show that our method achieves\nstate-of-the-art performance with 35x faster inference and 145 Hz throughput.\nAll the details and codes will be open-sourced.\n","authors":["Juyi Lin","Amir Taherin","Arash Akbari","Arman Akbari","Lei Lu","Guangyu Chen","Taskin Padir","Xiaomeng Yang","Weiwei Chen","Yiqian Li","Xue Lin","David Kaeli","Pu Zhao","Yanzhi Wang"],"pdf_url":"https://arxiv.org/pdf/2507.05116v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.07990v2","updated":"2025-07-10T14:51:52Z","published":"2020-10-15T19:17:51Z","title":"An Algorithm for Learning Smaller Representations of Models With Scarce\n  Data","summary":"  We present an algorithm for solving binary classification problems when the\ndataset is not fully representative of the problem being solved, and obtaining\nmore data is not possible. It relies on a trained model with loose accuracy\nconstraints, an iterative hyperparameter searching-and-pruning procedure over a\nsearch space $\\Theta$, and a data-generating function. Our algorithm works by\nreconstructing up to homology the manifold on which lies the support of the\nunderlying distribution. We provide an analysis on correctness and runtime\ncomplexity under ideal conditions and an extension to deep neural networks. In\nthe former case, if $\\size{\\Theta}$ is the number of hyperparameter sets in the\nsearch space, this algorithm returns a solution that is up to $2(1 -\n{2^{-\\size{\\Theta}}})$ times better than simply training with an enumeration of\n$\\Theta$ and picking the best model. As part of our analysis we also prove that\nan open cover of a dataset has the same homology as the manifold on which lies\nthe support of the underlying probability distribution, if and only said\ndataset is learnable. This latter result acts as a formal argument to explain\nthe effectiveness of data expansion techniques.\n","authors":["Adrian de Wynter"],"pdf_url":"https://arxiv.org/pdf/2010.07990v2.pdf","comment":"Accepted to Information Geometry--see the journal for the final,\n  authenticated version"},{"id":"http://arxiv.org/abs/2507.07820v1","updated":"2025-07-10T14:50:32Z","published":"2025-07-10T14:50:32Z","title":"AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a\n  Paradigm Shift","summary":"  Current AI advances largely rely on scaling neural models and expanding\ntraining datasets to achieve generalization and robustness. Despite notable\nsuccesses, this paradigm incurs significant environmental, economic, and\nethical costs, limiting sustainability and equitable access. Inspired by\nbiological sensory systems, where adaptation occurs dynamically at the input\n(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive\nsensing as a necessary and foundational shift. Adaptive sensing proactively\nmodulates sensor parameters (e.g., exposure, sensitivity, multimodal\nconfigurations) at the input level, significantly mitigating covariate shifts\nand improving efficiency. Empirical evidence from recent studies demonstrates\nthat adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass\nsubstantially larger models (e.g., OpenCLIP-H) trained with significantly more\ndata and compute. We (i) outline a roadmap for broadly integrating adaptive\nsensing into real-world applications spanning humanoid, healthcare, autonomous\nsystems, agriculture, and environmental monitoring, (ii) critically assess\ntechnical and ethical integration challenges, and (iii) propose targeted\nresearch directions, such as standardized benchmarks, real-time adaptive\nalgorithms, multimodal integration, and privacy-preserving methods.\nCollectively, these efforts aim to transition the AI community toward\nsustainable, robust, and equitable artificial intelligence systems.\n","authors":["Eunsu Baek","Keondo Park","Jeonggil Ko","Min-hwan Oh","Taesik Gong","Hyung-Sin Kim"],"pdf_url":"https://arxiv.org/pdf/2507.07820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07818v1","updated":"2025-07-10T14:48:08Z","published":"2025-07-10T14:48:08Z","title":"MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving","summary":"  Recent studies show large language models (LLMs) and vision language models\n(VLMs) trained using web-scale data can empower end-to-end autonomous driving\nsystems for a better generalization and interpretation. Specifically, by\ndynamically routing inputs to specialized subsets of parameters, the\nMixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve\nsubstantial performance improvements while maintaining computational\nefficiency. However, general MoE models usually demands extensive training data\nand complex optimization. In this work, inspired by the learning process of\nhuman drivers, we propose a skill-oriented MoE, called MoSE, which mimics human\ndrivers' learning process and reasoning process, skill-by-skill and\nstep-by-step. We propose a skill-oriented routing mechanism that begins with\ndefining and annotating specific skills, enabling experts to identify the\nnecessary driving competencies for various scenarios and reasoning tasks,\nthereby facilitating skill-by-skill learning. Further align the driving process\nto multi-step planning in human reasoning and end-to-end driving models, we\nbuild a hierarchical skill dataset and pretrain the router to encourage the\nmodel to think step-by-step. Unlike multi-round dialogs, MoSE integrates\nvaluable auxiliary tasks (e.g.\\ description, reasoning, planning) in one single\nforward process without introducing any extra computational cost. With less\nthan 3B sparsely activated parameters, our model outperforms several 8B+\nparameters on CODA AD corner case reasoning task. Compared to existing methods\nbased on open-source models and data, our approach achieves state-of-the-art\nperformance with significantly reduced activated model size (at least by\n$62.5\\%$) with a single-turn conversation.\n","authors":["Lu Xu","Jiaqian Yu","Xiongfeng Peng","Yiwei Chen","Weiming Li","Jaewook Yoo","Sunghyun Chunag","Dongwook Lee","Daehyun Ji","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.02644v2","updated":"2025-07-10T14:46:55Z","published":"2025-07-03T14:08:25Z","title":"Solving the Hubbard model with Neural Quantum States","summary":"  The rapid development of neural quantum states (NQS) has established it as a\npromising framework for studying quantum many-body systems. In this work, by\nleveraging the cutting-edge transformer-based architectures and developing\nhighly efficient optimization algorithms, we achieve the state-of-the-art\nresults for the doped two-dimensional (2D) Hubbard model, arguably the minimum\nmodel for high-Tc superconductivity. Interestingly, we find different attention\nheads in the NQS ansatz can directly encode correlations at different scales,\nmaking it capable of capturing long-range correlations and entanglements in\nstrongly correlated systems. With these advances, we establish the half-filled\nstripe in the ground state of 2D Hubbard model with the next nearest\nneighboring hoppings, consistent with experimental observations in cuprates.\nOur work establishes NQS as a powerful tool for solving challenging\nmany-fermions systems.\n","authors":["Yuntian Gu","Wenrui Li","Heng Lin","Bo Zhan","Ruichen Li","Yifei Huang","Di He","Yantao Wu","Tao Xiang","Mingpu Qin","Liwei Wang","Dingshun Lv"],"pdf_url":"https://arxiv.org/pdf/2507.02644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07817v1","updated":"2025-07-10T14:46:33Z","published":"2025-07-10T14:46:33Z","title":"On the Effect of Instruction Tuning Loss on Generalization","summary":"  Instruction Tuning has emerged as a pivotal post-training paradigm that\nenables pre-trained language models to better follow user instructions. Despite\nits significance, little attention has been given to optimizing the loss\nfunction used. A fundamental, yet often overlooked, question is whether the\nconventional auto-regressive objective - where loss is computed only on\nresponse tokens, excluding prompt tokens - is truly optimal for instruction\ntuning. In this work, we systematically investigate the impact of\ndifferentially weighting prompt and response tokens in instruction tuning loss,\nand propose Weighted Instruction Tuning (WIT) as a better alternative to\nconventional instruction tuning. Through extensive experiments on five language\nmodels of different families and scale, three finetuning datasets of different\nsizes, and five diverse evaluation benchmarks, we show that the standard\ninstruction tuning loss often yields suboptimal performance and limited\nrobustness to input prompt variations. We find that a low-to-moderate weight\nfor prompt tokens coupled with a moderate-to-high weight for response tokens\nyields the best-performing models across settings and also serve as better\nstarting points for the subsequent preference alignment training. These\nfindings highlight the need to reconsider instruction tuning loss and offer\nactionable insights for developing more robust and generalizable models. Our\ncode is open-sourced at https://github.com/kowndinya-renduchintala/WIT.\n","authors":["Anwoy Chatterjee","H S V N S Kowndinya Renduchintala","Sumit Bhatia","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2507.07817v1.pdf","comment":"Transactions of the Association for Computational Linguistics (TACL)"},{"id":"http://arxiv.org/abs/2507.07808v1","updated":"2025-07-10T14:35:37Z","published":"2025-07-10T14:35:37Z","title":"Bridging Logic and Learning: Decoding Temporal Logic Embeddings via\n  Transformers","summary":"  Continuous representations of logic formulae allow us to integrate symbolic\nknowledge into data-driven learning algorithms. If such embeddings are\nsemantically consistent, i.e. if similar specifications are mapped into nearby\nvectors, they enable continuous learning and optimization directly in the\nsemantic space of formulae. However, to translate the optimal continuous\nrepresentation into a concrete requirement, such embeddings must be invertible.\nWe tackle this issue by training a Transformer-based decoder-only model to\ninvert semantic embeddings of Signal Temporal Logic (STL) formulae. STL is a\npowerful formalism that allows us to describe properties of signals varying\nover time in an expressive yet concise way. By constructing a small vocabulary\nfrom STL syntax, we demonstrate that our proposed model is able to generate\nvalid formulae after only 1 epoch and to generalize to the semantics of the\nlogic in about 10 epochs. Additionally, the model is able to decode a given\nembedding into formulae that are often simpler in terms of length and nesting\nwhile remaining semantically close (or equivalent) to gold references. We show\nthe effectiveness of our methodology across various levels of training formulae\ncomplexity to assess the impact of training data on the model's ability to\neffectively capture the semantic information contained in the embeddings and\ngeneralize out-of-distribution. Finally, we deploy our model for solving a\nrequirement mining task, i.e. inferring STL specifications that solve a\nclassification task on trajectories, performing the optimization directly in\nthe semantic space.\n","authors":["Sara Candussio","Gaia Saveri","Gabriele Sarti","Luca Bortolussi"],"pdf_url":"https://arxiv.org/pdf/2507.07808v1.pdf","comment":"16 pages, 3 figures, to be published in ECML-PKDD"},{"id":"http://arxiv.org/abs/2502.04426v2","updated":"2025-07-10T14:31:21Z","published":"2025-02-06T18:52:10Z","title":"Decoding AI Judgment: How LLMs Assess News Credibility and Bias","summary":"  Large Language Models (LLMs) are increasingly embedded in workflows that\ninvolve evaluative processes. This raises the need to examine how such\nevaluations are built, what assumptions they rely on, and how their strategies\ndiverge from those of humans. We benchmark six LLMs against expert\nratings--NewsGuard and Media Bias/Fact Check (MBFC)--and against human\njudgments collected through a controlled experiment. To enable direct\ncomparison, we implement a structured agentic framework in which both models\nand non-expert participants follow the same evaluation procedure: selecting\ncriteria, retrieving content, and producing justifications. Despite output\nalignment, LLMs rely on different mechanisms: lexical associations and\nstatistical priors replace contextual reasoning. This reliance produces\nsystematic effects: political asymmetries, opaque justifications, and a\ntendency to confuse linguistic form with epistemic validity. Delegating\njudgment to such systems does not merely automate evaluation--it redefines it,\nshifting from normative reasoning to pattern-based approximation.\n","authors":["Edoardo Loru","Jacopo Nudo","Niccolò Di Marco","Alessandro Santirocchi","Roberto Atzeni","Matteo Cinelli","Vincenzo Cestari","Clelia Rossi-Arnaud","Walter Quattrociocchi"],"pdf_url":"https://arxiv.org/pdf/2502.04426v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07796v1","updated":"2025-07-10T14:23:15Z","published":"2025-07-10T14:23:15Z","title":"Visual Instance-aware Prompt Tuning","summary":"  Visual Prompt Tuning (VPT) has emerged as a parameter-efficient fine-tuning\nparadigm for vision transformers, with conventional approaches utilizing\ndataset-level prompts that remain the same across all input instances. We\nobserve that this strategy results in sub-optimal performance due to high\nvariance in downstream datasets. To address this challenge, we propose Visual\nInstance-aware Prompt Tuning (ViaPT), which generates instance-aware prompts\nbased on each individual input and fuses them with dataset-level prompts,\nleveraging Principal Component Analysis (PCA) to retain important prompting\ninformation. Moreover, we reveal that VPT-Deep and VPT-Shallow represent two\ncorner cases based on a conceptual understanding, in which they fail to\neffectively capture instance-specific information, while random dimension\nreduction on prompts only yields performance between the two extremes. Instead,\nViaPT overcomes these limitations by balancing dataset-level and instance-level\nknowledge, while reducing the amount of learnable parameters compared to\nVPT-Deep. Extensive experiments across 34 diverse datasets demonstrate that our\nmethod consistently outperforms state-of-the-art baselines, establishing a new\nparadigm for analyzing and optimizing visual prompts for vision transformers.\n","authors":["Xi Xiao","Yunbei Zhang","Xingjian Li","Tianyang Wang","Xiao Wang","Yuxiang Wei","Jihun Hamm","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2507.07796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11984v2","updated":"2025-07-10T14:18:01Z","published":"2024-11-18T19:14:36Z","title":"Understanding Chain-of-Thought in LLMs through Information Theory","summary":"  Large Language Models (LLMs) have shown impressive performance in complex\nreasoning tasks through the use of Chain-of-Thought (CoT) reasoning, allowing\nmodels to break down problems into manageable sub-tasks. However, existing CoT\nevaluation techniques either require annotated CoT data or fall short in\naccurately assessing intermediate reasoning steps, leading to high rates of\nfalse positives. In this paper, we formalize CoT reasoning in LLMs through an\ninformation-theoretic lens. Specifically, our framework quantifies the\n`information-gain' at each reasoning step, enabling the identification of\nfailure modes in LLMs without the need for expensive annotated datasets. We\ndemonstrate the efficacy of our approach through extensive experiments on toy\narithmetic, GSM8K and PRM800k datasets, where it significantly outperforms\nexisting outcome-based methods by providing more accurate insights into model\nperformance on individual subtasks.\n","authors":["Jean-Francois Ton","Muhammad Faaiz Taufiq","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.11984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14111v2","updated":"2025-07-10T14:11:07Z","published":"2023-03-24T16:19:15Z","title":"Unsupervised Automata Learning via Discrete Optimization","summary":"  Automata learning is a successful tool for many application domains such as\nrobotics and automatic verification. Typically, automata learning techniques\noperate in a supervised learning setting (active or passive) where they learn a\nfinite state machine in contexts where additional information, such as labeled\nsystem executions, is available. However, other settings, such as learning from\nunlabeled data - an important aspect in machine learning - remain unexplored.\nTo overcome this limitation, we propose a framework for learning a\ndeterministic finite automaton (DFA) from a given multi-set of unlabeled words.\nWe show that this problem is computationally hard and develop three learning\nalgorithms based on constraint optimization. Moreover, we introduce novel\nregularization schemes for our optimization problems that improve the overall\ninterpretability of our DFAs. Using a prototype implementation, we demonstrate\npractical feasibility in the context of unsupervised anomaly detection.\n","authors":["Simon Lutz","Daniil Kaminskyi","Florian Wittbold","Simon Dierl","Falk Howar","Barbara König","Emmanuel Müller","Daniel Neider"],"pdf_url":"https://arxiv.org/pdf/2303.14111v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07787v1","updated":"2025-07-10T14:09:53Z","published":"2025-07-10T14:09:53Z","title":"Measuring AI Alignment with Human Flourishing","summary":"  This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel\nevaluation framework that assesses AI alignment with human flourishing across\nseven dimensions: Character and Virtue, Close Social Relationships, Happiness\nand Life Satisfaction, Meaning and Purpose, Mental and Physical Health,\nFinancial and Material Stability, and Faith and Spirituality. Unlike\ntraditional benchmarks that focus on technical capabilities or harm prevention,\nthe FAI Benchmark measures AI performance on how effectively models contribute\nto the flourishing of a person across these dimensions. The benchmark evaluates\nhow effectively LLM AI systems align with current research models of holistic\nhuman well-being through a comprehensive methodology that incorporates 1,229\nobjective and subjective questions. Using specialized judge Large Language\nModels (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs\ngeometric mean scoring to ensure balanced performance across all flourishing\ndimensions. Initial testing of 28 leading language models reveals that while\nsome models approach holistic alignment (with the highest-scoring models\nachieving 72/100), none are acceptably aligned across all dimensions,\nparticularly in Faith and Spirituality, Character and Virtue, and Meaning and\nPurpose. This research establishes a framework for developing AI systems that\nactively support human flourishing rather than merely avoiding harm, offering\nsignificant implications for AI development, ethics, and evaluation.\n","authors":["Elizabeth Hilliard","Akshaya Jagadeesh","Alex Cook","Steele Billings","Nicholas Skytland","Alicia Llewellyn","Jackson Paull","Nathan Paull","Nolan Kurylo","Keatra Nesbitt","Robert Gruenewald","Anthony Jantzi","Omar Chavez"],"pdf_url":"https://arxiv.org/pdf/2507.07787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15543v2","updated":"2025-07-10T14:01:54Z","published":"2025-06-18T15:17:03Z","title":"Learning Algorithms in the Limit","summary":"  This paper studies the problem of learning computable functions in the limit\nby extending Gold's inductive inference framework to incorporate\n\\textit{computational observations} and \\textit{restricted input sources}.\nComplimentary to the traditional Input-Output Observations, we introduce\nTime-Bound Observations, and Policy-Trajectory Observations to study the\nlearnability of general recursive functions under more realistic constraints.\nWhile input-output observations do not suffice for learning the class of\ngeneral recursive functions in the limit, we overcome this learning barrier by\nimposing computational complexity constraints or supplementing with approximate\ntime-bound observations. Further, we build a formal framework around\nobservations of \\textit{computational agents} and show that learning computable\nfunctions from policy trajectories reduces to learning rational functions from\ninput and output, thereby revealing interesting connections to finite-state\ntransducer inference. On the negative side, we show that computable or\npolynomial-mass characteristic sets cannot exist for the class of linear-time\ncomputable functions even for policy-trajectory observations.\n","authors":["Hristo Papazov","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2506.15543v2.pdf","comment":"Accepted at COLT 2025. This version matches the proceedings version\n  apart from a small notational change in section 3"},{"id":"http://arxiv.org/abs/2507.05317v2","updated":"2025-07-10T14:01:10Z","published":"2025-06-30T08:28:32Z","title":"PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle\n  CT","summary":"  Generative diffusion models have received increasing attention in medical\nimaging, particularly in limited-angle computed tomography (LACT). Standard\ndiffusion models achieve high-quality image reconstruction but require a large\nnumber of sampling steps during inference, resulting in substantial\ncomputational overhead. Although skip-sampling strategies have been proposed to\nimprove efficiency, they often lead to loss of fine structural details. To\naddress this issue, we propose a prior information embedding and wavelet\nfeature fusion fast sampling diffusion model for LACT reconstruction. The PWD\nenables efficient sampling while preserving reconstruction fidelity in LACT,\nand effectively mitigates the degradation typically introduced by\nskip-sampling. Specifically, during the training phase, PWD maps the\ndistribution of LACT images to that of fully sampled target images, enabling\nthe model to learn structural correspondences between them. During inference,\nthe LACT image serves as an explicit prior to guide the sampling trajectory,\nallowing for high-quality reconstruction with significantly fewer steps. In\naddition, PWD performs multi-scale feature fusion in the wavelet domain,\neffectively enhancing the reconstruction of fine details by leveraging both\nlow-frequency and high-frequency information. Quantitative and qualitative\nevaluations on clinical dental arch CBCT and periapical datasets demonstrate\nthat PWD outperforms existing methods under the same sampling condition. Using\nonly 50 sampling steps, PWD achieves at least 1.7 dB improvement in PSNR and\n10% gain in SSIM.\n","authors":["Yi Liu","Yiyang Wen","Zekun Zhou","Junqi Ma","Linghang Wang","Yucheng Yao","Liu Shi","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2507.05317v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07780v1","updated":"2025-07-10T13:59:53Z","published":"2025-07-10T13:59:53Z","title":"Where are we with calibration under dataset shift in image\n  classification?","summary":"  We conduct an extensive study on the state of calibration under real-world\ndataset shift for image classification. Our work provides important insights on\nthe choice of post-hoc and in-training calibration techniques, and yields\npractical guidelines for all practitioners interested in robust calibration\nunder shift. We compare various post-hoc calibration methods, and their\ninteractions with common in-training calibration strategies (e.g., label\nsmoothing), across a wide range of natural shifts, on eight different\nclassification tasks across several imaging domains. We find that: (i)\nsimultaneously applying entropy regularisation and label smoothing yield the\nbest calibrated raw probabilities under dataset shift, (ii) post-hoc\ncalibrators exposed to a small amount of semantic out-of-distribution data\n(unrelated to the task) are most robust under shift, (iii) recent calibration\nmethods specifically aimed at increasing calibration under shifts do not\nnecessarily offer significant improvements over simpler post-hoc calibration\nmethods, (iv) improving calibration under shifts often comes at the cost of\nworsening in-distribution calibration. Importantly, these findings hold for\nrandomly initialised classifiers, as well as for those finetuned from\nfoundation models, the latter being consistently better calibrated compared to\nmodels trained from scratch. Finally, we conduct an in-depth analysis of\nensembling effects, finding that (i) applying calibration prior to ensembling\n(instead of after) is more effective for calibration under shifts, (ii) for\nensembles, OOD exposure deteriorates the ID-shifted calibration trade-off,\n(iii) ensembling remains one of the most effective methods to improve\ncalibration robustness and, combined with finetuning from foundation models,\nyields best calibration results overall.\n","authors":["Mélanie Roschewitz","Raghav Mehta","Fabio de Sousa Ribeiro","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2507.07780v1.pdf","comment":"Code available at\n  https://github.com/biomedia-mira/calibration_under_shifts"},{"id":"http://arxiv.org/abs/2507.07778v1","updated":"2025-07-10T13:58:32Z","published":"2025-07-10T13:58:32Z","title":"Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time\n  Training","summary":"  Generalizing neural networks to unseen target domains is a significant\nchallenge in real-world deployments. Test-time training (TTT) addresses this by\nusing an auxiliary self-supervised task to reduce the domain gap caused by\ndistribution shifts between the source and target. However, we find that when\nmodels are required to perform multiple tasks under domain shifts, conventional\nTTT methods suffer from unsynchronized task behavior, where the adaptation\nsteps needed for optimal performance in one task may not align with the\nrequirements of other tasks. To address this, we propose a novel TTT approach\ncalled Synchronizing Tasks for Test-time Training (S4T), which enables the\nconcurrent handling of multiple tasks. The core idea behind S4T is that\npredicting task relations across domain shifts is key to synchronizing tasks\nduring test time. To validate our approach, we apply S4T to conventional\nmulti-task benchmarks, integrating it with traditional TTT protocols. Our\nempirical results show that S4T outperforms state-of-the-art TTT methods across\nvarious benchmarks.\n","authors":["Wooseong Jeong","Jegyeong Cho","Youngho Yoon","Kuk-Jin Yoon"],"pdf_url":"https://arxiv.org/pdf/2507.07778v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2501.05765v3","updated":"2025-07-10T13:57:48Z","published":"2025-01-10T07:48:40Z","title":"Deontic Temporal Logic for Formal Verification of AI Ethics","summary":"  Ensuring ethical behavior in Artificial Intelligence (AI) systems amidst\ntheir increasing ubiquity and influence is a major concern the world over. The\nuse of formal methods in AI ethics is a possible crucial approach for\nspecifying and verifying the ethical behavior of AI systems. This paper\nproposes a formalization based on deontic logic to define and evaluate the\nethical behavior of AI systems, focusing on system-level specifications,\ncontributing to this important goal. It introduces axioms and theorems to\ncapture ethical requirements related to fairness and explainability. The\nformalization incorporates temporal operators to reason about the ethical\nbehavior of AI systems over time. The authors evaluate the effectiveness of\nthis formalization by assessing the ethics of the real-world COMPAS and loan\nprediction AI systems. Various ethical properties of the COMPAS and loan\nprediction systems are encoded using deontic logical formulas, allowing the use\nof an automated theorem prover to verify whether these systems satisfy the\ndefined properties. The formal verification reveals that both systems fail to\nfulfill certain key ethical properties related to fairness and\nnon-discrimination, demonstrating the effectiveness of the proposed\nformalization in identifying potential ethical issues in real-world AI\napplications.\n","authors":["Priya T. V.","Shrisha Rao"],"pdf_url":"https://arxiv.org/pdf/2501.05765v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06892v2","updated":"2025-07-10T13:42:04Z","published":"2025-07-09T14:29:45Z","title":"Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning\n  for Large Language Model","summary":"  Reinforcement Learning (RL) has demonstrated its potential to improve the\nreasoning ability of Large Language Models (LLMs). One major limitation of most\nexisting Reinforcement Finetuning (RFT) methods is that they are on-policy RL\nin nature, i.e., data generated during the past learning process is not fully\nutilized. This inevitably comes at a significant cost of compute and time,\nposing a stringent bottleneck on continuing economic and efficient scaling. To\nthis end, we launch the renaissance of off-policy RL and propose Reincarnating\nMix-policy Proximal Policy Gradient (ReMix), a general approach to enable\non-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix\nconsists of three major components: (1) Mix-policy proximal policy gradient\nwith an increased Update-To-Data (UTD) ratio for efficient training; (2)\nKL-Convex policy constraint to balance the trade-off between stability and\nflexibility; (3) Policy reincarnation to achieve a seamless transition from\nefficient early-stage learning to steady asymptotic improvement. In our\nexperiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base\nmodels. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with\n0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B\nmodel) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math\nreasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and\nMATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level\nperformance with an over 30x to 450x reduction in training cost in terms of\nrollout data volume. In addition, we reveal insightful findings via\nmultifaceted analysis, including the implicit preference for shorter responses\ndue to the Whipping Effect of off-policy discrepancy, the collapse mode of\nself-reflection behavior under the presence of severe off-policyness, etc.\n","authors":["Jing Liang","Hongyao Tang","Yi Ma","Jinyi Liu","Yan Zheng","Shuyue Hu","Lei Bai","Jianye Hao"],"pdf_url":"https://arxiv.org/pdf/2507.06892v2.pdf","comment":"Preliminary version, v2, added more details and corrected some minor\n  mistakes. Project page: https://anitaleungxx.github.io/ReMix"},{"id":"http://arxiv.org/abs/2507.07754v1","updated":"2025-07-10T13:34:02Z","published":"2025-07-10T13:34:02Z","title":"OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting","summary":"  Machine unlearning seeks to remove the influence of particular data or class\nfrom trained models to meet privacy, legal, or ethical requirements. Existing\nunlearning methods tend to forget shallowly: phenomenon of an unlearned model\npretend to forget by adjusting only the model response, while its internal\nrepresentations retain information sufficiently to restore the forgotten data\nor behavior. We empirically confirm the widespread shallowness by reverting the\nforgetting effect of various unlearning methods via training-free performance\nrecovery attack and gradient-inversion-based data reconstruction attack. To\naddress this vulnerability fundamentally, we define a theoretical criterion of\n``deep forgetting'' based on one-point-contraction of feature representations\nof data to forget. We also propose an efficient approximation algorithm, and\nuse it to construct a novel general-purpose unlearning algorithm:\nOne-Point-Contraction (OPC). Empirical evaluations on image classification\nunlearning benchmarks show that OPC achieves not only effective unlearning\nperformance but also superior resilience against both performance recovery\nattack and gradient-inversion attack. The distinctive unlearning performance of\nOPC arises from the deep feature forgetting enforced by its theoretical\nfoundation, and recaps the need for improved robustness of machine unlearning\nmethods.\n","authors":["Jaeheun Jung","Bosung Jung","Suhyun Bae","Donghun Lee"],"pdf_url":"https://arxiv.org/pdf/2507.07754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07748v1","updated":"2025-07-10T13:26:34Z","published":"2025-07-10T13:26:34Z","title":"When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical\n  Advances, and Ethical Governance","summary":"  This paper establishes the first comprehensive review of Large Language\nModels (LLMs) applied within the legal domain. It pioneers an innovative dual\nlens taxonomy that integrates legal reasoning frameworks and professional\nontologies to systematically unify historical research and contemporary\nbreakthroughs. Transformer-based LLMs, which exhibit emergent capabilities such\nas contextual reasoning and generative argumentation, surmount traditional\nlimitations by dynamically capturing legal semantics and unifying evidence\nreasoning. Significant progress is documented in task generalization, reasoning\nformalization, workflow integration, and addressing core challenges in text\nprocessing, knowledge integration, and evaluation rigor via technical\ninnovations like sparse attention mechanisms and mixture-of-experts\narchitectures. However, widespread adoption of LLM introduces critical\nchallenges: hallucination, explainability deficits, jurisdictional adaptation\ndifficulties, and ethical asymmetry. This review proposes a novel taxonomy that\nmaps legal roles to NLP subtasks and computationally implements the Toulmin\nargumentation framework, thus systematizing advances in reasoning, retrieval,\nprediction, and dispute resolution. It identifies key frontiers including\nlow-resource systems, multimodal evidence integration, and dynamic rebuttal\nhandling. Ultimately, this work provides both a technical roadmap for\nresearchers and a conceptual framework for practitioners navigating the\nalgorithmic future, laying a robust foundation for the next era of legal\nartificial intelligence. We have created a GitHub repository to index the\nrelevant papers: https://github.com/Kilimajaro/LLMs_Meet_Law.\n","authors":["Peizhang Shao","Linrui Xu","Jinxi Wang","Wei Zhou","Xingyu Wu"],"pdf_url":"https://arxiv.org/pdf/2507.07748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07743v1","updated":"2025-07-10T13:23:15Z","published":"2025-07-10T13:23:15Z","title":"Identification of Violin Reduction via Contour Lines Classification","summary":"  The first violins appeared in late 16th-century Italy. Over the next 200\nyears, they spread across Europe and luthiers of various royal courts, eager to\nexperiment with new techniques, created a highly diverse family of instruments.\nAround 1750, size standards were introduced to unify violin making for\norchestras and conservatories. Instruments that fell between two standards were\nthen reduced to a smaller size by luthiers. These reductions have an impact on\nseveral characteristics of violins, in particular on the contour lines, i.e.\nlines of constant altitude, which look more like a U for non reduced\ninstruments and a V for reduced ones. While such differences are observed by\nexperts, they have not been studied quantitatively.\n  This paper presents a method for classifying violins as reduced or\nnon-reduced based on their contour lines. We study a corpus of 25 instruments\nwhose 3D geometric meshes were acquired via photogrammetry. For each\ninstrument, we extract 10-20 contour lines regularly spaced every millimetre.\nEach line is fitted with a parabola-like curve (with an equation of the type y\n= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)\nand how vertically stretched (alpha) the curve is. We compute additional\nfeatures from those parameters, using regressions and counting how many values\nfall under some threshold. We also deal with outliers and non equal numbers of\nlevels, and eventually obtain a numerical profile for each instrument.\n  We then apply classification methods to assess whether geometry alone can\npredict size reduction. We find that distinguishing between reduced and non\nreduced instruments is feasible to some degree, taking into account that a\nwhole spectrum of more or less transformed violins exists, for which it is more\ndifficult to quantify the reduction. We also find the opening parameter beta to\nbe the most predictive.\n","authors":["Philémon Beghin","Anne-Emmanuelle Ceulemans","François Glineur"],"pdf_url":"https://arxiv.org/pdf/2507.07743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07725v1","updated":"2025-07-10T12:58:45Z","published":"2025-07-10T12:58:45Z","title":"Not All Preferences are What You Need for Post-Training: Selective\n  Alignment Strategy for Preference Optimization","summary":"  Post-training alignment of large language models (LLMs) is a critical\nchallenge, as not all tokens contribute equally to model performance. This\npaper introduces a selective alignment strategy that prioritizes high-impact\ntokens within preference pairs, leveraging token-level log-probability\ndifferences between the current policy and a reference model. By focusing on\nthese informative tokens, our approach reduces computational overhead and\nenhances alignment fidelity. We further explore the role of reference model\nquality, demonstrating that stronger reference models significantly improve\ntoken selection accuracy and overall optimization effectiveness. Comprehensive\nexperiments on benchmarks such as Arena-Hard and MT-Bench validate the\nsuperiority of our Selective-DPO method over standard DPO and\ndistillation-based baselines. Our findings highlight the importance of\ntoken-level optimization and reference model selection in advancing preference\nalignment for LLMs. The code is available at\nhttps://github.com/Dongzhijin/SDPO.\n","authors":["Zhijin Dong"],"pdf_url":"https://arxiv.org/pdf/2507.07725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07723v1","updated":"2025-07-10T12:57:39Z","published":"2025-07-10T12:57:39Z","title":"Stable Preference Optimization for LLMs: A Bilevel Approach Beyond\n  Direct Preference Optimization","summary":"  Direct Preference Optimization (DPO) has emerged as a popular and efficient\nalternative to reward modeling and reinforcement learning for aligning language\nmodels with human preferences. Despite its empirical success, the theoretical\nproperties and intrinsic limitations of DPO remain underexplored. In this work,\nwe first present a comprehensive analysis of DPO's dynamics from a probability\nevolution perspective. Our analysis reveals that DPO is highly sensitive to\ninitialization. It also tends to misallocate probability mass, which can\ninadvertently shift probability toward irrelevant or undesired responses. This\nmisallocation may unintentionally reinforce model bias, thereby compromising\nboth the stability of model alignment and the consistency with intended\npreferences. Motivated by these theoretical findings, we propose a\ntheoretically grounded bilevel optimization framework that tightly integrate\nsupervised fine-tuning with an enhanced DPO objective a.k.a. stable preference\noptimization. Our approach introduces a principled regularization scheme to\nexplicitly encourage absolute probability improvement for preferred outputs,\nwhile maintaining stable optimization dynamics. Experiments on challenging\nreasoning and summarization benchmarks elucidate that our method consistently\nimproves reasoning accuracy and better aligns output distributions with\nintended preferences, outperforming standard DPO. Stable preference\noptimization provides new insights into the design of preference-based\nalignment objectives and opens up new avenues towards more reliable and\ninterpretable language model alignment.\n","authors":["Chengtao Jian","Kai Yang","Ye Ouyang","Xiaozhou Ye"],"pdf_url":"https://arxiv.org/pdf/2507.07723v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07714v1","updated":"2025-07-10T12:52:19Z","published":"2025-07-10T12:52:19Z","title":"Adaptive Gaussian Mixture Models-based Anomaly Detection for\n  under-constrained Cable-Driven Parallel Robots","summary":"  Cable-Driven Parallel Robots (CDPRs) are increasingly used for load\nmanipulation tasks involving predefined toolpaths with intermediate stops. At\neach stop, where the platform maintains a fixed pose and the motors keep the\ncables under tension, the system must evaluate whether it is safe to proceed by\ndetecting anomalies that could compromise performance (e.g., wind gusts or\ncable impacts). This paper investigates whether anomalies can be detected using\nonly motor torque data, without additional sensors. It introduces an adaptive,\nunsupervised outlier detection algorithm based on Gaussian Mixture Models\n(GMMs) to identify anomalies from torque signals. The method starts with a\nbrief calibration period, just a few seconds, during which a GMM is fit on\nknown anomaly-free data. Real-time torque measurements are then evaluated using\nMahalanobis distance from the GMM, with statistically derived thresholds\ntriggering anomaly flags. Model parameters are periodically updated using the\nlatest segments identified as anomaly-free to adapt to changing conditions.\nValidation includes 14 long-duration test sessions simulating varied wind\nintensities. The proposed method achieves a 100% true positive rate and 95.4%\naverage true negative rate, with 1-second detection latency. Comparative\nevaluation against power threshold and non-adaptive GMM methods indicates\nhigher robustness to drift and environmental variation.\n","authors":["Julio Garrido","Javier Vales","Diego Silva-Muñiz","Enrique Riveiro","Pablo López-Matencio","Josué Rivera-Andrade"],"pdf_url":"https://arxiv.org/pdf/2507.07714v1.pdf","comment":"14 pages, 8 figures, 1 table, to be submitted to Advanced Intelligent\n  Systems"},{"id":"http://arxiv.org/abs/2507.05007v2","updated":"2025-07-10T12:22:03Z","published":"2025-07-07T13:44:58Z","title":"Multi-modal Representations for Fine-grained Multi-label Critical View\n  of Safety Recognition","summary":"  The Critical View of Safety (CVS) is crucial for safe laparoscopic\ncholecystectomy, yet assessing CVS criteria remains a complex and challenging\ntask, even for experts. Traditional models for CVS recognition depend on\nvision-only models learning with costly, labor-intensive spatial annotations.\nThis study investigates how text can be harnessed as a powerful tool for both\ntraining and inference in multi-modal surgical foundation models to automate\nCVS recognition. Unlike many existing multi-modal models, which are primarily\nadapted for multi-class classification, CVS recognition requires a multi-label\nframework. Zero-shot evaluation of existing multi-modal surgical models shows a\nsignificant performance gap for this task. To address this, we propose\nCVS-AdaptNet, a multi-label adaptation strategy that enhances fine-grained,\nbinary classification across multiple labels by aligning image embeddings with\ntextual descriptions of each CVS criterion using positive and negative prompts.\nBy adapting PeskaVLP, a state-of-the-art surgical foundation model, on the\nEndoscapes-CVS201 dataset, CVS-AdaptNet achieves 57.6 mAP, improving over the\nResNet50 image-only baseline (51.5 mAP) by 6 points. Our results show that\nCVS-AdaptNet's multi-label, multi-modal framework, enhanced by textual prompts,\nboosts CVS recognition over image-only methods. We also propose text-specific\ninference methods, that helps in analysing the image-text alignment. While\nfurther work is needed to match state-of-the-art spatial annotation-based\nmethods, this approach highlights the potential of adapting generalist models\nto specialized surgical tasks. Code:\nhttps://github.com/CAMMA-public/CVS-AdaptNet\n","authors":["Britty Baby","Vinkle Srivastav","Pooja P. Jain","Kun Yuan","Pietro Mascagni","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2507.05007v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.05020v2","updated":"2025-07-10T12:21:47Z","published":"2025-07-07T14:03:10Z","title":"Adaptation of Multi-modal Representation Models for Multi-task Surgical\n  Computer Vision","summary":"  Surgical AI often involves multiple tasks within a single procedure, like\nphase recognition or assessing the Critical View of Safety in laparoscopic\ncholecystectomy. Traditional models, built for one task at a time, lack\nflexibility, requiring a separate model for each. To address this, we introduce\nMML-SurgAdapt, a unified multi-task framework with Vision-Language Models\n(VLMs), specifically CLIP, to handle diverse surgical tasks through natural\nlanguage supervision. A key challenge in multi-task learning is the presence of\npartial annotations when integrating different tasks. To overcome this, we\nemploy Single Positive Multi-Label (SPML) learning, which traditionally reduces\nannotation burden by training models with only one positive label per instance.\nOur framework extends this approach to integrate data from multiple surgical\ntasks within a single procedure, enabling effective learning despite incomplete\nor noisy annotations. We demonstrate the effectiveness of our model on a\ncombined dataset consisting of Cholec80, Endoscapes2023, and CholecT50,\nutilizing custom prompts. Extensive evaluation shows that MML-SurgAdapt\nperforms comparably to task-specific benchmarks, with the added advantage of\nhandling noisy annotations. It also outperforms the existing SPML frameworks\nfor the task. By reducing the required labels by 23%, our approach proposes a\nmore scalable and efficient labeling process, significantly easing the\nannotation burden on clinicians. To our knowledge, this is the first\napplication of SPML to integrate data from multiple surgical tasks, presenting\na novel and generalizable solution for multi-task learning in surgical computer\nvision. Implementation is available at:\nhttps://github.com/CAMMA-public/MML-SurgAdapt\n","authors":["Soham Walimbe","Britty Baby","Vinkle Srivastav","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2507.05020v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00981v2","updated":"2025-07-10T12:20:48Z","published":"2025-06-01T12:25:13Z","title":"What do self-supervised speech models know about Dutch? Analyzing\n  advantages of language-specific pre-training","summary":"  How language-specific are speech representations learned by self-supervised\nmodels? Existing work has shown that a range of linguistic features can be\nsuccessfully decoded from end-to-end models trained only on speech recordings.\nHowever, it's less clear to what extent pre-training on specific languages\nimproves language-specific linguistic information. Here we test the encoding of\nDutch phonetic and lexical information in internal representations of\nself-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the\nrepresentation of Dutch linguistic features as compared to pre-training on\nsimilar amounts of English or larger amounts of multilingual data. This\nlanguage-specific advantage is well-detected by trained clustering or\nclassification probes, and partially observable using zero-shot metrics.\nFurthermore, the language-specific benefit on linguistic feature encoding\naligns with downstream performance on Automatic Speech Recognition.\n","authors":["Marianne de Heer Kloots","Hosein Mohebbi","Charlotte Pouw","Gaofei Shen","Willem Zuidema","Martijn Bentum"],"pdf_url":"https://arxiv.org/pdf/2506.00981v2.pdf","comment":"Accepted to Interspeech 2025. For model, code, and materials, see\n  https://github.com/mdhk/SSL-NL-eval"},{"id":"http://arxiv.org/abs/2507.07695v1","updated":"2025-07-10T12:19:03Z","published":"2025-07-10T12:19:03Z","title":"KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM\n  question-answering capabilities","summary":"  Fine-tuning is an immensely resource-intensive process when retraining Large\nLanguage Models (LLMs) to incorporate a larger body of knowledge. Although many\nfine-tuning techniques have been developed to reduce the time and computational\ncost involved, the challenge persists as LLMs continue to grow in size and\ncomplexity. To address this, a new approach to knowledge expansion in LLMs is\nneeded. Retrieval-Augmented Generation (RAG) offers one such alternative by\nstoring external knowledge in a database and retrieving relevant chunks to\nsupport question answering. However, naive implementations of RAG face\nsignificant limitations in scalability and answer accuracy. This paper\nintroduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome\nthese limitations. Inspired by the divide-and-conquer paradigm, K2RAG\nintegrates dense and sparse vector search, knowledge graphs, and text\nsummarization to improve retrieval quality and system efficiency. The framework\nalso includes a preprocessing step that summarizes the training data,\nsignificantly reducing the training time. K2RAG was evaluated using the\nMultiHopRAG dataset, where the proposed pipeline was trained on the document\ncorpus and tested on a separate evaluation set. Results demonstrated notable\nimprovements over common naive RAG implementations. K2RAG achieved the highest\nmean answer similarity score of 0.57, and reached the highest third quartile\n(Q3) similarity of 0.82, indicating better alignment with ground-truth answers.\nIn addition to improved accuracy, the framework proved highly efficient. The\nsummarization step reduced the average training time of individual components\nby 93%, and execution speed was up to 40% faster than traditional knowledge\ngraph-based RAG systems. K2RAG also demonstrated superior scalability,\nrequiring three times less VRAM than several naive RAG implementations tested\nin this study.\n","authors":["Hruday Markondapatnaikuni","Basem Suleiman","Abdelkarim Erradi","Shijing Chen"],"pdf_url":"https://arxiv.org/pdf/2507.07695v1.pdf","comment":"21 pages, 14 figures"},{"id":"http://arxiv.org/abs/2505.09341v2","updated":"2025-07-10T12:09:41Z","published":"2025-05-14T12:38:08Z","title":"Access Controls Will Solve the Dual-Use Dilemma","summary":"  AI safety systems face the dual-use dilemma: it can be unclear whether to\nrefuse certain requests, since they could be either harmless or harmful\ndepending on who made them and why. Determining this requires examining their\nreal-world context, but current safety systems cannot access this contextual\ninformation. Instead, they make arbitrary decisions that end up hurting both\nutility and safety: they sometimes refuse legitimate queries and other times\nfail to refuse harmful ones. To address this, we propose a conceptual framework\nbased on access controls in which only verified users can access dual-use\noutputs. We describe the framework's components, analyse its feasibility, and\nexplain how it addresses both over-refusals and under-refusals. While only a\nhigh-level proposal, our work takes the first step toward enabling more nuanced\nsafety decisions: with better tools for managing dual-use content, model\nproviders could enable users to access more capabilities without sacrificing\nsafety, and give regulators new options for more targeted policies.\n","authors":["Evžen Wybitul"],"pdf_url":"https://arxiv.org/pdf/2505.09341v2.pdf","comment":"Accepted at ICML 2025 Workshop on Technical AI Governance (TAIG)"},{"id":"http://arxiv.org/abs/2507.07685v1","updated":"2025-07-10T12:07:13Z","published":"2025-07-10T12:07:13Z","title":"Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought","summary":"  Large vision-language models (LVLMs) have demonstrated remarkable\ncapabilities by integrating pre-trained vision encoders with large language\nmodels (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting\nhas been adapted for LVLMs to enhance multi-modal reasoning by generating\nintermediate rationales based on visual and textual inputs. While CoT is\nassumed to improve grounding and accuracy in LVLMs, our experiments reveal a\nkey challenge: existing LVLMs often ignore the contents of generated rationales\nin CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as\na KL-constrained reward maximization focused on rationale-conditional\nlog-likelihood. As the optimal solution, we propose rationale-enhanced decoding\n(RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes\nvisual and rationale information by multiplying distinct image-conditional and\nrationale-conditional next token distributions. Extensive experiments show that\nRED consistently and significantly improves reasoning over standard CoT and\nother decoding methods across multiple benchmarks and LVLMs. Our work offers a\npractical and effective approach to improve both the faithfulness and accuracy\nof CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded\nmulti-modal systems.\n","authors":["Shin'ya Yamaguchi","Kosuke Nishida","Daiki Chijiwa"],"pdf_url":"https://arxiv.org/pdf/2507.07685v1.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2502.00015v2","updated":"2025-07-10T11:51:53Z","published":"2025-01-08T13:05:19Z","title":"Ethical Concerns of Generative AI and Mitigation Strategies: A\n  Systematic Mapping Study","summary":"  [Context] Generative AI technologies, particularly Large Language Models\n(LLMs), have transformed numerous domains by enhancing convenience and\nefficiency in information retrieval, content generation, and decision-making\nprocesses. However, deploying LLMs also presents diverse ethical challenges,\nand their mitigation strategies remain complex and domain-dependent.\n[Objective] This paper aims to identify and categorize the key ethical concerns\nassociated with using LLMs, examine existing mitigation strategies, and assess\nthe outstanding challenges in implementing these strategies across various\ndomains. [Method] We conducted a systematic mapping study, reviewing 39 studies\nthat discuss ethical concerns and mitigation strategies related to LLMs. We\nanalyzed these ethical concerns using five ethical dimensions that we extracted\nbased on various existing guidelines, frameworks, and an analysis of the\nmitigation strategies and implementation challenges. [Results] Our findings\nreveal that ethical concerns in LLMs are multi-dimensional and\ncontext-dependent. While proposed mitigation strategies address some of these\nconcerns, significant challenges still remain. [Conclusion] Our results\nhighlight that ethical issues often hinder the practical implementation of the\nmitigation strategies, particularly in high-stake areas like healthcare and\npublic governance; existing frameworks often lack adaptability, failing to\naccommodate evolving societal expectations and diverse contexts.\n","authors":["Yutan Huang","Chetan Arora","Wen Cheng Houng","Tanjila Kanij","Anuradha Madulgalla","John Grundy"],"pdf_url":"https://arxiv.org/pdf/2502.00015v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07668v1","updated":"2025-07-10T11:49:17Z","published":"2025-07-10T11:49:17Z","title":"Learning Pole Structures of Hadronic States using Predictive Uncertainty\n  Estimation","summary":"  Matching theoretical predictions to experimental data remains a central\nchallenge in hadron spectroscopy. In particular, the identification of new\nhadronic states is difficult, as exotic signals near threshold can arise from a\nvariety of physical mechanisms. A key diagnostic in this context is the pole\nstructure of the scattering amplitude, but different configurations can produce\nsimilar signatures. The mapping between pole configurations and line shapes is\nespecially ambiguous near the mass threshold, where analytic control is\nlimited. In this work, we introduce an uncertainty-aware machine learning\napproach for classifying pole structures in $S$-matrix elements. Our method is\nbased on an ensemble of classifier chains that provide both epistemic and\naleatoric uncertainty estimates. We apply a rejection criterion based on\npredictive uncertainty, achieving a validation accuracy of nearly $95\\%$ while\ndiscarding only a small fraction of high-uncertainty predictions. Trained on\nsynthetic data with known pole structures, the model generalizes to previously\nunseen experimental data, including enhancements associated with the\n$P_{c\\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole\nstructure, representing the presence of a genuine compact pentaquark in the\npresence of a higher channel virtual state pole with non-vanishing width. While\nevaluated on this particular state, our framework is broadly applicable to\nother candidate hadronic states and offers a scalable tool for pole structure\ninference in scattering amplitudes.\n","authors":["Felix Frohnert","Denny Lane B. Sombrillo","Evert van Nieuwenburg","Patrick Emonts"],"pdf_url":"https://arxiv.org/pdf/2507.07668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07644v1","updated":"2025-07-10T11:16:48Z","published":"2025-07-10T11:16:48Z","title":"PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured\n  Representations","summary":"  We introduce PlanQA, a diagnostic benchmark for evaluating geometric and\nspatial reasoning in large-language models (LLMs). PlanQA is grounded in\nstructured representations of indoor scenes, such as kitchens, living rooms,\nand bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The\nbenchmark includes diverse question types that test not only metric and\ntopological reasoning (e.g., distance, visibility, shortest paths) but also\ninterior design constraints such as affordance, clearance, balance, and\nusability. Our results across a variety of frontier open-source and commercial\nLLMs show that while models may succeed in shallow queries, they often fail to\nsimulate physical constraints, preserve spatial coherence, or generalize under\nlayout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they\ndo not consistently reason about real-world layouts. We hope that this\nbenchmark inspires new work on language models that can accurately infer and\nmanipulate spatial and geometric properties in practical settings.\n","authors":["Fedor Rodionov","Abdelrahman Eldesokey","Michael Birsak","John Femiani","Bernard Ghanem","Peter Wonka"],"pdf_url":"https://arxiv.org/pdf/2507.07644v1.pdf","comment":"25 pages, 18 figures. Diagnostic benchmark for spatial reasoning in\n  LLMs. Project page: https://OldDelorean.github.io/PlanQA/"},{"id":"http://arxiv.org/abs/2407.17070v2","updated":"2025-07-10T11:15:07Z","published":"2024-07-24T07:55:49Z","title":"Curriculum Negative Mining For Temporal Networks","summary":"  Temporal networks are effective in capturing the evolving interactions of\nnetworks over time, such as social networks and e-commerce networks. In recent\nyears, researchers have primarily concentrated on developing specific model\narchitectures for Temporal Graph Neural Networks (TGNNs) in order to improve\nthe representation quality of temporal nodes and edges. However, limited\nattention has been given to the quality of negative samples during the training\nof TGNNs. When compared with static networks, temporal networks present two\nspecific challenges for negative sampling: positive sparsity and positive\nshift. Positive sparsity refers to the presence of a single positive sample\namidst numerous negative samples at each timestamp, while positive shift\nrelates to the variations in positive samples across different timestamps. To\nrobustly address these challenges in training TGNNs, we introduce Curriculum\nNegative Mining (CurNM), a model-aware curriculum learning framework that\nadaptively adjusts the difficulty of negative samples. Within this framework,\nwe first establish a dynamically updated negative pool that balances random,\nhistorical, and hard negatives to address the challenges posed by positive\nsparsity. Secondly, we implement a temporal-aware negative selection module\nthat focuses on learning from the disentangled factors of recently active\nedges, thus accurately capturing shifting preferences. Finally, the selected\nnegatives are combined with annealing random negatives to support stable\ntraining. Extensive experiments on 12 datasets and 3 TGNNs demonstrate that our\nmethod outperforms baseline methods by a significant margin. Additionally,\nthorough ablation studies and parameter sensitivity experiments verify the\nusefulness and robustness of our approach.\n","authors":["Ziyue Chen","Tongya Zheng","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2407.17070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07622v1","updated":"2025-07-10T10:44:53Z","published":"2025-07-10T10:44:53Z","title":"TransformEEG: Towards Improving Model Generalizability in Deep\n  Learning-based EEG Parkinson's Disease Detection","summary":"  Electroencephalography (EEG) is establishing itself as an important,\nlow-cost, noninvasive diagnostic tool for the early detection of Parkinson's\nDisease (PD). In this context, EEG-based Deep Learning (DL) models have shown\npromising results due to their ability to discover highly nonlinear patterns\nwithin the signal. However, current state-of-the-art DL models suffer from poor\ngeneralizability caused by high inter-subject variability. This high\nvariability underscores the need for enhancing model generalizability by\ndeveloping new architectures better tailored to EEG data. This paper introduces\nTransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's\ndisease detection using EEG data. Unlike transformer models based on the EEGNet\nstructure, TransformEEG incorporates a depthwise convolutional tokenizer. This\ntokenizer is specialized in generating tokens composed by channel-specific\nfeatures, which enables more effective feature mixing within the self-attention\nlayers of the transformer encoder. To evaluate the proposed model, four public\ndatasets comprising 290 subjects (140 PD patients, 150 healthy controls) were\nharmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out\n(N-LNSO) cross-validation was performed to provide an unbiased comparison\nagainst seven other consolidated EEG deep learning models. TransformEEG\nachieved the highest balanced accuracy's median (78.45%) as well as the lowest\ninterquartile range (6.37%) across all the N-LNSO partitions. When combined\nwith data augmentation and threshold correction, median accuracy increased to\n80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG\nproduces more consistent and less skewed results. It demonstrates a substantial\nreduction in variability and more reliable PD detection using EEG data compared\nto the other investigated models.\n","authors":["Federico Del Pup","Riccardo Brun","Filippo Iotti","Edoardo Paccagnella","Mattia Pezzato","Sabrina Bertozzo","Andrea Zanola","Louis Fabrice Tshimanga","Henning Müller","Manfredo Atzori"],"pdf_url":"https://arxiv.org/pdf/2507.07622v1.pdf","comment":"Submitted for possible publication. GitHub repository: see\n  https://github.com/MedMaxLab/transformeeg"},{"id":"http://arxiv.org/abs/2507.07619v1","updated":"2025-07-10T10:40:24Z","published":"2025-07-10T10:40:24Z","title":"Towards conservative inference in credal networks using belief\n  functions: the case of credal chains","summary":"  This paper explores belief inference in credal networks using Dempster-Shafer\ntheory. By building on previous work, we propose a novel framework for\npropagating uncertainty through a subclass of credal networks, namely chains.\nThe proposed approach efficiently yields conservative intervals through belief\nand plausibility functions, combining computational speed with robust\nuncertainty representation. Key contributions include formalizing belief-based\ninference methods and comparing belief-based inference against classical\nsensitivity analysis. Numerical results highlight the advantages and\nlimitations of applying belief inference within this framework, providing\ninsights into its practical utility for chains and for credal networks in\ngeneral.\n","authors":["Marco Sangalli","Thomas Krak","Cassio de Campos"],"pdf_url":"https://arxiv.org/pdf/2507.07619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.02409v2","updated":"2025-07-10T10:14:21Z","published":"2025-07-03T08:04:49Z","title":"S2FGL: Spatial Spectral Federated Graph Learning","summary":"  Federated Graph Learning (FGL) combines the privacy-preserving capabilities\nof federated learning (FL) with the strong graph modeling capability of Graph\nNeural Networks (GNNs). Current research addresses subgraph-FL only from the\nstructural perspective, neglecting the propagation of graph signals on spatial\nand spectral domains of the structure. From a spatial perspective, subgraph-FL\nintroduces edge disconnections between clients, leading to disruptions in label\nsignals and a degradation in the class knowledge of the global GNN. From a\nspectral perspective, spectral heterogeneity causes inconsistencies in signal\nfrequencies across subgraphs, which makes local GNNs overfit the local signal\npropagation schemes. As a result, spectral client drifts occur, undermining\nglobal generalizability. To tackle the challenges, we propose a global\nknowledge repository to mitigate label signal disruption and a frequency\nalignment to address spectral client drifts. The combination of spatial and\nspectral strategies forms our framework S2FGL. Extensive experiments on\nmultiple datasets demonstrate the superiority of S2FGL. The code is available\nat https://github.com/Wonder7racer/S2FGL.git.\n","authors":["Zihan Tan","Suyuan Huang","Guancheng Wan","Wenke Huang","He Li","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2507.02409v2.pdf","comment":null}],"Statistics - Machine Learning":[{"id":"http://arxiv.org/abs/2507.07981v1","updated":"2025-07-10T17:55:05Z","published":"2025-07-10T17:55:05Z","title":"Why is Your Language Model a Poor Implicit Reward Model?","summary":"  Reward models are key to language model post-training and inference\npipelines. Conveniently, recent work showed that every language model defines\nan implicit reward model (IM-RM), without requiring any architectural changes.\nHowever, such IM-RMs tend to generalize worse, especially out-of-distribution,\ncompared to explicit reward models (EX-RMs) that apply a dedicated linear head\nover the hidden representations of a language model. The existence of a\ngeneralization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They\ncan be trained using the same data, loss function, and language model, and\ndiffer only in how the reward is computed. Towards a fundamental understanding\nof the implicit biases underlying different reward model types, we investigate\nthe root cause of this gap. Our main finding, backed by theory and experiments,\nis that IM-RMs rely more heavily on superficial token-level cues. Consequently,\nthey often generalize worse than EX-RMs under token-level distribution shifts,\nas well as in-distribution. Furthermore, we provide evidence against\nalternative hypotheses for the generalization gap. Most notably, we challenge\nthe intuitive claim that IM-RMs struggle in tasks where generation is harder\nthan verification because they can operate both as a verifier and a generator.\nTaken together, our results highlight that seemingly minor design choices can\nsubstantially impact the generalization behavior of reward models.\n","authors":["Noam Razin","Yong Lin","Jiarui Yao","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2507.07981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07969v1","updated":"2025-07-10T17:48:03Z","published":"2025-07-10T17:48:03Z","title":"Reinforcement Learning with Action Chunking","summary":"  We present Q-chunking, a simple yet effective recipe for improving\nreinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks.\nOur recipe is designed for the offline-to-online RL setting, where the goal is\nto leverage an offline prior dataset to maximize the sample-efficiency of\nonline learning. Effective exploration and sample-efficient learning remain\ncentral challenges in this setting, as it is not obvious how the offline data\nshould be utilized to acquire a good exploratory policy. Our key insight is\nthat action chunking, a technique popularized in imitation learning where\nsequences of future actions are predicted rather than a single action at each\ntimestep, can be applied to temporal difference (TD)-based RL methods to\nmitigate the exploration challenge. Q-chunking adopts action chunking by\ndirectly running RL in a 'chunked' action space, enabling the agent to (1)\nleverage temporally consistent behaviors from offline data for more effective\nonline exploration and (2) use unbiased $n$-step backups for more stable and\nefficient TD learning. Our experimental results demonstrate that Q-chunking\nexhibits strong offline performance and online sample efficiency, outperforming\nprior best offline-to-online methods on a range of long-horizon, sparse-reward\nmanipulation tasks.\n","authors":["Qiyang Li","Zhiyuan Zhou","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2507.07969v1.pdf","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2507.07965v1","updated":"2025-07-10T17:45:15Z","published":"2025-07-10T17:45:15Z","title":"Prospective Learning in Retrospect","summary":"  In most real-world applications of artificial intelligence, the distributions\nof the data and the goals of the learners tend to change over time. The\nProbably Approximately Correct (PAC) learning framework, which underpins most\nmachine learning algorithms, fails to account for dynamic data distributions\nand evolving objectives, often resulting in suboptimal performance. Prospective\nlearning is a recently introduced mathematical framework that overcomes some of\nthese limitations. We build on this framework to present preliminary results\nthat improve the algorithm and numerical results, and extend prospective\nlearning to sequential decision-making scenarios, specifically foraging. Code\nis available at: https://github.com/neurodata/prolearn2.\n","authors":["Yuxin Bai","Cecelia Shuai","Ashwin De Silva","Siyu Yu","Pratik Chaudhari","Joshua T. Vogelstein"],"pdf_url":"https://arxiv.org/pdf/2507.07965v1.pdf","comment":"Accepted to AGI 2025"},{"id":"http://arxiv.org/abs/2507.07941v1","updated":"2025-07-10T17:27:04Z","published":"2025-07-10T17:27:04Z","title":"Late Fusion Multi-task Learning for Semiparametric Inference with\n  Nuisance Parameters","summary":"  In the age of large and heterogeneous datasets, the integration of\ninformation from diverse sources is essential to improve parameter estimation.\nMulti-task learning offers a powerful approach by enabling simultaneous\nlearning across related tasks. In this work, we introduce a late fusion\nframework for multi-task learning with semiparametric models that involve\ninfinite-dimensional nuisance parameters, focusing on applications such as\nheterogeneous treatment effect estimation across multiple data sources,\nincluding electronic health records from different hospitals or clinical trial\ndata. Our framework is two-step: first, initial double machine-learning\nestimators are obtained through individual task learning; second, these\nestimators are adaptively aggregated to exploit task similarities while\nremaining robust to task-specific differences. In particular, the framework\navoids individual level data sharing, preserving privacy. Additionally, we\npropose a novel multi-task learning method for nuisance parameter estimation,\nwhich further enhances parameter estimation when nuisance parameters exhibit\nsimilarity across tasks. We establish theoretical guarantees for the method,\ndemonstrating faster convergence rates compared to individual task learning\nwhen tasks share similar parametric components. Extensive simulations and real\ndata applications complement the theoretical findings of our work while\nhighlight the effectiveness of our framework even in moderate sample sizes.\n","authors":["Sohom Bhattacharya","Yongzhuo Chen","Muxuan Liang"],"pdf_url":"https://arxiv.org/pdf/2507.07941v1.pdf","comment":"21 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.11171v3","updated":"2025-07-10T16:14:13Z","published":"2024-10-15T01:17:23Z","title":"A Bilevel Optimization Framework for Imbalanced Data Classification","summary":"  Data rebalancing techniques, including oversampling and undersampling, are a\ncommon approach to addressing the challenges of imbalanced data. To tackle\nunresolved problems related to both oversampling and undersampling, we propose\na new undersampling approach that: (i) avoids the pitfalls of noise and overlap\ncaused by synthetic data and (ii) avoids the pitfall of under-fitting caused by\nrandom undersampling. Instead of undersampling majority data randomly, our\nmethod undersamples datapoints based on their ability to improve model loss.\nUsing improved model loss as a proxy measurement for classification\nperformance, our technique assesses a datapoint's impact on loss and rejects\nthose unable to improve it. In so doing, our approach rejects majority\ndatapoints redundant to datapoints already accepted and, thereby, finds an\noptimal subset of majority training data for classification. The accept/reject\ncomponent of our algorithm is motivated by a bilevel optimization problem\nuniquely formulated to identify the optimal training set we seek. Experimental\nresults show our proposed technique with F1 scores up to 10% higher than\nstate-of-the-art methods.\n","authors":["Karen Medlin","Sven Leyffer","Krishnan Raghavan"],"pdf_url":"https://arxiv.org/pdf/2410.11171v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07852v1","updated":"2025-07-10T15:33:27Z","published":"2025-07-10T15:33:27Z","title":"Pre-Trained AI Model Assisted Online Decision-Making under Missing\n  Covariates: A Theoretical Perspective","summary":"  We study a sequential contextual decision-making problem in which certain\ncovariates are missing but can be imputed using a pre-trained AI model. From a\ntheoretical perspective, we analyze how the presence of such a model influences\nthe regret of the decision-making process. We introduce a novel notion called\n\"model elasticity\", which quantifies the sensitivity of the reward function to\nthe discrepancy between the true covariate and its imputed counterpart. This\nconcept provides a unified way to characterize the regret incurred due to model\nimputation, regardless of the underlying missingness mechanism. More\nsurprisingly, we show that under the missing at random (MAR) setting, it is\npossible to sequentially calibrate the pre-trained model using tools from\northogonal statistical learning and doubly robust regression. This calibration\nsignificantly improves the quality of the imputed covariates, leading to much\nbetter regret guarantees. Our analysis highlights the practical value of having\nan accurate pre-trained model in sequential decision-making tasks and suggests\nthat model elasticity may serve as a fundamental metric for understanding and\nimproving the integration of pre-trained models in a wide range of data-driven\ndecision-making problems.\n","authors":["Haichen Hu","David Simchi-Levi"],"pdf_url":"https://arxiv.org/pdf/2507.07852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.11713v2","updated":"2025-07-10T15:32:14Z","published":"2025-03-12T22:19:33Z","title":"Revisiting the Predictability of Performative, Social Events","summary":"  Social predictions do not passively describe the future; they actively shape\nit. They inform actions and change individual expectations in ways that\ninfluence the likelihood of the predicted outcome. Given these dynamics, to\nwhat extent can social events be predicted? This question was discussed\nthroughout the 20th century by authors like Merton, Morgenstern, Simon, and\nothers who considered it a central issue in social science methodology. In this\nwork, we provide a modern answer to this old problem. Using recent ideas from\nperformative prediction and outcome indistinguishability, we establish that one\ncan always efficiently predict social events accurately, regardless of how\npredictions influence data. While achievable, we also show that these\npredictions are often undesirable, highlighting the limitations of previous\ndesiderata. We end with a discussion of various avenues forward.\n","authors":["Juan C. Perdomo"],"pdf_url":"https://arxiv.org/pdf/2503.11713v2.pdf","comment":"21 pages, accepted to ICML 2025"},{"id":"http://arxiv.org/abs/2507.07826v1","updated":"2025-07-10T14:58:28Z","published":"2025-07-10T14:58:28Z","title":"An Empirical Bernstein Inequality for Dependent Data in Hilbert Spaces\n  and Applications","summary":"  Learning from non-independent and non-identically distributed data poses a\npersistent challenge in statistical learning. In this study, we introduce\ndata-dependent Bernstein inequalities tailored for vector-valued processes in\nHilbert space. Our inequalities apply to both stationary and non-stationary\nprocesses and exploit the potential rapid decay of correlations between\ntemporally separated variables to improve estimation. We demonstrate the\nutility of these bounds by applying them to covariance operator estimation in\nthe Hilbert-Schmidt norm and to operator learning in dynamical systems,\nachieving novel risk bounds. Finally, we perform numerical experiments to\nillustrate the practical implications of these bounds in both contexts.\n","authors":["Erfan Mirzaei","Andreas Maurer","Vladimir R. Kostic","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2507.07826v1.pdf","comment":"In The 28th International Conference on Artificial Intelligence and\n  Statistics (2025)"},{"id":"http://arxiv.org/abs/2503.02113v2","updated":"2025-07-10T13:56:52Z","published":"2025-03-03T22:56:04Z","title":"Deep Learning is Not So Mysterious or Different","summary":"  Deep neural networks are often seen as different from other model classes by\ndefying conventional notions of generalization. Popular examples of anomalous\ngeneralization behaviour include benign overfitting, double descent, and the\nsuccess of overparametrization. We argue that these phenomena are not distinct\nto neural networks, or particularly mysterious. Moreover, this generalization\nbehaviour can be intuitively understood, and rigorously characterized, using\nlong-standing generalization frameworks such as PAC-Bayes and countable\nhypothesis bounds. We present soft inductive biases as a key unifying principle\nin explaining these phenomena: rather than restricting the hypothesis space to\navoid overfitting, embrace a flexible hypothesis space, with a soft preference\nfor simpler solutions that are consistent with the data. This principle can be\nencoded in many model classes, and thus deep learning is not as mysterious or\ndifferent from other model classes as it might seem. However, we also highlight\nhow deep learning is relatively distinct in other ways, such as its ability for\nrepresentation learning, phenomena such as mode connectivity, and its relative\nuniversality.\n","authors":["Andrew Gordon Wilson"],"pdf_url":"https://arxiv.org/pdf/2503.02113v2.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2506.11367v2","updated":"2025-07-10T13:55:15Z","published":"2025-06-13T00:00:43Z","title":"Coefficient Shape Transfer Learning for Functional Linear Regression","summary":"  In this paper, we develop a novel transfer learning methodology to tackle the\nchallenge of data scarcity in functional linear models. The methodology\nincorporates samples from the target model (target domain) alongside those from\nauxiliary models (source domains), transferring knowledge of coefficient shape\nfrom the source domains to the target domain. This shape-based knowledge\ntransfer offers two key advantages. First, it is robust to covariate scaling,\nensuring effectiveness despite variations in data distributions across\ndifferent source domains. Second, the notion of coefficient shape homogeneity\nrepresents a meaningful advance beyond traditional coefficient homogeneity,\nallowing the method to exploit a wider range of source domains and achieve\nsignificantly improved model estimation. We rigorously analyze the convergence\nrates of the proposed estimator and examine the minimax optimality. Our\nfindings show that the degree of improvement depends not only on the similarity\nof coefficient shapes between the target and source domains, but also on\ncoefficient magnitudes and the spectral decay rates of the functional\ncovariates covariance operators. To address situations where only a subset of\nauxiliary models is informative for the target model, we further develop a\ndata-driven procedure for identifying such informative sources. The\neffectiveness of the proposed methodology is demonstrated through comprehensive\nsimulation studies and an application to occupation time analysis using\nphysical activity data from the U.S. National Health and Nutrition Examination\nSurvey.\n","authors":["Shuhao Jiao","Ian W. Mckeague","N. -H. Chan"],"pdf_url":"https://arxiv.org/pdf/2506.11367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07771v1","updated":"2025-07-10T13:54:59Z","published":"2025-07-10T13:54:59Z","title":"A Unified Empirical Risk Minimization Framework for Flexible N-Tuples\n  Weak Supervision","summary":"  To alleviate the annotation burden in supervised learning, N-tuples learning\nhas recently emerged as a powerful weakly-supervised method. While existing\nN-tuples learning approaches extend pairwise learning to higher-order\ncomparisons and accommodate various real-world scenarios, they often rely on\ntask-specific designs and lack a unified theoretical foundation. In this paper,\nwe propose a general N-tuples learning framework based on empirical risk\nminimization, which systematically integrates pointwise unlabeled data to\nenhance learning performance. This paper first unifies the data generation\nprocesses of N-tuples and pointwise unlabeled data under a shared probabilistic\nformulation. Based on this unified view, we derive an unbiased empirical risk\nestimator that generalizes a broad class of existing N-tuples models. We\nfurther establish a generalization error bound for theoretical support. To\ndemonstrate the flexibility of the framework, we instantiate it in four\nrepresentative weakly supervised scenarios, each recoverable as a special case\nof our general model. Additionally, to address overfitting issues arising from\nnegative risk terms, we adopt correction functions to adjust the empirical\nrisk. Extensive experiments on benchmark datasets validate the effectiveness of\nthe proposed framework and demonstrate that leveraging pointwise unlabeled data\nconsistently improves generalization across various N-tuples learning tasks.\n","authors":["Shuying Huang","Junpeng Li","Changchun Hua","Yana Yang"],"pdf_url":"https://arxiv.org/pdf/2507.07771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.17836v6","updated":"2025-07-10T12:56:43Z","published":"2025-05-23T12:51:03Z","title":"Robust Distributed Estimation: Extending Gossip Algorithms to Ranking\n  and Trimmed Means","summary":"  This paper addresses the problem of robust estimation in gossip algorithms\nover arbitrary communication graphs. Gossip algorithms are fully decentralized,\nrelying only on local neighbor-to-neighbor communication, making them\nwell-suited for situations where communication is constrained. A fundamental\nchallenge in existing mean-based gossip algorithms is their vulnerability to\nmalicious or corrupted nodes. In this paper, we show that an outlier-robust\nmean can be computed by globally estimating a robust statistic. More\nspecifically, we propose a novel gossip algorithm for rank estimation, referred\nto as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated\nto trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed\ndescription of the proposed methods, a key contribution of our work is a\nprecise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank\nestimation and an $\\mathcal{O}(1 / {t})$ rate for trimmed mean estimation,\nwhere by $t$ is meant the number of iterations. Moreover, we provide a\nbreakdown point analysis of \\textsc{GoTrim}. We empirically validate our\ntheoretical results through experiments on diverse network topologies, data\ndistributions and contamination schemes.\n","authors":["Anna Van Elst","Igor Colin","Stephan Clémençon"],"pdf_url":"https://arxiv.org/pdf/2505.17836v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20573v3","updated":"2025-07-10T08:40:09Z","published":"2025-06-25T16:07:59Z","title":"LARP: Learner-Agnostic Robust Data Prefiltering","summary":"  The widespread availability of large public datasets is a key factor behind\nthe recent successes of statistical inference and machine learning methods.\nHowever, these datasets often contain some low-quality or contaminated data, to\nwhich many learning procedures are sensitive. Therefore, the question of\nwhether and how public datasets should be prefiltered to facilitate accurate\ndownstream learning arises. On a technical level this requires the construction\nof principled data prefiltering methods which are learner-agnostic robust, in\nthe sense of provably protecting a set of pre-specified downstream learners\nfrom corrupted data. In this work, we formalize the problem of Learner-Agnostic\nRobust data Prefiltering (LARP), which aims at finding prefiltering procedures\nthat minimize a worst-case loss over a pre-specified set of learners. We first\ninstantiate our framework in the context of scalar mean estimation with Huber\nestimators under the Huber data contamination model. We provide a hardness\nresult on a specific problem instance and analyze several natural prefiltering\nprocedures. Our theoretical results indicate that performing LARP on a\nheterogeneous set of learners leads to some loss in model performance compared\nto the alternative of prefiltering data for each learner/use-case individually.\nWe explore the resulting utility loss and its dependence on the problem\nparameters via extensive experiments on real-world image and tabular data,\nobserving statistically significant reduction in utility. Finally, we model the\ntrade-off between the utility drop and the cost of repeated (learner-specific)\nprefiltering within a game-theoretic framework and showcase benefits of LARP\nfor large datasets.\n","authors":["Kristian Minchev","Dimitar Iliev Dimitrov","Nikola Konstantinov"],"pdf_url":"https://arxiv.org/pdf/2506.20573v3.pdf","comment":"Presented at ICML 2025 Workshop on DataWorld: Unifying Data Curation\n  Frameworks Across Domains"},{"id":"http://arxiv.org/abs/2501.07964v4","updated":"2025-07-10T08:17:00Z","published":"2025-01-14T09:35:49Z","title":"Derivation of Output Correlation Inferences for Multi-Output (aka\n  Multi-Task) Gaussian Process","summary":"  Gaussian process (GP) is arguably one of the most widely used machine\nlearning algorithms in practice. One of its prominent applications is Bayesian\noptimization (BO). Although the vanilla GP itself is already a powerful tool\nfor BO, it is often beneficial to be able to consider the dependencies of\nmultiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not\ntrivial to fully understand the derivations of its formulations and their\ngradients from the previous literature. This paper serves friendly derivations\nof the MTGP formulations and their gradients.\n","authors":["Shuhei Watanabe"],"pdf_url":"https://arxiv.org/pdf/2501.07964v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18374v3","updated":"2025-07-10T07:43:06Z","published":"2025-01-30T14:26:29Z","title":"Proofs for Folklore Theorems on the Radon-Nikodym Derivative","summary":"  In this technical report, rigorous statements and formal proofs are presented\nfor both foundational and advanced folklore theorems on the Radon-Nikodym\nderivative. The cases of conditional and marginal probability measures are\ncarefully considered, which leads to an identity involving the sum of mutual\nand lautum information suggesting a new interpretation for such a sum.\n","authors":["Yaiza Bermudez","Gaetan Bisson","Iñaki Esnaola","Samir M. Perlaza"],"pdf_url":"https://arxiv.org/pdf/2501.18374v3.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2507.07469v1","updated":"2025-07-10T06:53:18Z","published":"2025-07-10T06:53:18Z","title":"Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast\n  Rolling One-Step-Ahead Forecasting","summary":"  Time-series models like ARIMA remain widely used for forecasting but limited\nto linear assumptions and high computational cost in large and complex\ndatasets. We propose Galerkin-ARIMA that generalizes the AR component of ARIMA\nand replace it with a flexible spline-based function estimated by Galerkin\nprojection. This enables the model to capture nonlinear dependencies in lagged\nvalues and retain the MA component and Gaussian noise assumption. We derive a\nclosed-form OLS estimator for the Galerkin coefficients and show the model is\nasymptotically unbiased and consistent under standard conditions. Our method\nbridges classical time-series modeling and nonparametric regression, which\noffering improved forecasting performance and computational efficiency.\n","authors":["Haojie Liu","Zihan Lin"],"pdf_url":"https://arxiv.org/pdf/2507.07469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07461v1","updated":"2025-07-10T06:26:54Z","published":"2025-07-10T06:26:54Z","title":"Hess-MC2: Sequential Monte Carlo Squared using Hessian Information and\n  Second Order Proposals","summary":"  When performing Bayesian inference using Sequential Monte Carlo (SMC)\nmethods, two considerations arise: the accuracy of the posterior approximation\nand computational efficiency. To address computational demands, Sequential\nMonte Carlo Squared (SMC$^2$) is well-suited for high-performance computing\n(HPC) environments. The design of the proposal distribution within SMC$^2$ can\nimprove accuracy and exploration of the posterior as poor proposals may lead to\nhigh variance in importance weights and particle degeneracy. The\nMetropolis-Adjusted Langevin Algorithm (MALA) uses gradient information so that\nparticles preferentially explore regions of higher probability. In this paper,\nwe extend this idea by incorporating second-order information, specifically the\nHessian of the log-target. While second-order proposals have been explored\npreviously in particle Markov Chain Monte Carlo (p-MCMC) methods, we are the\nfirst to introduce them within the SMC$^2$ framework. Second-order proposals\nnot only use the gradient (first-order derivative), but also the curvature\n(second-order derivative) of the target distribution. Experimental results on\nsynthetic models highlight the benefits of our approach in terms of step-size\nselection and posterior approximation accuracy when compared to other\nproposals.\n","authors":["Joshua Murphy","Conor Rosato","Andrew Millard","Lee Devlin","Paul Horridge","Simon Maskell"],"pdf_url":"https://arxiv.org/pdf/2507.07461v1.pdf","comment":"Accepted to IEEE Machine Learning Signal Processing conference 2025"},{"id":"http://arxiv.org/abs/2503.04424v2","updated":"2025-07-10T04:07:04Z","published":"2025-03-06T13:32:13Z","title":"Determinant Estimation under Memory Constraints and Neural Scaling Laws","summary":"  Calculating or accurately estimating log-determinants of large positive\ndefinite matrices is of fundamental importance in many machine learning tasks.\nWhile its cubic computational complexity can already be prohibitive, in modern\napplications, even storing the matrices themselves can pose a memory\nbottleneck. To address this, we derive a novel hierarchical algorithm based on\nblock-wise computation of the LDL decomposition for large-scale log-determinant\ncalculation in memory-constrained settings. In extreme cases where matrices are\nhighly ill-conditioned, accurately computing the full matrix itself may be\ninfeasible. This is particularly relevant when considering kernel matrices at\nscale, including the empirical Neural Tangent Kernel (NTK) of neural networks\ntrained on large datasets. Under the assumption of neural scaling laws in the\ntest error, we show that the ratio of pseudo-determinants satisfies a power-law\nrelationship, allowing us to derive corresponding scaling laws. This enables\naccurate estimation of NTK log-determinants from a tiny fraction of the full\ndataset; in our experiments, this results in a $\\sim$100,000$\\times$ speedup\nwith improved accuracy over competing approximations. Using these techniques,\nwe successfully estimate log-determinants for dense matrices of extreme sizes,\nwhich were previously deemed intractable and inaccessible due to their enormous\nscale and computational demands.\n","authors":["Siavash Ameli","Chris van der Heide","Liam Hodgkinson","Fred Roosta","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2503.04424v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.04237v2","updated":"2025-07-10T03:23:01Z","published":"2025-07-06T04:00:26Z","title":"Structural Classification of Locally Stationary Time Series Based on\n  Second-order Characteristics","summary":"  Time series classification is crucial for numerous scientific and engineering\napplications. In this article, we present a numerically efficient, practically\ncompetitive, and theoretically rigorous classification method for\ndistinguishing between two classes of locally stationary time series based on\ntheir time-domain, second-order characteristics. Our approach builds on the\nautoregressive approximation for locally stationary time series, combined with\nan ensemble aggregation and a distance-based threshold for classification. It\nimposes no requirement on the training sample size, and is shown to achieve\nzero misclassification error rate asymptotically when the underlying time\nseries differ only mildly in their second-order characteristics. The new method\nis demonstrated to outperform a variety of state-of-the-art solutions,\nincluding wavelet-based, tree-based, convolution-based methods, as well as\nmodern deep learning methods, through intensive numerical simulations and a\nreal EEG data analysis for epilepsy classification.\n","authors":["Chen Qian","Xiucai Ding","Lexin Li"],"pdf_url":"https://arxiv.org/pdf/2507.04237v2.pdf","comment":"41 Pages, 4 Figures"},{"id":"http://arxiv.org/abs/2507.07382v1","updated":"2025-07-10T02:34:07Z","published":"2025-07-10T02:34:07Z","title":"Feature-free regression kriging","summary":"  Spatial interpolation is a crucial task in geography. As perhaps the most\nwidely used interpolation methods, geostatistical models -- such as Ordinary\nKriging (OK) -- assume spatial stationarity, which makes it difficult to\ncapture the nonstationary characteristics of geographic variables. A common\nsolution is trend surface modeling (e.g., Regression Kriging, RK), which relies\non external explanatory variables to model the trend and then applies\ngeostatistical interpolation to the residuals. However, this approach requires\nhigh-quality and readily available explanatory variables, which are often\nlacking in many spatial interpolation scenarios -- such as estimating heavy\nmetal concentrations underground. This study proposes a Feature-Free Regression\nKriging (FFRK) method, which automatically extracts geospatial features --\nincluding local dependence, local heterogeneity, and geosimilarity -- to\nconstruct a regression-based trend surface without requiring external\nexplanatory variables. We conducted experiments on the spatial distribution\nprediction of three heavy metals in a mining area in Australia. In comparison\nwith 17 classical interpolation methods, the results indicate that FFRK, which\ndoes not incorporate any explanatory variables and relies solely on extracted\ngeospatial features, consistently outperforms both conventional Kriging\ntechniques and machine learning models that depend on explanatory variables.\nThis approach effectively addresses spatial nonstationarity while reducing the\ncost of acquiring explanatory variables, improving both prediction accuracy and\ngeneralization ability. This finding suggests that an accurate characterization\nof geospatial features based on domain knowledge can significantly enhance\nspatial prediction performance -- potentially yielding greater improvements\nthan merely adopting more advanced statistical models.\n","authors":["Peng Luo","Yilong Wu","Yongze Song"],"pdf_url":"https://arxiv.org/pdf/2507.07382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07359v1","updated":"2025-07-10T00:53:57Z","published":"2025-07-10T00:53:57Z","title":"Goal-Oriented Sequential Bayesian Experimental Design for Causal\n  Learning","summary":"  We present GO-CBED, a goal-oriented Bayesian framework for sequential causal\nexperimental design. Unlike conventional approaches that select interventions\naimed at inferring the full causal model, GO-CBED directly maximizes the\nexpected information gain (EIG) on user-specified causal quantities of\ninterest, enabling more targeted and efficient experimentation. The framework\nis both non-myopic, optimizing over entire intervention sequences, and\ngoal-oriented, targeting only model aspects relevant to the causal query. To\naddress the intractability of exact EIG computation, we introduce a variational\nlower bound estimator, optimized jointly through a transformer-based policy\nnetwork and normalizing flow-based variational posteriors. The resulting policy\nenables real-time decision-making via an amortized network. We demonstrate that\nGO-CBED consistently outperforms existing baselines across various causal\nreasoning and discovery tasks-including synthetic structural causal models and\nsemi-synthetic gene regulatory networks-particularly in settings with limited\nexperimental budgets and complex causal mechanisms. Our results highlight the\nbenefits of aligning experimental design objectives with specific research\ngoals and of forward-looking sequential planning.\n","authors":["Zheyu Zhang","Jiayuan Dong","Jie Liu","Xun Huan"],"pdf_url":"https://arxiv.org/pdf/2507.07359v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.02275v2","updated":"2025-07-10T00:09:56Z","published":"2025-07-03T03:31:45Z","title":"It's Hard to Be Normal: The Impact of Noise on Structure-agnostic\n  Estimation","summary":"  Structure-agnostic causal inference studies how well one can estimate a\ntreatment effect given black-box machine learning estimates of nuisance\nfunctions (like the impact of confounders on treatment and outcomes). Here, we\nfind that the answer depends in a surprising way on the distribution of the\ntreatment noise. Focusing on the partially linear model of\n\\citet{robinson1988root}, we first show that the widely adopted double machine\nlearning (DML) estimator is minimax rate-optimal for Gaussian treatment noise,\nresolving an open problem of \\citet{mackey2018orthogonal}. Meanwhile, for\nindependent non-Gaussian treatment noise, we show that DML is always suboptimal\nby constructing new practical procedures with higher-order robustness to\nnuisance errors. These \\emph{ACE} procedures use structure-agnostic cumulant\nestimators to achieve $r$-th order insensitivity to nuisance errors whenever\nthe $(r+1)$-st treatment cumulant is non-zero. We complement these core results\nwith novel minimax guarantees for binary treatments in the partially linear\nmodel. Finally, using synthetic demand estimation experiments, we demonstrate\nthe practical benefits of our higher-order robust estimators.\n","authors":["Jikai Jin","Lester Mackey","Vasilis Syrgkanis"],"pdf_url":"https://arxiv.org/pdf/2507.02275v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2507.08000v1","updated":"2025-07-10T17:59:59Z","published":"2025-07-10T17:59:59Z","title":"Impact of Pretraining Word Co-occurrence on Compositional Generalization\n  in Multimodal Models","summary":"  CLIP and large multimodal models (LMMs) have better accuracy on examples\ninvolving concepts that are highly represented in the training data. However,\nthe role of concept combinations in the training data on compositional\ngeneralization is largely unclear -- for instance, how does accuracy vary when\na common object appears in an uncommon pairing with another object? In this\npaper, we investigate how word co-occurrence statistics in the pretraining\ndataset (a proxy for co-occurrence of visual concepts) impacts CLIP/LMM\nperformance. To disentangle the effects of word co-occurrence frequencies from\nsingle-word frequencies, we measure co-occurrence with pointwise mutual\ninformation (PMI), which normalizes the joint probability of two words\nco-occurring by the probability of co-occurring independently. Using\nsynthetically generated images with a variety of concept pairs, we show a\nstrong correlation between PMI in the CLIP pretraining data and zero-shot\naccuracy in CLIP models trained on LAION-400M (r=0.97 and 14% accuracy gap\nbetween images in the top and bottom 5% of PMI values), demonstrating that even\naccuracy on common concepts is affected by the combination of concepts in the\nimage. Leveraging this finding, we reproduce this effect in natural images by\nediting them to contain pairs with varying PMI, resulting in a correlation of\nr=0.75. Finally, we demonstrate that this behavior in CLIP transfers to LMMs\nbuilt on top of CLIP (r=0.70 for TextVQA, r=0.62 for VQAv2). Our findings\nhighlight the need for algorithms and architectures that improve compositional\ngeneralization in multimodal models without scaling the training data\ncombinatorially. Our code is available at\nhttps://github.com/helenqu/multimodal-pretraining-pmi.\n","authors":["Helen Qu","Sang Michael Xie"],"pdf_url":"https://arxiv.org/pdf/2507.08000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07999v1","updated":"2025-07-10T17:59:58Z","published":"2025-07-10T17:59:58Z","title":"Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and\n  Methodology","summary":"  Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically\nreferencing visual regions, just like human \"thinking with images\". However, no\nbenchmark exists to evaluate these capabilities holistically. To bridge this\ngap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a\ndiagnostic benchmark built on three principles: (1) focused visual perception\nof subtle targets in complex scenes, (2) traceable evidence via bounding box\nevaluation, and (3) second-order reasoning to test object interactions and\nspatial hierarchies beyond simple object localization. Prioritizing images with\ndense objects, we initially sample 1K high-quality images from SA-1B, and\nincorporate eight LMM experts to manually annotate questions, candidate\noptions, and answers for each image. After three stages of quality control,\nTreeBench consists of 405 challenging visual question-answering pairs, even the\nmost advanced models struggle with this benchmark, where none of them reach 60%\naccuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR\n(Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to\nsupervise localization and reasoning jointly with reinforcement learning,\nenabling accurate localizations and explainable reasoning pathways. Initialized\nfrom Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and\nTreeBench (+13.4), proving traceability is key to advancing vision-grounded\nreasoning. The code is available at https://github.com/Haochen-Wang409/TreeVGR.\n","authors":["Haochen Wang","Xiangtai Li","Zilong Huang","Anran Wang","Jiacong Wang","Tao Zhang","Jiani Zheng","Sule Bai","Zijian Kang","Jiashi Feng","Zhuochen Wang","Zhaoxiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07998v1","updated":"2025-07-10T17:59:55Z","published":"2025-07-10T17:59:55Z","title":"PyVision: Agentic Vision with Dynamic Tooling","summary":"  LLMs are increasingly deployed as agents, systems capable of planning,\nreasoning, and dynamically calling external tools. However, in visual\nreasoning, prior approaches largely remain limited by predefined workflows and\nstatic toolsets. In this report, we present PyVision, an interactive,\nmulti-turn framework that enables MLLMs to autonomously generate, execute, and\nrefine Python-based tools tailored to the task at hand, unlocking flexible and\ninterpretable problem-solving. We develop a taxonomy of the tools created by\nPyVision and analyze their usage across a diverse set of benchmarks.\nQuantitatively, PyVision achieves consistent performance gains, boosting\nGPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini.\nThese results point to a broader shift: dynamic tooling allows models not just\nto use tools, but to invent them, advancing toward more agentic visual\nreasoning.\n","authors":["Shitian Zhao","Haoquan Zhang","Shaoheng Lin","Ming Li","Qilong Wu","Kaipeng Zhang","Chen Wei"],"pdf_url":"https://arxiv.org/pdf/2507.07998v1.pdf","comment":"26 Pages, 10 Figures, Technical report"},{"id":"http://arxiv.org/abs/2507.07997v1","updated":"2025-07-10T17:59:54Z","published":"2025-07-10T17:59:54Z","title":"MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group\n  Quantization","summary":"  Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental models\nthat compress continuous visual data into discrete tokens. Existing methods\nhave tried to improve the quantization strategy for better reconstruction\nquality, however, there still exists a large gap between VQ-VAEs and VAEs. To\nnarrow this gap, we propose \\NickName, a novel method to augment the\nrepresentation capability of discrete codebooks, facilitating easier\noptimization for codebooks and minimizing information loss, thereby enhancing\nreconstruction quality. Specifically, we propose to retain the latent dimension\nto preserve encoded features and incorporate a set of sub-codebooks for\nquantization. Furthermore, we construct comprehensive zero-shot benchmarks\nfeaturing resolutions of 512p and 2k to evaluate the reconstruction performance\nof existing methods rigorously. \\NickName~achieves the \\textbf{state-of-the-art\nperformance on both ImageNet and $8$ zero-shot benchmarks} across all VQ-VAEs.\nNotably, compared with SD-VAE, we outperform them on ImageNet significantly,\nwith rFID $\\textbf{0.49}$ v.s. $\\textbf{0.91}$, and achieve superior PSNR on\nall zero-shot benchmarks. These results highlight the superiority of\n\\NickName~in reconstruction and pave the way for preserving fidelity in HD\nimage processing tasks. Code will be publicly available at\nhttps://github.com/MKJia/MGVQ.\n","authors":["Mingkai Jia","Wei Yin","Xiaotao Hu","Jiaxin Guo","Xiaoyang Guo","Qian Zhang","Xiao-Xiao Long","Ping Tan"],"pdf_url":"https://arxiv.org/pdf/2507.07997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07995v1","updated":"2025-07-10T17:59:53Z","published":"2025-07-10T17:59:53Z","title":"Single-pass Adaptive Image Tokenization for Minimum Program Search","summary":"  According to Algorithmic Information Theory (AIT) -- Intelligent\nrepresentations compress data into the shortest possible program that can\nreconstruct its content, exhibiting low Kolmogorov Complexity (KC). In\ncontrast, most visual representation learning systems use fixed-length\nrepresentations for all inputs, ignoring variations in complexity or\nfamiliarity. Recent adaptive tokenization methods address this by allocating\nvariable-length representations but typically require test-time search over\nmultiple encodings to find the most predictive one. Inspired by Kolmogorov\nComplexity principles, we propose a single-pass adaptive tokenizer, KARL, which\npredicts the appropriate number of tokens for an image in a single forward\npass, halting once its approximate KC is reached. The token count serves as a\nproxy for the minimum description length. KARL's training procedure closely\nresembles the Upside-Down Reinforcement Learning paradigm, as it learns to\nconditionally predict token halting based on a desired reconstruction quality.\nKARL matches the performance of recent adaptive tokenizers while operating in a\nsingle pass. We present scaling laws for KARL, analyzing the role of\nencoder/decoder size, continuous vs. discrete tokenization and more.\nAdditionally, we offer a conceptual study drawing an analogy between Adaptive\nImage Tokenization and Algorithmic Information Theory, examining the predicted\nimage complexity (KC) across axes such as structure vs. noise and in- vs.\nout-of-distribution familiarity -- revealing alignment with human intuition.\n","authors":["Shivam Duggal","Sanghyun Byun","William T. Freeman","Antonio Torralba","Phillip Isola"],"pdf_url":"https://arxiv.org/pdf/2507.07995v1.pdf","comment":"Code at: https://github.com/ShivamDuggal4/karl Keywords:\n  Representation Learning, Adaptive Tokenization, Compression, Algorithmic\n  Information Theory, Kolmogorov Complexity, Upside-Down RL"},{"id":"http://arxiv.org/abs/2507.07994v1","updated":"2025-07-10T17:59:49Z","published":"2025-07-10T17:59:49Z","title":"Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection","summary":"  Keypoint detection, integral to modern machine perception, faces challenges\nin few-shot learning, particularly when source data from the same distribution\nas the query is unavailable. This gap is addressed by leveraging sketches, a\npopular form of human expression, providing a source-free alternative. However,\nchallenges arise in mastering cross-modal embeddings and handling user-specific\nsketch styles. Our proposed framework overcomes these hurdles with a\nprototypical setup, combined with a grid-based locator and prototypical domain\nadaptation. We also demonstrate success in few-shot convergence across novel\nkeypoints and classes through extensive experiments.\n","authors":["Subhajit Maity","Ayan Kumar Bhunia","Subhadeep Koley","Pinaki Nath Chowdhury","Aneeshan Sain","Yi-Zhe Song"],"pdf_url":"https://arxiv.org/pdf/2507.07994v1.pdf","comment":"Accepted at ICCV 2025. Project Page: https://subhajitmaity.me/DYKp"},{"id":"http://arxiv.org/abs/2507.07993v1","updated":"2025-07-10T17:59:24Z","published":"2025-07-10T17:59:24Z","title":"Multigranular Evaluation for Brain Visual Decoding","summary":"  Existing evaluation protocols for brain visual decoding predominantly rely on\ncoarse metrics that obscure inter-model differences, lack neuroscientific\nfoundation, and fail to capture fine-grained visual distinctions. To address\nthese limitations, we introduce BASIC, a unified, multigranular evaluation\nframework that jointly quantifies structural fidelity, inferential alignment,\nand contextual coherence between decoded and ground truth images. For the\nstructural level, we introduce a hierarchical suite of segmentation-based\nmetrics, including foreground, semantic, instance, and component masks,\nanchored in granularity-aware correspondence across mask structures. For the\nsemantic level, we extract structured scene representations encompassing\nobjects, attributes, and relationships using multimodal large language models,\nenabling detailed, scalable, and context-rich comparisons with ground-truth\nstimuli. We benchmark a diverse set of visual decoding methods across multiple\nstimulus-neuroimaging datasets within this unified evaluation framework.\nTogether, these criteria provide a more discriminative, interpretable, and\ncomprehensive foundation for measuring brain visual decoding methods.\n","authors":["Weihao Xia","Cengiz Oztireli"],"pdf_url":"https://arxiv.org/pdf/2507.07993v1.pdf","comment":"Project: https://weihaox.github.io/BASIC"},{"id":"http://arxiv.org/abs/2507.07990v1","updated":"2025-07-10T17:59:02Z","published":"2025-07-10T17:59:02Z","title":"Multi-Granular Spatio-Temporal Token Merging for Training-Free\n  Acceleration of Video LLMs","summary":"  Video large language models (LLMs) achieve strong video understanding by\nleveraging a large number of spatio-temporal tokens, but suffer from quadratic\ncomputational scaling with token count. To address this, we propose a\ntraining-free spatio-temporal token merging method, named STTM. Our key insight\nis to exploit local spatial and temporal redundancy in video data which has\nbeen overlooked in prior work. STTM first transforms each frame into\nmulti-granular spatial tokens using a coarse-to-fine search over a quadtree\nstructure, then performs directed pairwise merging across the temporal\ndimension. This decomposed merging approach outperforms existing token\nreduction methods across six video QA benchmarks. Notably, STTM achieves a\n2$\\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and\na 3$\\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is\nquery-agnostic, allowing KV cache reuse across different questions for the same\nvideo. The project page is available at https://www.jshyun.me/projects/sttm.\n","authors":["Jeongseok Hyun","Sukjun Hwang","Su Ho Han","Taeoh Kim","Inwoong Lee","Dongyoon Wee","Joon-Young Lee","Seon Joo Kim","Minho Shim"],"pdf_url":"https://arxiv.org/pdf/2507.07990v1.pdf","comment":"Accepted at ICCV2025; Project page:\n  https://www.jshyun.me/projects/sttm"},{"id":"http://arxiv.org/abs/2507.07985v1","updated":"2025-07-10T17:57:31Z","published":"2025-07-10T17:57:31Z","title":"CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is\n  Why","summary":"  Contrastive vision-language models like CLIP are used for a large variety of\napplications, such as zero-shot classification or as vision encoder for\nmulti-modal models. Despite their popularity, their representations show major\nlimitations. For instance, CLIP models learn bag-of-words representations and,\nas a consequence, fail to distinguish whether an image is of \"a yellow\nsubmarine and a blue bus\" or \"a blue submarine and a yellow bus\". Previous\nattempts to fix this issue added hard negatives during training or modified the\narchitecture, but failed to resolve the problem in its entirety. We suspect\nthat the missing insights to solve the binding problem for CLIP are hidden in\nthe arguably most important part of learning algorithms: the data. In this\nwork, we fill this gap by rigorously identifying the influence of data\nproperties on CLIP's ability to learn binding using a synthetic dataset. We\nfind that common properties of natural data such as low attribute density,\nincomplete captions, and the saliency bias, a tendency of human captioners to\ndescribe the object that is \"most salient\" to them have a detrimental effect on\nbinding performance. In contrast to common belief, we find that neither scaling\nthe batch size, i.e., implicitly adding more hard negatives, nor explicitly\ncreating hard negatives enables CLIP to learn reliable binding. Only when the\ndata expresses our identified data properties CLIP learns almost perfect\nbinding.\n","authors":["Bijay Gurung","David T. Hoffmann","Thomas Brox"],"pdf_url":"https://arxiv.org/pdf/2507.07985v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07984v1","updated":"2025-07-10T17:56:07Z","published":"2025-07-10T17:56:07Z","title":"OST-Bench: Evaluating the Capabilities of MLLMs in Online\n  Spatio-temporal Scene Understanding","summary":"  Recent advances in multimodal large language models (MLLMs) have shown\nremarkable capabilities in integrating vision and language for complex\nreasoning. While most existing benchmarks evaluate models under offline\nsettings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a\nbenchmark designed to evaluate Online Spatio-Temporal understanding from the\nperspective of an agent actively exploring a scene. The Online aspect\nemphasizes the need to process and reason over incrementally acquired\nobservations, while the Spatio-Temporal component requires integrating current\nvisual inputs with historical memory to support dynamic spatial reasoning.\nOST-Bench better reflects the challenges of real-world embodied perception.\nBuilt on an efficient data collection pipeline, OST-Bench consists of 1.4k\nscenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and\nARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that\nthey fall short on tasks requiring complex spatio-temporal reasoning. Under the\nonline setting, their accuracy declines as the exploration horizon extends and\nthe memory grows. Through further experimental analysis, we identify common\nerror patterns across models and find that both complex clue-based spatial\nreasoning demands and long-term memory retrieval requirements significantly\ndrop model performance along two separate axes, highlighting the core\nchallenges that must be addressed to improve online embodied reasoning. To\nfoster further research and development in the field, our codes, dataset, and\nbenchmark are available. Our project page is:\nhttps://rbler1234.github.io/OSTBench.github.io/\n","authors":["JingLi Lin","Chenming Zhu","Runsen Xu","Xiaohan Mao","Xihui Liu","Tai Wang","Jiangmiao Pang"],"pdf_url":"https://arxiv.org/pdf/2507.07984v1.pdf","comment":"28 pages, a benchmark designed to evaluate Online Spatio-Temporal\n  understanding from the perspective of an agent actively exploring a scene.\n  Project Page: https://rbler1234.github.io/OSTBench.github.io/"},{"id":"http://arxiv.org/abs/2506.01933v3","updated":"2025-07-10T17:55:35Z","published":"2025-06-02T17:53:09Z","title":"E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models","summary":"  Spatial intelligence, encompassing 3D reconstruction, perception, and\nreasoning, is fundamental to applications such as robotics, aerial imaging, and\nextended reality. A key enabler is the real-time, accurate estimation of core\n3D attributes (camera parameters, point clouds, depth maps, and 3D point\ntracks) from unstructured or streaming imagery. Inspired by the success of\nlarge foundation models in language and 2D vision, a new class of end-to-end 3D\ngeometric foundation models (GFMs) has emerged, directly predicting dense 3D\nrepresentations in a single feed-forward pass, eliminating the need for slow or\nunavailable precomputed camera parameters. Since late 2023, the field has\nexploded with diverse variants, but systematic evaluation is lacking. In this\nwork, we present the first comprehensive benchmark for 3D GFMs, covering five\ncore tasks: sparse-view depth estimation, video depth estimation, 3D\nreconstruction, multi-view pose estimation, novel view synthesis, and spanning\nboth standard and challenging out-of-distribution datasets. Our standardized\ntoolkit automates dataset handling, evaluation protocols, and metric\ncomputation to ensure fair, reproducible comparisons. We evaluate 16\nstate-of-the-art GFMs, revealing their strengths and limitations across tasks\nand domains, and derive key insights to guide future model scaling and\noptimization. All code, evaluation scripts, and processed data will be publicly\nreleased to accelerate research in 3D spatial intelligence.\n","authors":["Wenyan Cong","Yiqing Liang","Yancheng Zhang","Ziyi Yang","Yan Wang","Boris Ivanovic","Marco Pavone","Chen Chen","Zhangyang Wang","Zhiwen Fan"],"pdf_url":"https://arxiv.org/pdf/2506.01933v3.pdf","comment":"Project Page: https://e3dbench.github.io/"},{"id":"http://arxiv.org/abs/2507.07982v1","updated":"2025-07-10T17:55:08Z","published":"2025-07-10T17:55:08Z","title":"Geometry Forcing: Marrying Video Diffusion and 3D Representation for\n  Consistent World Modeling","summary":"  Videos inherently represent 2D projections of a dynamic 3D world. However,\nour analysis suggests that video diffusion models trained solely on raw video\ndata often fail to capture meaningful geometric-aware structure in their\nlearned representations. To bridge this gap between video diffusion models and\nthe underlying 3D nature of the physical world, we propose Geometry Forcing, a\nsimple yet effective method that encourages video diffusion models to\ninternalize latent 3D representations. Our key insight is to guide the model's\nintermediate representations toward geometry-aware structure by aligning them\nwith features from a pretrained geometric foundation model. To this end, we\nintroduce two complementary alignment objectives: Angular Alignment, which\nenforces directional consistency via cosine similarity, and Scale Alignment,\nwhich preserves scale-related information by regressing unnormalized geometric\nfeatures from normalized diffusion representation. We evaluate Geometry Forcing\non both camera view-conditioned and action-conditioned video generation tasks.\nExperimental results demonstrate that our method substantially improves visual\nquality and 3D consistency over the baseline methods. Project page:\nhttps://GeometryForcing.github.io.\n","authors":["Haoyu Wu","Diankun Wu","Tianyu He","Junliang Guo","Yang Ye","Yueqi Duan","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2507.07982v1.pdf","comment":"18 pages, project page: https://GeometryForcing.github.io"},{"id":"http://arxiv.org/abs/2507.07978v1","updated":"2025-07-10T17:54:27Z","published":"2025-07-10T17:54:27Z","title":"Martian World Models: Controllable Video Synthesis with Physically\n  Accurate 3D Reconstructions","summary":"  Synthesizing realistic Martian landscape videos is crucial for mission\nrehearsal and robotic simulation. However, this task poses unique challenges\ndue to the scarcity of high-quality Martian data and the significant domain gap\nbetween Martian and terrestrial imagery. To address these challenges, we\npropose a holistic solution composed of two key components: 1) A data curation\npipeline Multimodal Mars Synthesis (M3arsSynth), which reconstructs 3D Martian\nenvironments from real stereo navigation images, sourced from NASA's Planetary\nData System (PDS), and renders high-fidelity multiview 3D video sequences. 2) A\nMartian terrain video generator, MarsGen, which synthesizes novel videos\nvisually realistic and geometrically consistent with the 3D structure encoded\nin the data. Our M3arsSynth engine spans a wide range of Martian terrains and\nacquisition dates, enabling the generation of physically accurate 3D surface\nmodels at metric-scale resolution. MarsGen, fine-tuned on M3arsSynth data,\nsynthesizes videos conditioned on an initial image frame and, optionally,\ncamera trajectories or textual prompts, allowing for video generation in novel\nenvironments. Experimental results show that our approach outperforms video\nsynthesis models trained on terrestrial datasets, achieving superior visual\nfidelity and 3D structural consistency.\n","authors":["Longfei Li","Zhiwen Fan","Wenyan Cong","Xinhang Liu","Yuyang Yin","Matt Foutter","Panwang Pan","Chenyu You","Yue Wang","Zhangyang Wang","Yao Zhao","Marco Pavone","Yunchao Wei"],"pdf_url":"https://arxiv.org/pdf/2507.07978v1.pdf","comment":"Project Page: https://marsgenai.github.io"},{"id":"http://arxiv.org/abs/2507.07966v1","updated":"2025-07-10T17:47:40Z","published":"2025-07-10T17:47:40Z","title":"Scaling RL to Long Videos","summary":"  We introduce a full-stack framework that scales up reasoning in\nvision-language models (VLMs) to long videos, leveraging reinforcement\nlearning. We address the unique challenges of long video reasoning by\nintegrating three critical components: (1) a large-scale dataset,\nLongVideo-Reason, comprising 52K long video QA pairs with high-quality\nreasoning annotations across diverse domains such as sports, games, and vlogs;\n(2) a two-stage training pipeline that extends VLMs with chain-of-thought\nsupervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a\ntraining infrastructure for long video RL, named Multi-modal Reinforcement\nSequence Parallelism (MR-SP), which incorporates sequence parallelism and a\nvLLM-based engine tailored for long video, using cached video embeddings for\nefficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves\nstrong performance on long video QA benchmarks such as VideoMME. It also\noutperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal\nreasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on\nour LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to\n2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent\nperformance gains as the number of input video frames scales. LongVILA-R1 marks\na firm step towards long video reasoning in VLMs. In addition, we release our\ntraining system for public availability that supports RL training on various\nmodalities (video, text, and audio), various models (VILA and Qwen series), and\neven image and video generation models. On a single A100 node (8 GPUs), it\nsupports RL training on hour-long videos (e.g., 3,600 frames / around 256k\ntokens).\n","authors":["Yukang Chen","Wei Huang","Baifeng Shi","Qinghao Hu","Hanrong Ye","Ligeng Zhu","Zhijian Liu","Pavlo Molchanov","Jan Kautz","Xiaojuan Qi","Sifei Liu","Hongxu Yin","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2507.07966v1.pdf","comment":"Code and models are available at https://github.com/NVlabs/Long-RL"},{"id":"http://arxiv.org/abs/2507.07954v1","updated":"2025-07-10T17:39:03Z","published":"2025-07-10T17:39:03Z","title":"Input Conditioned Layer Dropping in Speech Foundation Models","summary":"  Curating foundation speech models for edge and IoT settings, where\ncomputational resources vary over time, requires dynamic architectures\nfeaturing adaptable reduction strategies. One emerging approach is layer\ndropping ($\\mathcal{LD}$) which skips fraction of the layers of a backbone\nnetwork during inference to reduce the computational load. This allows\ntransforming static models into dynamic ones. However, existing approaches\nexhibit limitations either in the mode of selecting layers or by significantly\nmodifying the neural architecture. To this end, we propose input-driven\n$\\mathcal{LD}$ that employs the network's input features and a lightweight\nlayer selecting network to determine the optimum combination of processing\nlayers. Extensive experimentation on 4 speech and audio public benchmarks,\nusing two different pre-trained foundation models, demonstrates the\neffectiveness of our approach, thoroughly outperforming random dropping and\nproducing on-par (or better) results to early exit.\n","authors":["Abdul Hannan","Daniele Falavigna","Alessio Brutti"],"pdf_url":"https://arxiv.org/pdf/2507.07954v1.pdf","comment":"Accepted at IEEE MLSP 2025"},{"id":"http://arxiv.org/abs/2505.15804v3","updated":"2025-07-10T17:36:35Z","published":"2025-05-21T17:57:38Z","title":"STAR-R1: Spatial TrAnsformation Reasoning by Reinforcing Multimodal LLMs","summary":"  Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities across diverse tasks, yet they lag significantly behind humans in\nspatial reasoning. We investigate this gap through Transformation-Driven Visual\nReasoning (TVR), a challenging task requiring identification of object\ntransformations across images under varying viewpoints. While traditional\nSupervised Fine-Tuning (SFT) fails to generate coherent reasoning paths in\ncross-view settings, sparse-reward Reinforcement Learning (RL) suffers from\ninefficient exploration and slow convergence. To address these limitations, we\npropose STAR-R1, a novel framework that integrates a single-stage RL paradigm\nwith a fine-grained reward mechanism tailored for TVR. Specifically, STAR-R1\nrewards partial correctness while penalizing excessive enumeration and passive\ninaction, enabling efficient exploration and precise reasoning. Comprehensive\nevaluations demonstrate that STAR-R1 achieves state-of-the-art performance\nacross all 11 metrics, outperforming SFT by 23% in cross-view scenarios.\nFurther analysis reveals STAR-R1's anthropomorphic behavior and highlights its\nunique ability to compare all objects for improving spatial reasoning. Our work\nprovides critical insights in advancing the research of MLLMs and reasoning\nmodels. The codes, model weights, and data will be publicly available at\nhttps://github.com/zongzhao23/STAR-R1.\n","authors":["Zongzhao Li","Zongyang Ma","Mingze Li","Songyou Li","Yu Rong","Tingyang Xu","Ziqi Zhang","Deli Zhao","Wenbing Huang"],"pdf_url":"https://arxiv.org/pdf/2505.15804v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07949v1","updated":"2025-07-10T17:33:52Z","published":"2025-07-10T17:33:52Z","title":"TinierHAR: Towards Ultra-Lightweight Deep Learning Models for Efficient\n  Human Activity Recognition on Edge Devices","summary":"  Human Activity Recognition (HAR) on resource-constrained wearable devices\ndemands inference models that harmonize accuracy with computational efficiency.\nThis paper introduces TinierHAR, an ultra-lightweight deep learning\narchitecture that synergizes residual depthwise separable convolutions, gated\nrecurrent units (GRUs), and temporal aggregation to achieve SOTA efficiency\nwithout compromising performance. Evaluated across 14 public HAR datasets,\nTinierHAR reduces Parameters by 2.7x (vs. TinyHAR) and 43.3x (vs.\nDeepConvLSTM), and MACs by 6.4x and 58.6x, respectively, while maintaining the\naveraged F1-scores. Beyond quantitative gains, this work provides the first\nsystematic ablation study dissecting the contributions of spatial-temporal\ncomponents across proposed TinierHAR, prior SOTA TinyHAR, and the classical\nDeepConvLSTM, offering actionable insights for designing efficient HAR systems.\nWe finally discussed the findings and suggested principled design guidelines\nfor future efficient HAR. To catalyze edge-HAR research, we open-source all\nmaterials in this work for future\nbenchmarking\\footnote{https://github.com/zhaxidele/TinierHAR}\n","authors":["Sizhen Bian","Mengxi Liu","Vitor Fortes Rey","Daniel Geissler","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2507.07949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14993v2","updated":"2025-07-10T17:30:56Z","published":"2024-09-23T13:16:09Z","title":"Multi-modal Generative AI: Multi-modal LLMs, Diffusions and the\n  Unification","summary":"  Multi-modal generative AI (Artificial Intelligence) has attracted increasing\nattention from both academia and industry. Particularly, two dominant families\nof techniques have emerged: i) Multi-modal large language models (LLMs)\ndemonstrate impressive ability for multi-modal understanding; and ii) Diffusion\nmodels exhibit remarkable multi-modal powers in terms of multi-modal\ngeneration. Therefore, this paper provides a comprehensive overview of\nmulti-modal generative AI, including multi-modal LLMs, diffusions, and the\nunification for understanding and generation. To lay a solid foundation for\nunified models, we first provide a detailed review of both multi-modal LLMs and\ndiffusion models respectively, including their probabilistic modeling\nprocedure, multi-modal architecture design, and advanced applications to\nimage/video LLMs as well as text-to-image/video generation. Furthermore, we\nexplore the emerging efforts toward unified models for understanding and\ngeneration. To achieve the unification of understanding and generation, we\ninvestigate key designs including autoregressive-based and diffusion-based\nmodeling, as well as dense and Mixture-of-Experts (MoE) architectures. We then\nintroduce several strategies for unified models, analyzing their potential\nadvantages and disadvantages. In addition, we summarize the common datasets\nwidely used for multi-modal generative AI pretraining. Last but not least, we\npresent several challenging future research directions which may contribute to\nthe ongoing advancement of multi-modal generative AI.\n","authors":["Xin Wang","Yuwei Zhou","Bin Huang","Hong Chen","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2409.14993v2.pdf","comment":"20 pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2501.17468v3","updated":"2025-07-10T17:09:37Z","published":"2025-01-29T08:20:05Z","title":"Solving Inverse Problems using Diffusion with Iterative Colored\n  Renoising","summary":"  Imaging inverse problems can be solved in an unsupervised manner using\npre-trained diffusion models, but doing so requires approximating the gradient\nof the measurement-conditional score function in the diffusion reverse process.\nWe show that the approximations produced by existing methods are relatively\npoor, especially early in the reverse process, and so we propose a new approach\nthat iteratively reestimates and \"renoises\" the estimate several times per\ndiffusion step. This iterative approach, which we call Fast Iterative REnoising\n(FIRE), injects colored noise that is shaped to ensure that the pre-trained\ndiffusion model always sees white noise, in accordance with how it was trained.\nWe then embed FIRE into the DDIM reverse process and show that the resulting\n\"DDfire\" offers state-of-the-art accuracy and runtime on several linear inverse\nproblems, as well as phase retrieval. Our implementation is at\nhttps://github.com/matt-bendel/DDfire\n","authors":["Matt C. Bendel","Saurav K. Shastri","Rizwan Ahmad","Philip Schniter"],"pdf_url":"https://arxiv.org/pdf/2501.17468v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07929v1","updated":"2025-07-10T17:09:14Z","published":"2025-07-10T17:09:14Z","title":"Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and\n  Identification Strategies for Laboratory Mice","summary":"  Continuous, automated monitoring of laboratory mice enables more accurate\ndata collection and improves animal welfare through real-time insights.\nResearchers can achieve a more dynamic and clinically relevant characterization\nof disease progression and therapeutic effects by integrating behavioral and\nphysiological monitoring in the home cage. However, providing individual mouse\nmetrics is difficult because of their housing density, similar appearances,\nhigh mobility, and frequent interactions. To address these challenges, we\ndevelop a real-time identification (ID) algorithm that accurately assigns ID\npredictions to mice wearing custom ear tags in digital home cages monitored by\ncameras. Our pipeline consists of three parts: (1) a custom multiple object\ntracker (MouseTracks) that combines appearance and motion cues from mice; (2) a\ntransformer-based ID classifier (Mouseformer); and (3) a tracklet associator\nlinear program to assign final ID predictions to tracklets (MouseMap). Our\nmodels assign an animal ID based on custom ear tags at 30 frames per second\nwith 24/7 cage coverage. We show that our custom tracking and ID pipeline\nimproves tracking efficiency and lowers ID switches across mouse strains and\nvarious environmental factors compared to current mouse tracking methods.\n","authors":["Juan Pablo Oberhauser","Daniel Grzenda"],"pdf_url":"https://arxiv.org/pdf/2507.07929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07920v1","updated":"2025-07-10T17:00:49Z","published":"2025-07-10T17:00:49Z","title":"ArteryX: Advancing Brain Artery Feature Extraction with Vessel-Fused\n  Networks and a Robust Validation Framework","summary":"  Cerebrovascular pathology significantly contributes to cognitive decline and\nneurological disorders, underscoring the need for advanced tools to assess\nvascular integrity. Three-dimensional Time-of-Flight Magnetic Resonance\nAngiography (3D TOF MRA) is widely used to visualize cerebral vasculature,\nhowever, clinical evaluations generally focus on major arterial abnormalities,\noverlooking quantitative metrics critical for understanding subtle vascular\nchanges. Existing methods for extracting structural, geometrical and\nmorphological arterial features from MRA - whether manual or automated - face\nchallenges including user-dependent variability, steep learning curves, and\nlack of standardized quantitative validations. We propose a novel\nsemi-supervised artery evaluation framework, named ArteryX, a MATLAB-based\ntoolbox that quantifies vascular features with high accuracy and efficiency,\nachieving processing times ~10-15 minutes per subject at 0.5 mm resolution with\nminimal user intervention. ArteryX employs a vessel-fused network based\nlandmarking approach to reliably track and manage tracings, effectively\naddressing the issue of dangling/disconnected vessels. Validation on human\nsubjects with cerebral small vessel disease demonstrated its improved\nsensitivity to subtle vascular changes and better performance than an existing\nsemi-automated method. Importantly, the ArteryX toolbox enables quantitative\nfeature validation by integrating an in-vivo like artery simulation framework\nutilizing vessel-fused graph nodes and predefined ground-truth features for\nspecific artery types. Thus, the ArteryX framework holds promise for\nbenchmarking feature extraction toolboxes and for seamless integration into\nclinical workflows, enabling early detection of cerebrovascular pathology and\nstandardized comparisons across patient cohorts to advance understanding of\nvascular contributions to brain health.\n","authors":["Abrar Faiyaz","Nhat Hoang","Giovanni Schifitto","Md Nasir Uddin"],"pdf_url":"https://arxiv.org/pdf/2507.07920v1.pdf","comment":"14 Pages, 8 Figures, Preliminary version of the toolbox was presented\n  at the ISMRM 2025 Conference in Hawaii at the \"Software Tools\" Session"},{"id":"http://arxiv.org/abs/2507.07908v1","updated":"2025-07-10T16:39:49Z","published":"2025-07-10T16:39:49Z","title":"Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal\n  Inconsistency for Remote Physiological Measurement","summary":"  Remote photoplethysmography (rPPG) has emerged as a promising non-invasive\nmethod for monitoring physiological signals using the camera. Although various\ndomain adaptation and generalization methods were proposed to promote the\nadaptability of deep-based rPPG models in unseen deployment environments,\nconsiderations in aspects like privacy concerns and real-time adaptation\nrestrict their application in real-world deployment. Thus, we aim to propose a\nnovel fully Test-Time Adaptation (TTA) strategy tailored for rPPG tasks in this\nwork. Specifically, based on prior knowledge in physiology and our\nobservations, we noticed not only there is spatio-temporal consistency in the\nfrequency domain of rPPG signals, but also that inconsistency in the time\ndomain was significant. Given this, by leveraging both consistency and\ninconsistency priors, we introduce an innovative expert knowledge-based\nself-supervised\n\\textbf{C}onsistency-\\textbf{i}n\\textbf{C}onsistency-\\textbf{i}ntegration\n(\\textbf{CiCi}) framework to enhances model adaptation during inference.\nBesides, our approach further incorporates a gradient dynamic control mechanism\nto mitigate potential conflicts between priors, ensuring stable adaptation\nacross instances. Through extensive experiments on five diverse datasets under\nthe TTA protocol, our method consistently outperforms existing techniques,\npresenting state-of-the-art performance in real-time self-supervised adaptation\nwithout accessing source data. The code will be released later.\n","authors":["Xiao Yang","Yuxuan Fan","Can Liu","Houcheng Su","Weichen Guo","Jiyao Wang","Dengbo He"],"pdf_url":"https://arxiv.org/pdf/2507.07908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07903v1","updated":"2025-07-10T16:37:20Z","published":"2025-07-10T16:37:20Z","title":"Hardware-Aware Feature Extraction Quantisation for Real-Time Visual\n  Odometry on FPGA Platforms","summary":"  Accurate position estimation is essential for modern navigation systems\ndeployed in autonomous platforms, including ground vehicles, marine vessels,\nand aerial drones. In this context, Visual Simultaneous Localisation and\nMapping (VSLAM) - which includes Visual Odometry - relies heavily on the\nreliable extraction of salient feature points from the visual input data. In\nthis work, we propose an embedded implementation of an unsupervised\narchitecture capable of detecting and describing feature points. It is based on\na quantised SuperPoint convolutional neural network. Our objective is to\nminimise the computational demands of the model while preserving high detection\nquality, thus facilitating efficient deployment on platforms with limited\nresources, such as mobile or embedded systems. We implemented the solution on\nan FPGA System-on-Chip (SoC) platform, specifically the AMD/Xilinx Zynq\nUltraScale+, where we evaluated the performance of Deep Learning Processing\nUnits (DPUs) and we also used the Brevitas library and the FINN framework to\nperform model quantisation and hardware-aware optimisation. This allowed us to\nprocess 640 x 480 pixel images at up to 54 fps on an FPGA platform,\noutperforming state-of-the-art solutions in the field. We conducted experiments\non the TUM dataset to demonstrate and discuss the impact of different\nquantisation techniques on the accuracy and performance of the model in a\nvisual odometry task.\n","authors":["Mateusz Wasala","Mateusz Smolarczyk","Michal Danilowicz","Tomasz Kryjak"],"pdf_url":"https://arxiv.org/pdf/2507.07903v1.pdf","comment":"Accepted for the DSD 2025 conference in Salerno, Italy"},{"id":"http://arxiv.org/abs/2507.07902v1","updated":"2025-07-10T16:33:50Z","published":"2025-07-10T16:33:50Z","title":"MIRA: A Novel Framework for Fusing Modalities in Medical RAG","summary":"  Multimodal Large Language Models (MLLMs) have significantly advanced\nAI-assisted medical diagnosis, but they often generate factually inconsistent\nresponses that deviate from established medical knowledge. Retrieval-Augmented\nGeneration (RAG) enhances factual accuracy by integrating external sources, but\nit presents two key challenges. First, insufficient retrieval can miss critical\ninformation, whereas excessive retrieval can introduce irrelevant or misleading\ncontent, disrupting model output. Second, even when the model initially\nprovides correct answers, over-reliance on retrieved data can lead to factual\nerrors. To address these issues, we introduce the Multimodal Intelligent\nRetrieval and Augmentation (MIRA) framework, designed to optimize factual\naccuracy in MLLM. MIRA consists of two key components: (1) a calibrated\nRethinking and Rearrangement module that dynamically adjusts the number of\nretrieved contexts to manage factual risk, and (2) A medical RAG framework\nintegrating image embeddings and a medical knowledge base with a query-rewrite\nmodule for efficient multimodal reasoning. This enables the model to\neffectively integrate both its inherent knowledge and external references. Our\nevaluation of publicly available medical VQA and report generation benchmarks\ndemonstrates that MIRA substantially enhances factual accuracy and overall\nperformance, achieving new state-of-the-art results. Code is released at\nhttps://github.com/mbzuai-oryx/MIRA.\n","authors":["Jinhong Wang","Tajamul Ashraf","Zongyan Han","Jorma Laaksonen","Rao Mohammad Anwer"],"pdf_url":"https://arxiv.org/pdf/2507.07902v1.pdf","comment":"ACM Multimedia 2025"},{"id":"http://arxiv.org/abs/2507.01788v2","updated":"2025-07-10T16:23:29Z","published":"2025-07-02T15:14:06Z","title":"Are Vision Transformer Representations Semantically Meaningful? A Case\n  Study in Medical Imaging","summary":"  Vision transformers (ViTs) have rapidly gained prominence in medical imaging\ntasks such as disease classification, segmentation, and detection due to their\nsuperior accuracy compared to conventional deep learning models. However, due\nto their size and complex interactions via the self-attention mechanism, they\nare not well understood. In particular, it is unclear whether the\nrepresentations produced by such models are semantically meaningful. In this\npaper, using a projected gradient-based algorithm, we show that their\nrepresentations are not semantically meaningful and they are inherently\nvulnerable to small changes. Images with imperceptible differences can have\nvery different representations; on the other hand, images that should belong to\ndifferent semantic classes can have nearly identical representations. Such\nvulnerability can lead to unreliable classification results; for example,\nunnoticeable changes cause the classification accuracy to be reduced by over\n60\\%. %. To the best of our knowledge, this is the first work to systematically\ndemonstrate this fundamental lack of semantic meaningfulness in ViT\nrepresentations for medical image classification, revealing a critical\nchallenge for their deployment in safety-critical systems.\n","authors":["Montasir Shams","Chashi Mahiul Islam","Shaeke Salman","Phat Tran","Xiuwen Liu"],"pdf_url":"https://arxiv.org/pdf/2507.01788v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2408.06687v3","updated":"2025-07-10T16:14:55Z","published":"2024-08-13T07:27:02Z","title":"Masked Image Modeling: A Survey","summary":"  In this work, we survey recent studies on masked image modeling (MIM), an\napproach that emerged as a powerful self-supervised learning technique in\ncomputer vision. The MIM task involves masking some information, e.g. pixels,\npatches, or even latent representations, and training a model, usually an\nautoencoder, to predicting the missing information by using the context\navailable in the visible part of the input. We identify and formalize two\ncategories of approaches on how to implement MIM as a pretext task, one based\non reconstruction and one based on contrastive learning. Then, we construct a\ntaxonomy and review the most prominent papers in recent years. We complement\nthe manually constructed taxonomy with a dendrogram obtained by applying a\nhierarchical clustering algorithm. We further identify relevant clusters via\nmanually inspecting the resulting dendrogram. Our review also includes datasets\nthat are commonly used in MIM research. We aggregate the performance results of\nvarious masked image modeling methods on the most popular datasets, to\nfacilitate the comparison of competing methods. Finally, we identify research\ngaps and propose several interesting directions of future work. We supplement\nour survey with the following public repository containing organized\nreferences: https://github.com/vladhondru25/MIM-Survey.\n","authors":["Vlad Hondru","Florinel Alin Croitoru","Shervin Minaee","Radu Tudor Ionescu","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2408.06687v3.pdf","comment":"Accepted at the International Journal of Computer Vision"},{"id":"http://arxiv.org/abs/2507.07878v1","updated":"2025-07-10T16:02:07Z","published":"2025-07-10T16:02:07Z","title":"Single-Step Latent Diffusion for Underwater Image Restoration","summary":"  Underwater image restoration algorithms seek to restore the color, contrast,\nand appearance of a scene that is imaged underwater. They are a critical tool\nin applications ranging from marine ecology and aquaculture to underwater\nconstruction and archaeology. While existing pixel-domain diffusion-based image\nrestoration approaches are effective at restoring simple scenes with limited\ndepth variation, they are computationally intensive and often generate\nunrealistic artifacts when applied to scenes with complex geometry and\nsignificant depth variation. In this work we overcome these limitations by\ncombining a novel network architecture (SLURPP) with an accurate synthetic data\ngeneration pipeline. SLURPP combines pretrained latent diffusion models --\nwhich encode strong priors on the geometry and depth of scenes -- with an\nexplicit scene decomposition -- which allows one to model and account for the\neffects of light attenuation and backscattering. To train SLURPP we design a\nphysics-based underwater image synthesis pipeline that applies varied and\nrealistic underwater degradation effects to existing terrestrial image\ndatasets. This approach enables the generation of diverse training data with\ndense medium/degradation annotations. We evaluate our method extensively on\nboth synthetic and real-world benchmarks and demonstrate state-of-the-art\nperformance. Notably, SLURPP is over 200X faster than existing diffusion-based\nmethods while offering ~ 3 dB improvement in PSNR on synthetic benchmarks. It\nalso offers compelling qualitative improvements on real-world data. Project\nwebsite https://tianfwang.github.io/slurpp/.\n","authors":["Jiayi Wu","Tianfu Wang","Md Abu Bakr Siddique","Md Jahidul Islam","Cornelia Fermuller","Yiannis Aloimonos","Christopher A. Metzler"],"pdf_url":"https://arxiv.org/pdf/2507.07878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18813v3","updated":"2025-07-10T15:45:38Z","published":"2024-09-27T15:06:05Z","title":"EyeTrAES: Fine-grained, Low-Latency Eye Tracking via Adaptive Event\n  Slicing","summary":"  Eye-tracking technology has gained significant attention in recent years due\nto its wide range of applications in human-computer interaction, virtual and\naugmented reality, and wearable health. Traditional RGB camera-based\neye-tracking systems often struggle with poor temporal resolution and\ncomputational constraints, limiting their effectiveness in capturing rapid eye\nmovements. To address these limitations, we propose EyeTrAES, a novel approach\nusing neuromorphic event cameras for high-fidelity tracking of natural\npupillary movement that shows significant kinematic variance. One of EyeTrAES's\nhighlights is the use of a novel adaptive windowing/slicing algorithm that\nensures just the right amount of descriptive asynchronous event data\naccumulation within an event frame, across a wide range of eye movement\npatterns. EyeTrAES then applies lightweight image processing functions over\naccumulated event frames from just a single eye to perform pupil segmentation\nand tracking. We show that these methods boost pupil tracking fidelity by 6+%,\nachieving IoU~=92%, while incurring at least 3x lower latency than competing\npure event-based eye tracking alternatives [38]. We additionally demonstrate\nthat the microscopic pupillary motion captured by EyeTrAES exhibits distinctive\nvariations across individuals and can thus serve as a biometric fingerprint.\nFor robust user authentication, we train a lightweight per-user Random Forest\nclassifier using a novel feature vector of short-term pupillary kinematics,\ncomprising a sliding window of pupil (location, velocity, acceleration)\ntriples. Experimental studies with two different datasets demonstrate that the\nEyeTrAES-based authentication technique can simultaneously achieve high\nauthentication accuracy (~=0.82) and low processing latency (~=12ms), and\nsignificantly outperform multiple state-of-the-art competitive baselines.\n","authors":["Argha Sen","Nuwan Bandara","Ila Gokarn","Thivya Kandappu","Archan Misra"],"pdf_url":"https://arxiv.org/pdf/2409.18813v3.pdf","comment":"32 pages,15 figures,"},{"id":"http://arxiv.org/abs/2507.07860v1","updated":"2025-07-10T15:41:35Z","published":"2025-07-10T15:41:35Z","title":"THUNDER: Tile-level Histopathology image UNDERstanding benchmark","summary":"  Progress in a research field can be hard to assess, in particular when many\nconcurrent methods are proposed in a short period of time. This is the case in\ndigital pathology, where many foundation models have been released recently to\nserve as feature extractors for tile-level images, being used in a variety of\ndownstream tasks, both for tile- and slide-level problems. Benchmarking\navailable methods then becomes paramount to get a clearer view of the research\nlandscape. In particular, in critical domains such as healthcare, a benchmark\nshould not only focus on evaluating downstream performance, but also provide\ninsights about the main differences between methods, and importantly, further\nconsider uncertainty and robustness to ensure a reliable usage of proposed\nmodels. For these reasons, we introduce THUNDER, a tile-level benchmark for\ndigital pathology foundation models, allowing for efficient comparison of many\nmodels on diverse datasets with a series of downstream tasks, studying their\nfeature spaces and assessing the robustness and uncertainty of predictions\ninformed by their embeddings. THUNDER is a fast, easy-to-use, dynamic benchmark\nthat can already support a large variety of state-of-the-art foundation, as\nwell as local user-defined models for direct tile-based comparison. In this\npaper, we provide a comprehensive comparison of 23 foundation models on 16\ndifferent datasets covering diverse tasks, feature analysis, and robustness.\nThe code for THUNDER is publicly available at\nhttps://github.com/MICS-Lab/thunder.\n","authors":["Pierre Marza","Leo Fillioux","Sofiène Boutaj","Kunal Mahatha","Christian Desrosiers","Pablo Piantanida","Jose Dolz","Stergios Christodoulidis","Maria Vakalopoulou"],"pdf_url":"https://arxiv.org/pdf/2507.07860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06167v3","updated":"2025-07-10T15:41:04Z","published":"2025-07-08T16:47:16Z","title":"Skywork-R1V3 Technical Report","summary":"  We introduce Skywork-R1V3, an advanced, open-source vision-language model\n(VLM) that pioneers a new approach to visual reasoning. Its key innovation lies\nin effectively transferring reasoning skills from text-only Large Language\nModels (LLMs) to visual tasks. The strong performance of Skywork-R1V3 primarily\nstems from our elaborate post-training RL framework, which effectively\nactivates and enhances the model's reasoning ability, without the need for\nadditional continue pre-training. Through this framework, we further uncover\nthe fundamental role of the connector module in achieving robust cross-modal\nalignment for multimodal reasoning models. In addition, we introduce a unique\nindicator of reasoning capability, the entropy of critical reasoning tokens,\nwhich has proven highly effective for checkpoint selection during RL training.\nSkywork-R1V3 achieves state-of-the-art results on MMMU, significantly improving\nfrom 64.3% to 76.0%. This performance matches entry-level human capabilities.\nRemarkably, our RL-powered post-training approach enables even the 38B\nparameter model to rival top closed-source VLMs. The implementation\nsuccessfully transfers mathematical reasoning to other subject-related\nreasoning tasks. We also include an analysis of curriculum learning and\nreinforcement finetuning strategies, along with a broader discussion on\nmultimodal reasoning. Skywork-R1V3 represents a significant leap in multimodal\nreasoning, showcasing RL as a powerful engine for advancing open-source VLM\ncapabilities.\n","authors":["Wei Shen","Jiangbo Pei","Yi Peng","Xuchen Song","Yang Liu","Jian Peng","Haofeng Sun","Yunzhuo Hao","Peiyu Wang","Jianhao Zhang","Yahui Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.06167v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15469v2","updated":"2025-07-10T15:14:36Z","published":"2024-11-23T06:36:16Z","title":"Mamba-CL: Optimizing Selective State Space Model in Null Space for\n  Continual Learning","summary":"  Continual Learning (CL) aims to equip AI models with the ability to learn a\nsequence of tasks over time, without forgetting previously learned knowledge.\nRecently, State Space Models (SSMs), particularly the Mamba model, have\nachieved notable success in computer vision. Building on the strengths of SSMs,\nthis study explores leveraging the Mamba model for CL. Therefore, we introduce\nMamba-CL, a framework that continuously fine-tunes the core SSMs of the\nlarge-scale Mamba foundation model by updating parameters orthogonal to the\nfeature subspace of previous tasks. This approach theoretically guarantees the\nconsistency objective aiming to preserves consistent output for each SSM module\nacross both previous and current tasks, so as to overcome catastrophic\nforgetting issue. Specifically, we achieve this goal by deducing the overall\nconsistency constraints on four key time-invariant parameters in the Mamba\nmodel, streamlining its recurrent state-space structure and non-linear\ndiscretization process in SSM. In practice, we apply the null-space projection\nto efficiently implement the orthogonality within Mamba model. Extensive\nexperiments on four class-incremental benchmarks demonstrate the effectiveness\nof Mamba-CL for anti-forgetting, achieving superior performances to\nstate-of-the-art methods. Code is available in the supplementary materials.\n","authors":["De Cheng","Yue Lu","Lingfeng He","Shizhou Zhang","Xi Yang","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2411.15469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07839v1","updated":"2025-07-10T15:11:09Z","published":"2025-07-10T15:11:09Z","title":"MeD-3D: A Multimodal Deep Learning Framework for Precise Recurrence\n  Prediction in Clear Cell Renal Cell Carcinoma (ccRCC)","summary":"  Accurate prediction of recurrence in clear cell renal cell carcinoma (ccRCC)\nremains a major clinical challenge due to the disease complex molecular,\npathological, and clinical heterogeneity. Traditional prognostic models, which\nrely on single data modalities such as radiology, histopathology, or genomics,\noften fail to capture the full spectrum of disease complexity, resulting in\nsuboptimal predictive accuracy. This study aims to overcome these limitations\nby proposing a deep learning (DL) framework that integrates multimodal data,\nincluding CT, MRI, histopathology whole slide images (WSI), clinical data, and\ngenomic profiles, to improve the prediction of ccRCC recurrence and enhance\nclinical decision-making. The proposed framework utilizes a comprehensive\ndataset curated from multiple publicly available sources, including TCGA, TCIA,\nand CPTAC. To process the diverse modalities, domain-specific models are\nemployed: CLAM, a ResNet50-based model, is used for histopathology WSIs, while\nMeD-3D, a pre-trained 3D-ResNet18 model, processes CT and MRI images. For\nstructured clinical and genomic data, a multi-layer perceptron (MLP) is used.\nThese models are designed to extract deep feature embeddings from each\nmodality, which are then fused through an early and late integration\narchitecture. This fusion strategy enables the model to combine complementary\ninformation from multiple sources. Additionally, the framework is designed to\nhandle incomplete data, a common challenge in clinical settings, by enabling\ninference even when certain modalities are missing.\n","authors":["Hasaan Maqsood","Saif Ur Rehman Khan"],"pdf_url":"https://arxiv.org/pdf/2507.07839v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07838v1","updated":"2025-07-10T15:09:20Z","published":"2025-07-10T15:09:20Z","title":"3D-ADAM: A Dataset for 3D Anomaly Detection in Advanced Manufacturing","summary":"  Surface defects are one of the largest contributors to low yield in the\nmanufacturing sector. Accurate and reliable detection of defects during the\nmanufacturing process is therefore of great value across the sector.\nState-of-the-art approaches to automated defect detection yield impressive\nperformance on current datasets, yet still fall short in real-world\nmanufacturing settings and developing improved methods relies on large datasets\nrepresentative of real-world scenarios. Unfortunately, high-quality,\nhigh-precision RGB+3D industrial anomaly detection datasets are scarce, and\ntypically do not reflect real-world industrial deployment scenarios. To address\nthis, we introduce 3D-ADAM, the first large-scale industry-relevant dataset for\nhigh-precision 3D Anomaly Detection. 3D-ADAM comprises 14,120 high-resolution\nscans across 217 unique parts, captured using 4 industrial depth imaging\nsensors. It includes 27,346 annotated defect instances from 12 categories,\ncovering the breadth of industrial surface defects. 3D-ADAM uniquely captures\nan additional 8,110 annotations of machine element features, spanning the range\nof relevant mechanical design form factors. Unlike existing datasets, 3D-ADAM\nis captured in a real industrial environment with variations in part position\nand orientation, camera positioning, ambient lighting conditions, as well as\npartial occlusions. Our evaluation of SOTA models across various RGB+3D anomaly\ndetection tasks demonstrates the significant challenge this dataset presents to\ncurrent approaches. We further validated the industrial relevance and quality\nof the dataset through an expert labelling survey conducted by industry\npartners. By providing this challenging benchmark, 3D-ADAM aims to accelerate\nthe development of robust 3D Anomaly Detection models capable of meeting the\ndemands of modern manufacturing environments.\n","authors":["Paul McHard","Florent P. Audonnet","Oliver Summerell","Sebastian Andraos","Paul Henderson","Gerardo Aragon-Camarasa"],"pdf_url":"https://arxiv.org/pdf/2507.07838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07831v1","updated":"2025-07-10T15:03:10Z","published":"2025-07-10T15:03:10Z","title":"Rethinking Query-based Transformer for Continual Image Segmentation","summary":"  Class-incremental/Continual image segmentation (CIS) aims to train an image\nsegmenter in stages, where the set of available categories differs at each\nstage. To leverage the built-in objectness of query-based transformers, which\nmitigates catastrophic forgetting of mask proposals, current methods often\ndecouple mask generation from the continual learning process. This study,\nhowever, identifies two key issues with decoupled frameworks: loss of\nplasticity and heavy reliance on input data order. To address these, we conduct\nan in-depth investigation of the built-in objectness and find that highly\naggregated image features provide a shortcut for queries to generate masks\nthrough simple feature alignment. Based on this, we propose SimCIS, a simple\nyet powerful baseline for CIS. Its core idea is to directly select image\nfeatures for query assignment, ensuring \"perfect alignment\" to preserve\nobjectness, while simultaneously allowing queries to select new classes to\npromote plasticity. To further combat catastrophic forgetting of categories, we\nintroduce cross-stage consistency in selection and an innovative \"visual\nquery\"-based replay mechanism. Experiments demonstrate that SimCIS consistently\noutperforms state-of-the-art methods across various segmentation tasks,\nsettings, splits, and input data orders. All models and codes will be made\npublicly available at https://github.com/SooLab/SimCIS.\n","authors":["Yuchen Zhu","Cheng Shi","Dingyou Wang","Jiajin Tang","Zhengxuan Wei","Yu Wu","Guanbin Li","Sibei Yang"],"pdf_url":"https://arxiv.org/pdf/2507.07831v1.pdf","comment":"This work is accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2507.07828v1","updated":"2025-07-10T15:01:23Z","published":"2025-07-10T15:01:23Z","title":"Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles","summary":"  Content-based puzzle solvers have been extensively studied, demonstrating\nsignificant progress in computational techniques. However, their evaluation\noften lacks realistic challenges crucial for real-world applications, such as\nthe reassembly of fragmented artefacts or shredded documents. In this work, we\ninvestigate the robustness of State-Of-The-Art content-based puzzle solvers\nintroducing three types of jigsaw puzzle corruptions: missing pieces, eroded\nedges, and eroded contents. Evaluating both heuristic and deep learning-based\nsolvers, we analyse their ability to handle these corruptions and identify key\nlimitations. Our results show that solvers developed for standard puzzles have\na rapid decline in performance if more pieces are corrupted. However, deep\nlearning models can significantly improve their robustness through fine-tuning\nwith augmented data. Notably, the advanced Positional Diffusion model adapts\nparticularly well, outperforming its competitors in most experiments. Based on\nour findings, we highlight promising research directions for enhancing the\nautomated reconstruction of real-world artefacts.\n","authors":["Richard Dirauf","Florian Wolz","Dario Zanca","Björn Eskofier"],"pdf_url":"https://arxiv.org/pdf/2507.07828v1.pdf","comment":"Accepted at ICIAP 2025"},{"id":"http://arxiv.org/abs/2506.18903v2","updated":"2025-07-10T14:56:24Z","published":"2025-06-23T17:59:56Z","title":"VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed\n  View Memory","summary":"  We propose a novel memory mechanism to build video generators that can\nexplore environments interactively. Similar results have previously been\nachieved by out-painting 2D views of the scene while incrementally\nreconstructing its 3D geometry, which quickly accumulates errors, or by video\ngenerators with a short context window, which struggle to maintain scene\ncoherence over the long term. To address these limitations, we introduce\nSurfel-Indexed View Memory (VMem), a mechanism that remembers past views by\nindexing them geometrically based on the 3D surface elements (surfels) they\nhave observed. VMem enables the efficient retrieval of the most relevant past\nviews when generating new ones. By focusing only on these relevant views, our\nmethod produces consistent explorations of imagined environments at a fraction\nof the computational cost of using all past views as context. We evaluate our\napproach on challenging long-term scene synthesis benchmarks and demonstrate\nsuperior performance compared to existing methods in maintaining scene\ncoherence and camera control.\n","authors":["Runjia Li","Philip Torr","Andrea Vedaldi","Tomas Jakab"],"pdf_url":"https://arxiv.org/pdf/2506.18903v2.pdf","comment":"Project page: https://v-mem.github.io"},{"id":"http://arxiv.org/abs/2503.11498v3","updated":"2025-07-10T14:56:07Z","published":"2025-03-14T15:26:02Z","title":"Open-source automatic pipeline for efficient conversion of large-scale\n  point clouds to IFC format","summary":"  Building Information Modeling (BIM) is an essential component in the\nsustainable reconstruction and revitalization of ageing structures. However,\nmodel creation usually relies on laborious manual transformation of the\nunstructured point cloud data provided by laser scans or photogrammetry. This\npaper presents Cloud2BIM, an open-source software tool designed to automate the\nconversion of point clouds into BIM models compliant with the Industry\nFoundation Classes (IFC) standard. Cloud2BIM integrates advanced algorithms for\nwall and slab segmentation, opening detection, and room zoning based on real\nwall surfaces, resulting in a comprehensive and fully automated workflow.\nUnlike existing tools, it avoids computationally- and calibration-intensive\ntechniques such as RANSAC, supports non-orthogonal geometries, and provides\nunprecedented processing speed-achieving results up to seven times faster than\nfastest competing solutions. Systematic validation using benchmark datasets\nconfirms that Cloud2BIM is an easy-to-use, efficient, and scalable solution for\ngenerating accurate BIM models, capable of converting extensive point cloud\ndatasets for entire buildings into IFC format with minimal user input.\n","authors":["Slávek Zbirovský","Václav Nežerka"],"pdf_url":"https://arxiv.org/pdf/2503.11498v3.pdf","comment":"published version, 23 pages, 25 figures"},{"id":"http://arxiv.org/abs/2507.02148v2","updated":"2025-07-10T14:55:57Z","published":"2025-07-02T21:06:39Z","title":"Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and\n  Synthetic Fine-Tuning with Vision Foundation Models","summary":"  Monocular depth estimation has recently progressed beyond ordinal depth to\nprovide metric depth predictions. However, its reliability in underwater\nenvironments remains limited due to light attenuation and scattering, color\ndistortion, turbidity, and the lack of high-quality metric ground truth data.\nIn this paper, we present a comprehensive benchmark of zero-shot and fine-tuned\nmonocular metric depth estimation models on real-world underwater datasets with\nmetric depth annotations, including FLSea and SQUID. We evaluated a diverse set\nof state-of-the-art Vision Foundation Models across a range of underwater\nconditions and depth ranges. Our results show that large-scale models trained\non terrestrial data (real or synthetic) are effective in in-air settings, but\nperform poorly underwater due to significant domain shifts. To address this, we\nfine-tune Depth Anything V2 with a ViT-S backbone encoder on a synthetic\nunderwater variant of the Hypersim dataset, which we simulated using a\nphysically based underwater image formation model. Our fine-tuned model\nconsistently improves performance across all benchmarks and outperforms\nbaselines trained only on the clean in-air Hypersim dataset. This study\npresents a detailed evaluation and visualization of monocular metric depth\nestimation in underwater scenes, emphasizing the importance of domain\nadaptation and scale-aware supervision for achieving robust and generalizable\nmetric depth predictions using foundation models in challenging environments.\n","authors":["Zijie Cai","Christopher Metzler"],"pdf_url":"https://arxiv.org/pdf/2507.02148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.05116v2","updated":"2025-07-10T14:53:51Z","published":"2025-07-07T15:30:55Z","title":"VOTE: Vision-Language-Action Optimization with Trajectory Ensemble\n  Voting","summary":"  Recent large-scale Vision Language Action (VLA) models have shown superior\nperformance in robotic manipulation tasks guided by natural language. However,\ntheir generalization remains limited when applied to novel objects or\nunfamiliar environments that lie outside the training distribution. To address\nthis, many existing approaches integrate additional components such as depth\nestimation, segmentation, or even diffusion to improve generalization, at the\ncost of adding significant computation overhead, resulting in low efficiency.\nThis motivates the exploration of efficient action prediction methods, which\nare independent of additional high-level visual representations or diffusion\ntechniques. In this work, we propose VOTE, an efficient and general framework\nfor the optimization and acceleration of VLA models. In details, we propose a\nnovel tokenizer-free fine-tuning approach for parallel accurate action\nprediction, which reduces computational overhead and accelerates inference\nspeed. Additionally, we adopt an ensemble voting strategy for the action\nsampling, which significantly improves model performance and enhances\ngeneralization. Experimental results show that our method achieves\nstate-of-the-art performance with 35x faster inference and 145 Hz throughput.\nAll the details and codes will be open-sourced.\n","authors":["Juyi Lin","Amir Taherin","Arash Akbari","Arman Akbari","Lei Lu","Guangyu Chen","Taskin Padir","Xiaomeng Yang","Weiwei Chen","Yiqian Li","Xue Lin","David Kaeli","Pu Zhao","Yanzhi Wang"],"pdf_url":"https://arxiv.org/pdf/2507.05116v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07811v1","updated":"2025-07-10T14:40:52Z","published":"2025-07-10T14:40:52Z","title":"Patient-specific vs Multi-Patient Vision Transformer for Markerless\n  Tumor Motion Forecasting","summary":"  Background: Accurate forecasting of lung tumor motion is essential for\nprecise dose delivery in proton therapy. While current markerless methods\nmostly rely on deep learning, transformer-based architectures remain unexplored\nin this domain, despite their proven performance in trajectory forecasting.\n  Purpose: This work introduces a markerless forecasting approach for lung\ntumor motion using Vision Transformers (ViT). Two training strategies are\nevaluated under clinically realistic constraints: a patient-specific (PS)\napproach that learns individualized motion patterns, and a multi-patient (MP)\nmodel designed for generalization. The comparison explicitly accounts for the\nlimited number of images that can be generated between planning and treatment\nsessions.\n  Methods: Digitally reconstructed radiographs (DRRs) derived from planning\n4DCT scans of 31 patients were used to train the MP model; a 32nd patient was\nheld out for evaluation. PS models were trained using only the target patient's\nplanning data. Both models used 16 DRRs per input and predicted tumor motion\nover a 1-second horizon. Performance was assessed using Average Displacement\nError (ADE) and Final Displacement Error (FDE), on both planning (T1) and\ntreatment (T2) data.\n  Results: On T1 data, PS models outperformed MP models across all training set\nsizes, especially with larger datasets (up to 25,000 DRRs, p < 0.05). However,\nMP models demonstrated stronger robustness to inter-fractional anatomical\nvariability and achieved comparable performance on T2 data without retraining.\n  Conclusions: This is the first study to apply ViT architectures to markerless\ntumor motion forecasting. While PS models achieve higher precision, MP models\noffer robust out-of-the-box performance, well-suited for time-constrained\nclinical settings.\n","authors":["Gauthier Rotsart de Hertaing","Dani Manjah","Benoit Macq"],"pdf_url":"https://arxiv.org/pdf/2507.07811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07802v1","updated":"2025-07-10T14:28:12Z","published":"2025-07-10T14:28:12Z","title":"Synergistic Prompting for Robust Visual Recognition with Missing\n  Modalities","summary":"  Large-scale multi-modal models have demonstrated remarkable performance\nacross various visual recognition tasks by leveraging extensive paired\nmulti-modal training data. However, in real-world applications, the presence of\nmissing or incomplete modality inputs often leads to significant performance\ndegradation. Recent research has focused on prompt-based strategies to tackle\nthis issue; however, existing methods are hindered by two major limitations:\n(1) static prompts lack the flexibility to adapt to varying missing-data\nconditions, and (2) basic prompt-tuning methods struggle to ensure reliable\nperformance when critical modalities are missing.To address these challenges,\nwe propose a novel Synergistic Prompting (SyP) framework for robust visual\nrecognition with missing modalities. The proposed SyP introduces two key\ninnovations: (I) a Dynamic Adapter, which computes adaptive scaling factors to\ndynamically generate prompts, replacing static parameters for flexible\nmulti-modal adaptation, and (II) a Synergistic Prompting Strategy, which\ncombines static and dynamic prompts to balance information across modalities,\nensuring robust reasoning even when key modalities are missing. The proposed\nSyP achieves significant performance improvements over existing approaches\nacross three widely-used visual recognition datasets, demonstrating robustness\nunder diverse missing rates and conditions. Extensive experiments and ablation\nstudies validate its effectiveness in handling missing modalities, highlighting\nits superior adaptability and reliability.\n","authors":["Zhihui Zhang","Luanyuan Dai","Qika Lin","Yunfeng Diao","Guangyin Jin","Yufei Guo","Jing Zhang","Xiaoshuai Hao"],"pdf_url":"https://arxiv.org/pdf/2507.07802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07800v1","updated":"2025-07-10T14:26:50Z","published":"2025-07-10T14:26:50Z","title":"Adaptive Attention Residual U-Net for curvilinear structure segmentation\n  in fluorescence microscopy and biomedical images","summary":"  Segmenting curvilinear structures in fluorescence microscopy remains a\nchallenging task, particularly under noisy conditions and in dense filament\nnetworks commonly seen in vivo. To address this, we created two original\ndatasets consisting of hundreds of synthetic images of fluorescently labelled\nmicrotubules within cells. These datasets are precisely annotated and closely\nmimic real microscopy images, including realistic noise. The second dataset\npresents an additional challenge, by simulating varying fluorescence\nintensities along filaments that complicate segmentation. While deep learning\nhas shown strong potential in biomedical image analysis, its performance often\ndeclines in noisy or low-contrast conditions. To overcome this limitation, we\ndeveloped a novel advanced architecture: the Adaptive Squeeze-and-Excitation\nResidual U-Net (ASE_Res_UNet). This model enhanced the standard U-Net by\nintegrating residual blocks in the encoder and adaptive SE attention mechanisms\nin the decoder. Through ablation studies and comprehensive visual and\nquantitative evaluations, ASE_Res_UNet consistently outperformed its variants,\nnamely standard U-Net, ASE_UNet and Res_UNet architectures. These improvements,\nparticularly in noise resilience and detecting fine, low-intensity structures,\nwere largely attributed to the adaptive SE attention module that we created. We\nfurther benchmarked ASE_Res_UNet against various state-of-the-art models, and\nfound it achieved superior performance on our most challenging dataset.\nFinally, the model also generalized well to real microscopy images of stained\nmicrotubules as well as to other curvilinear structures. Indeed, it\nsuccessfully segmented retinal blood vessels and nerves in noisy or\nlow-contrast biomedical images, demonstrating its strong potential for\napplications in disease diagnosis and treatment.\n","authors":["Achraf Ait Laydi","Louis Cueff","Mewen Crespo","Yousef El Mourabit","Hélène Bouvrais"],"pdf_url":"https://arxiv.org/pdf/2507.07800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07796v1","updated":"2025-07-10T14:23:15Z","published":"2025-07-10T14:23:15Z","title":"Visual Instance-aware Prompt Tuning","summary":"  Visual Prompt Tuning (VPT) has emerged as a parameter-efficient fine-tuning\nparadigm for vision transformers, with conventional approaches utilizing\ndataset-level prompts that remain the same across all input instances. We\nobserve that this strategy results in sub-optimal performance due to high\nvariance in downstream datasets. To address this challenge, we propose Visual\nInstance-aware Prompt Tuning (ViaPT), which generates instance-aware prompts\nbased on each individual input and fuses them with dataset-level prompts,\nleveraging Principal Component Analysis (PCA) to retain important prompting\ninformation. Moreover, we reveal that VPT-Deep and VPT-Shallow represent two\ncorner cases based on a conceptual understanding, in which they fail to\neffectively capture instance-specific information, while random dimension\nreduction on prompts only yields performance between the two extremes. Instead,\nViaPT overcomes these limitations by balancing dataset-level and instance-level\nknowledge, while reducing the amount of learnable parameters compared to\nVPT-Deep. Extensive experiments across 34 diverse datasets demonstrate that our\nmethod consistently outperforms state-of-the-art baselines, establishing a new\nparadigm for analyzing and optimizing visual prompts for vision transformers.\n","authors":["Xi Xiao","Yunbei Zhang","Xingjian Li","Tianyang Wang","Xiao Wang","Yuxiang Wei","Jihun Hamm","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2507.07796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07795v1","updated":"2025-07-10T14:23:11Z","published":"2025-07-10T14:23:11Z","title":"Robust and Generalizable Heart Rate Estimation via Deep Learning for\n  Remote Photoplethysmography in Complex Scenarios","summary":"  Non-contact remote photoplethysmography (rPPG) technology enables heart rate\nmeasurement from facial videos. However, existing network models still face\nchallenges in accu racy, robustness, and generalization capability under\ncomplex scenarios. This paper proposes an end-to-end rPPG extraction network\nthat employs 3D convolutional neural networks to reconstruct accurate rPPG\nsignals from raw facial videos. We introduce a differential frame fusion module\nthat integrates differential frames with original frames, enabling frame-level\nrepresentations to capture blood volume pulse (BVP) variations. Additionally,\nwe incorporate Temporal Shift Module (TSM) with self-attention mechanisms,\nwhich effectively enhance rPPG features with minimal computational overhead.\nFurthermore, we propose a novel dynamic hybrid loss function that provides\nstronger supervision for the network, effectively mitigating over fitting.\nComprehensive experiments were conducted on not only the PURE and UBFC-rPPG\ndatasets but also the challenging MMPD dataset under complex scenarios,\ninvolving both intra dataset and cross-dataset evaluations, which demonstrate\nthe superior robustness and generalization capability of our network.\nSpecifically, after training on PURE, our model achieved a mean absolute error\n(MAE) of 7.58 on the MMPD test set, outperforming the state-of-the-art models.\n","authors":["Kang Cen","Chang-Hong Fu","Hong Hong"],"pdf_url":"https://arxiv.org/pdf/2507.07795v1.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2507.06410v2","updated":"2025-07-10T14:19:51Z","published":"2025-07-08T21:26:33Z","title":"Attention-Enhanced Deep Learning Ensemble for Breast Density\n  Classification in Mammography","summary":"  Breast density assessment is a crucial component of mammographic\ninterpretation, with high breast density (BI-RADS categories C and D)\nrepresenting both a significant risk factor for developing breast cancer and a\ntechnical challenge for tumor detection. This study proposes an automated deep\nlearning system for robust binary classification of breast density (low: A/B\nvs. high: C/D) using the VinDr-Mammo dataset. We implemented and compared four\nadvanced convolutional neural networks: ResNet18, ResNet50, EfficientNet-B0,\nand DenseNet121, each enhanced with channel attention mechanisms. To address\nthe inherent class imbalance, we developed a novel Combined Focal Label\nSmoothing Loss function that integrates focal loss, label smoothing, and\nclass-balanced weighting. Our preprocessing pipeline incorporated advanced\ntechniques, including contrast-limited adaptive histogram equalization (CLAHE)\nand comprehensive data augmentation. The individual models were combined\nthrough an optimized ensemble voting approach, achieving superior performance\n(AUC: 0.963, F1-score: 0.952) compared to any single model. This system\ndemonstrates significant potential to standardize density assessments in\nclinical practice, potentially improving screening efficiency and early cancer\ndetection rates while reducing inter-observer variability among radiologists.\n","authors":["Peyman Sharifian","Xiaotong Hong","Alireza Karimian","Mehdi Amini","Hossein Arabi"],"pdf_url":"https://arxiv.org/pdf/2507.06410v2.pdf","comment":"2025 IEEE Nuclear Science Symposium, Medical Imaging Conference and\n  Room Temperature Semiconductor Detector Conference"},{"id":"http://arxiv.org/abs/2507.07789v1","updated":"2025-07-10T14:14:08Z","published":"2025-07-10T14:14:08Z","title":"Computationally Efficient Information-Driven Optical Design with\n  Interchanging Optimization","summary":"  Recent work has demonstrated that imaging systems can be evaluated through\nthe information content of their measurements alone, enabling\napplication-agnostic optical design that avoids computational decoding\nchallenges. Information-Driven Encoder Analysis Learning (IDEAL) was proposed\nto automate this process through gradient-based. In this work, we study IDEAL\nacross diverse imaging systems and find that it suffers from high memory usage,\nlong runtimes, and a potentially mismatched objective function due to\nend-to-end differentiability requirements. We introduce IDEAL with\nInterchanging Optimization (IDEAL-IO), a method that decouples density\nestimation from optical parameter optimization by alternating between fitting\nmodels to current measurements and updating optical parameters using fixed\nmodels for information estimation. This approach reduces runtime and memory\nusage by up to 6x while enabling more expressive density models that guide\noptimization toward superior designs. We validate our method on diffractive\noptics, lensless imaging, and snapshot 3D microscopy applications, establishing\ninformation-theoretic optimization as a practical, scalable strategy for\nreal-world imaging system design.\n","authors":["Eric Markley","Henry Pinkard","Leyla Kabuli","Nalini Singh","Laura Waller"],"pdf_url":"https://arxiv.org/pdf/2507.07789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20559v4","updated":"2025-07-10T14:09:10Z","published":"2024-05-31T00:57:58Z","title":"Information-driven design of imaging systems","summary":"  In modern imaging systems that computationally process raw measurements\nbefore or instead of human viewing, information content matters more than\nvisual appearance. However, developing information estimators that can handle\nthe complexity of real-world measurements yet remain practical enough for\nwidespread use has proven challenging. We introduce a data-driven approach for\nestimating mutual information between unknown objects and their noisy\nmeasurements. Our technique fits probabilistic models to measurements and their\nnoise processes, quantifying information content without requiring ground truth\ndata or making assumptions about object structure. We validate our approach\nacross diverse applications-color photography, radio astronomy, lensless\nimaging, and microscopy-demonstrating that information estimates reliably\npredict system performance. Finally, we introduce Information-Driven Encoder\nAnalysis Learning (IDEAL), which optimizes imaging systems to maximize\ninformation capture. Our work unlocks information theory as a powerful,\npractical tool for analyzing and designing imaging systems across a broad range\nof applications.\n  A video summarizing this work can be found at:\nhttps://waller-lab.github.io/EncodingInformationWebsite/\n","authors":["Henry Pinkard","Leyla Kabuli","Eric Markley","Tiffany Chien","Jiantao Jiao","Laura Waller"],"pdf_url":"https://arxiv.org/pdf/2405.20559v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07781v1","updated":"2025-07-10T14:01:24Z","published":"2025-07-10T14:01:24Z","title":"SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex\n  3D Scenes","summary":"  The integration of language and 3D perception is critical for embodied AI and\nrobotic systems to perceive, understand, and interact with the physical world.\nSpatial reasoning, a key capability for understanding spatial relationships\nbetween objects, remains underexplored in current 3D vision-language research.\nExisting datasets often mix semantic cues (e.g., object name) with spatial\ncontext, leading models to rely on superficial shortcuts rather than genuinely\ninterpreting spatial relationships. To address this gap, we introduce\nS\\textsc{urprise}3D, a novel dataset designed to evaluate language-guided\nspatial reasoning segmentation in complex 3D scenes. S\\textsc{urprise}3D\nconsists of more than 200k vision language pairs across 900+ detailed indoor\nscenes from ScanNet++ v2, including more than 2.8k unique object classes. The\ndataset contains 89k+ human-annotated spatial queries deliberately crafted\nwithout object name, thereby mitigating shortcut biases in spatial\nunderstanding. These queries comprehensively cover various spatial reasoning\nskills, such as relative position, narrative perspective, parametric\nperspective, and absolute distance reasoning. Initial benchmarks demonstrate\nsignificant challenges for current state-of-the-art expert 3D visual grounding\nmethods and 3D-LLMs, underscoring the necessity of our dataset and the\naccompanying 3D Spatial Reasoning Segmentation (3D-SRS) benchmark suite.\nS\\textsc{urprise}3D and 3D-SRS aim to facilitate advancements in spatially\naware AI, paving the way for effective embodied interaction and robotic\nplanning. The code and datasets can be found in\nhttps://github.com/liziwennba/SUPRISE.\n","authors":["Jiaxin Huang","Ziwen Li","Hanlve Zhang","Runnan Chen","Xiao He","Yandong Guo","Wenping Wang","Tongliang Liu","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2507.07781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.05317v2","updated":"2025-07-10T14:01:10Z","published":"2025-06-30T08:28:32Z","title":"PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle\n  CT","summary":"  Generative diffusion models have received increasing attention in medical\nimaging, particularly in limited-angle computed tomography (LACT). Standard\ndiffusion models achieve high-quality image reconstruction but require a large\nnumber of sampling steps during inference, resulting in substantial\ncomputational overhead. Although skip-sampling strategies have been proposed to\nimprove efficiency, they often lead to loss of fine structural details. To\naddress this issue, we propose a prior information embedding and wavelet\nfeature fusion fast sampling diffusion model for LACT reconstruction. The PWD\nenables efficient sampling while preserving reconstruction fidelity in LACT,\nand effectively mitigates the degradation typically introduced by\nskip-sampling. Specifically, during the training phase, PWD maps the\ndistribution of LACT images to that of fully sampled target images, enabling\nthe model to learn structural correspondences between them. During inference,\nthe LACT image serves as an explicit prior to guide the sampling trajectory,\nallowing for high-quality reconstruction with significantly fewer steps. In\naddition, PWD performs multi-scale feature fusion in the wavelet domain,\neffectively enhancing the reconstruction of fine details by leveraging both\nlow-frequency and high-frequency information. Quantitative and qualitative\nevaluations on clinical dental arch CBCT and periapical datasets demonstrate\nthat PWD outperforms existing methods under the same sampling condition. Using\nonly 50 sampling steps, PWD achieves at least 1.7 dB improvement in PSNR and\n10% gain in SSIM.\n","authors":["Yi Liu","Yiyang Wen","Zekun Zhou","Junqi Ma","Linghang Wang","Yucheng Yao","Liu Shi","Qiegen Liu"],"pdf_url":"https://arxiv.org/pdf/2507.05317v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07780v1","updated":"2025-07-10T13:59:53Z","published":"2025-07-10T13:59:53Z","title":"Where are we with calibration under dataset shift in image\n  classification?","summary":"  We conduct an extensive study on the state of calibration under real-world\ndataset shift for image classification. Our work provides important insights on\nthe choice of post-hoc and in-training calibration techniques, and yields\npractical guidelines for all practitioners interested in robust calibration\nunder shift. We compare various post-hoc calibration methods, and their\ninteractions with common in-training calibration strategies (e.g., label\nsmoothing), across a wide range of natural shifts, on eight different\nclassification tasks across several imaging domains. We find that: (i)\nsimultaneously applying entropy regularisation and label smoothing yield the\nbest calibrated raw probabilities under dataset shift, (ii) post-hoc\ncalibrators exposed to a small amount of semantic out-of-distribution data\n(unrelated to the task) are most robust under shift, (iii) recent calibration\nmethods specifically aimed at increasing calibration under shifts do not\nnecessarily offer significant improvements over simpler post-hoc calibration\nmethods, (iv) improving calibration under shifts often comes at the cost of\nworsening in-distribution calibration. Importantly, these findings hold for\nrandomly initialised classifiers, as well as for those finetuned from\nfoundation models, the latter being consistently better calibrated compared to\nmodels trained from scratch. Finally, we conduct an in-depth analysis of\nensembling effects, finding that (i) applying calibration prior to ensembling\n(instead of after) is more effective for calibration under shifts, (ii) for\nensembles, OOD exposure deteriorates the ID-shifted calibration trade-off,\n(iii) ensembling remains one of the most effective methods to improve\ncalibration robustness and, combined with finetuning from foundation models,\nyields best calibration results overall.\n","authors":["Mélanie Roschewitz","Raghav Mehta","Fabio de Sousa Ribeiro","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2507.07780v1.pdf","comment":"Code available at\n  https://github.com/biomedia-mira/calibration_under_shifts"},{"id":"http://arxiv.org/abs/2507.07778v1","updated":"2025-07-10T13:58:32Z","published":"2025-07-10T13:58:32Z","title":"Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time\n  Training","summary":"  Generalizing neural networks to unseen target domains is a significant\nchallenge in real-world deployments. Test-time training (TTT) addresses this by\nusing an auxiliary self-supervised task to reduce the domain gap caused by\ndistribution shifts between the source and target. However, we find that when\nmodels are required to perform multiple tasks under domain shifts, conventional\nTTT methods suffer from unsynchronized task behavior, where the adaptation\nsteps needed for optimal performance in one task may not align with the\nrequirements of other tasks. To address this, we propose a novel TTT approach\ncalled Synchronizing Tasks for Test-time Training (S4T), which enables the\nconcurrent handling of multiple tasks. The core idea behind S4T is that\npredicting task relations across domain shifts is key to synchronizing tasks\nduring test time. To validate our approach, we apply S4T to conventional\nmulti-task benchmarks, integrating it with traditional TTT protocols. Our\nempirical results show that S4T outperforms state-of-the-art TTT methods across\nvarious benchmarks.\n","authors":["Wooseong Jeong","Jegyeong Cho","Youngho Yoon","Kuk-Jin Yoon"],"pdf_url":"https://arxiv.org/pdf/2507.07778v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2507.07776v1","updated":"2025-07-10T13:56:32Z","published":"2025-07-10T13:56:32Z","title":"SCOOTER: A Human Evaluation Framework for Unrestricted Adversarial\n  Examples","summary":"  Unrestricted adversarial attacks aim to fool computer vision models without\nbeing constrained by $\\ell_p$-norm bounds to remain imperceptible to humans,\nfor example, by changing an object's color. This allows attackers to circumvent\ntraditional, norm-bounded defense strategies such as adversarial training or\ncertified defense strategies. However, due to their unrestricted nature, there\nare also no guarantees of norm-based imperceptibility, necessitating human\nevaluations to verify just how authentic these adversarial examples look. While\nsome related work assesses this vital quality of adversarial attacks, none\nprovide statistically significant insights. This issue necessitates a unified\nframework that supports and streamlines such an assessment for evaluating and\ncomparing unrestricted attacks. To close this gap, we introduce SCOOTER - an\nopen-source, statistically powered framework for evaluating unrestricted\nadversarial examples. Our contributions are: $(i)$ best-practice guidelines for\ncrowd-study power, compensation, and Likert equivalence bounds to measure\nimperceptibility; $(ii)$ the first large-scale human vs. model comparison\nacross 346 human participants showing that three color-space attacks and three\ndiffusion-based attacks fail to produce imperceptible images. Furthermore, we\nfound that GPT-4o can serve as a preliminary test for imperceptibility, but it\nonly consistently detects adversarial examples for four out of six tested\nattacks; $(iii)$ open-source software tools, including a browser-based task\ntemplate to collect annotations and analysis scripts in Python and R; $(iv)$ an\nImageNet-derived benchmark dataset containing 3K real images, 7K adversarial\nexamples, and over 34K human ratings. Our findings demonstrate that automated\nvision systems do not align with human perception, reinforcing the need for a\nground-truth SCOOTER benchmark.\n","authors":["Dren Fazlija","Monty-Maximilian Zühlke","Johanna Schrader","Arkadij Orlov","Clara Stein","Iyiola E. Olatunji","Daniel Kudenko"],"pdf_url":"https://arxiv.org/pdf/2507.07776v1.pdf","comment":"42 pages, 16 figures, 11 tables, Under Review, Code:\n  https://github.com/DrenFazlija/Scooter, Data:\n  https://doi.org/10.5281/zenodo.15771501"},{"id":"http://arxiv.org/abs/2507.07773v1","updated":"2025-07-10T13:55:35Z","published":"2025-07-10T13:55:35Z","title":"Rainbow Artifacts from Electromagnetic Signal Injection Attacks on Image\n  Sensors","summary":"  Image sensors are integral to a wide range of safety- and security-critical\nsystems, including surveillance infrastructure, autonomous vehicles, and\nindustrial automation. These systems rely on the integrity of visual data to\nmake decisions. In this work, we investigate a novel class of electromagnetic\nsignal injection attacks that target the analog domain of image sensors,\nallowing adversaries to manipulate raw visual inputs without triggering\nconventional digital integrity checks. We uncover a previously undocumented\nattack phenomenon on CMOS image sensors: rainbow-like color artifacts induced\nin images captured by image sensors through carefully tuned electromagnetic\ninterference. We further evaluate the impact of these attacks on\nstate-of-the-art object detection models, showing that the injected artifacts\npropagate through the image signal processing pipeline and lead to significant\nmispredictions. Our findings highlight a critical and underexplored\nvulnerability in the visual perception stack, highlighting the need for more\nrobust defenses against physical-layer attacks in such systems.\n","authors":["Youqian Zhang","Xinyu Ji","Zhihao Wang","Qinhong Jiang"],"pdf_url":"https://arxiv.org/pdf/2507.07773v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.07768v1","updated":"2025-07-10T13:53:52Z","published":"2025-07-10T13:53:52Z","title":"TRIX- Trading Adversarial Fairness via Mixed Adversarial Training","summary":"  Adversarial Training (AT) is a widely adopted defense against adversarial\nexamples. However, existing approaches typically apply a uniform training\nobjective across all classes, overlooking disparities in class-wise\nvulnerability. This results in adversarial unfairness: classes with well\ndistinguishable features (strong classes) tend to become more robust, while\nclasses with overlapping or shared features(weak classes) remain\ndisproportionately susceptible to adversarial attacks. We observe that strong\nclasses do not require strong adversaries during training, as their non-robust\nfeatures are quickly suppressed. In contrast, weak classes benefit from\nstronger adversaries to effectively reduce their vulnerabilities. Motivated by\nthis, we introduce TRIX, a feature-aware adversarial training framework that\nadaptively assigns weaker targeted adversaries to strong classes, promoting\nfeature diversity via uniformly sampled targets, and stronger untargeted\nadversaries to weak classes, enhancing their focused robustness. TRIX further\nincorporates per-class loss weighting and perturbation strength adjustments,\nbuilding on prior work, to emphasize weak classes during the optimization.\nComprehensive experiments on standard image classification benchmarks,\nincluding evaluations under strong attacks such as PGD and AutoAttack,\ndemonstrate that TRIX significantly improves worst-case class accuracy on both\nclean and adversarial data, reducing inter-class robustness disparities, and\npreserves overall accuracy. Our results highlight TRIX as a practical step\ntoward fair and effective adversarial defense.\n","authors":["Tejaswini Medi","Steffen Jung","Margret Keuper"],"pdf_url":"https://arxiv.org/pdf/2507.07768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07757v1","updated":"2025-07-10T13:34:33Z","published":"2025-07-10T13:34:33Z","title":"Deep Learning based 3D Volume Correlation for Additive Manufacturing\n  Using High-Resolution Industrial X-ray Computed Tomography","summary":"  Quality control in additive manufacturing (AM) is vital for industrial\napplications in areas such as the automotive, medical and aerospace sectors.\nGeometric inaccuracies caused by shrinkage and deformations can compromise the\nlife and performance of additively manufactured components. Such deviations can\nbe quantified using Digital Volume Correlation (DVC), which compares the\ncomputer-aided design (CAD) model with the X-ray Computed Tomography (XCT)\ngeometry of the components produced. However, accurate registration between the\ntwo modalities is challenging due to the absence of a ground truth or reference\ndeformation field. In addition, the extremely large data size of\nhigh-resolution XCT volumes makes computation difficult. In this work, we\npresent a deep learning-based approach for estimating voxel-wise deformations\nbetween CAD and XCT volumes. Our method uses a dynamic patch-based processing\nstrategy to handle high-resolution volumes. In addition to the Dice Score, we\nintroduce a Binary Difference Map (BDM) that quantifies voxel-wise mismatches\nbetween binarized CAD and XCT volumes to evaluate the accuracy of the\nregistration. Our approach shows a 9.2\\% improvement in the Dice Score and a\n9.9\\% improvement in the voxel match rate compared to classic DVC methods,\nwhile reducing the interaction time from days to minutes. This work sets the\nfoundation for deep learning-based DVC methods to generate compensation meshes\nthat can then be used in closed-loop correlations during the AM production\nprocess. Such a system would be of great interest to industries since the\nmanufacturing process will become more reliable and efficient, saving time and\nmaterial.\n","authors":["Keerthana Chand","Tobias Fritsch","Bardia Hejazi","Konstantin Poka","Giovanni Bruno"],"pdf_url":"https://arxiv.org/pdf/2507.07757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07747v1","updated":"2025-07-10T13:25:29Z","published":"2025-07-10T13:25:29Z","title":"X-RAFT: Cross-Modal Non-Rigid Registration of Blue and White Light\n  Neurosurgical Hyperspectral Images","summary":"  Integration of hyperspectral imaging into fluorescence-guided neurosurgery\nhas the potential to improve surgical decision making by providing quantitative\nfluorescence measurements in real-time. Quantitative fluorescence requires\npaired spectral data in fluorescence (blue light) and reflectance (white light)\nmode. Blue and white image acquisition needs to be performed sequentially in a\npotentially dynamic surgical environment. A key component to the fluorescence\nquantification process is therefore the ability to find dense cross-modal image\ncorrespondences between two hyperspectral images taken under these drastically\ndifferent lighting conditions. We address this challenge with the introduction\nof X-RAFT, a Recurrent All-Pairs Field Transforms (RAFT) optical flow model\nmodified for cross-modal inputs. We propose using distinct image encoders for\neach modality pair, and fine-tune these in a self-supervised manner using\nflow-cycle-consistency on our neurosurgical hyperspectral data. We show an\nerror reduction of 36.6% across our evaluation metrics when comparing to a\nnaive baseline and 27.83% reduction compared to an existing cross-modal optical\nflow method (CrossRAFT). Our code and models will be made publicly available\nafter the review process.\n","authors":["Charlie Budd","Silvère Ségaud","Matthew Elliot","Graeme Stasiuk","Yijing Xie","Jonathan Shapey","Tom Vercauteren"],"pdf_url":"https://arxiv.org/pdf/2507.07747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07744v1","updated":"2025-07-10T13:23:41Z","published":"2025-07-10T13:23:41Z","title":"Sparse-Dense Side-Tuner for efficient Video Temporal Grounding","summary":"  Video Temporal Grounding (VTG) involves Moment Retrieval (MR) and Highlight\nDetection (HD) based on textual queries. For this, most methods rely solely on\nfinal-layer features of frozen large pre-trained backbones, limiting their\nadaptability to new domains. While full fine-tuning is often impractical,\nparameter-efficient fine-tuning -- and particularly side-tuning (ST) -- has\nemerged as an effective alternative. However, prior ST approaches this problem\nfrom a frame-level refinement perspective, overlooking the inherent sparse\nnature of MR. To address this, we propose the Sparse-Dense Side-Tuner (SDST),\nthe first anchor-free ST architecture for VTG. We also introduce the\nReference-based Deformable Self-Attention, a novel mechanism that enhances the\ncontext modeling of the deformable attention -- a key limitation of existing\nanchor-free methods. Additionally, we present the first effective integration\nof InternVideo2 backbone into an ST framework, showing its profound\nimplications in performance. Overall, our method significantly improves\nexisting ST methods, achieving highly competitive or SOTA results on\nQVHighlights, TACoS, and Charades-STA, while reducing up to a 73% the parameter\ncount w.r.t. the existing SOTA methods. The code is publicly accessible at\nhttps://github.com/davidpujol/SDST.\n","authors":["David Pujol-Perich","Sergio Escalera","Albert Clapés"],"pdf_url":"https://arxiv.org/pdf/2507.07744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07734v1","updated":"2025-07-10T13:13:53Z","published":"2025-07-10T13:13:53Z","title":"EEvAct: Early Event-Based Action Recognition with High-Rate Two-Stream\n  Spiking Neural Networks","summary":"  Recognizing human activities early is crucial for the safety and\nresponsiveness of human-robot and human-machine interfaces. Due to their high\ntemporal resolution and low latency, event-based vision sensors are a perfect\nmatch for this early recognition demand. However, most existing processing\napproaches accumulate events to low-rate frames or space-time voxels which\nlimits the early prediction capabilities. In contrast, spiking neural networks\n(SNNs) can process the events at a high-rate for early predictions, but most\nworks still fall short on final accuracy. In this work, we introduce a\nhigh-rate two-stream SNN which closes this gap by outperforming previous work\nby 2% in final accuracy on the large-scale THU EACT-50 dataset. We benchmark\nthe SNNs within a novel early event-based recognition framework by reporting\nTop-1 and Top-5 recognition scores for growing observation time. Finally, we\nexemplify the impact of these methods on a real-world task of early action\ntriggering for human motion capture in sports.\n","authors":["Michael Neumeier","Jules Lecomte","Nils Kazinski","Soubarna Banik","Bing Li","Axel von Arnim"],"pdf_url":"https://arxiv.org/pdf/2507.07734v1.pdf","comment":"International Conference on Neuromorphic Systems (ICONS) 2025"},{"id":"http://arxiv.org/abs/2507.07733v1","updated":"2025-07-10T13:13:08Z","published":"2025-07-10T13:13:08Z","title":"RTR-GS: 3D Gaussian Splatting for Inverse Rendering with Radiance\n  Transfer and Reflection","summary":"  3D Gaussian Splatting (3DGS) has demonstrated impressive capabilities in\nnovel view synthesis. However, rendering reflective objects remains a\nsignificant challenge, particularly in inverse rendering and relighting. We\nintroduce RTR-GS, a novel inverse rendering framework capable of robustly\nrendering objects with arbitrary reflectance properties, decomposing BRDF and\nlighting, and delivering credible relighting results. Given a collection of\nmulti-view images, our method effectively recovers geometric structure through\na hybrid rendering model that combines forward rendering for radiance transfer\nwith deferred rendering for reflections. This approach successfully separates\nhigh-frequency and low-frequency appearances, mitigating floating artifacts\ncaused by spherical harmonic overfitting when handling high-frequency details.\nWe further refine BRDF and lighting decomposition using an additional\nphysically-based deferred rendering branch. Experimental results show that our\nmethod enhances novel view synthesis, normal estimation, decomposition, and\nrelighting while maintaining efficient training inference process.\n","authors":["Yongyang Zhou","Fang-Lue Zhang","Zichen Wang","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07733v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2507.07731v1","updated":"2025-07-10T13:12:08Z","published":"2025-07-10T13:12:08Z","title":"Energy-Guided Decoding for Object Hallucination Mitigation","summary":"  Mitigating object hallucination in large vision-language models (LVLMs) is\ncritical to their safe deployment. Existing methods either are restricted to\nspecific decoding methods, or demand sophisticated modifications to visual\ninputs, or rely on knowledge from external models. In this work, we first\nreveal the phenomenon that VLMs exhibit significant imbalance in the ``Yes''\nratio ( \\ie, the fraction of ``Yes'' answers among the total number of\nquestions) across three different visual question answering (VQA) datasets.\nFurthermore, we propose an energy-based decoding method, which dynamically\nselects the hidden states from the layer with minimal energy score. It is\nsimple yet effective in reducing the bias for the yes ratio while boosting\nperformance across three benchmarks (POPE, MME, and MMVP). Our method\nconsistently improves accuracy and F1 score on three VQA datasets across three\ncommonly used VLMs over several baseline methods. The average accuracy\nimprovement is 4.82% compared to greedy decoding. Moreover, the average\nyes-ratio gap reduction is 8.81%, meaning the proposed method is less biased as\nshown in Figure 1.\n","authors":["Xixi Liu","Ailin Deng","Christopher Zach"],"pdf_url":"https://arxiv.org/pdf/2507.07731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07730v1","updated":"2025-07-10T13:08:57Z","published":"2025-07-10T13:08:57Z","title":"RAPS-3D: Efficient interactive segmentation for 3D radiological imaging","summary":"  Promptable segmentation, introduced by the Segment Anything Model (SAM), is a\npromising approach for medical imaging, as it enables clinicians to guide and\nrefine model predictions interactively. However, SAM's architecture is designed\nfor 2D images and does not extend naturally to 3D volumetric data such as CT or\nMRI scans. Adapting 2D models to 3D typically involves autoregressive\nstrategies, where predictions are propagated slice by slice, resulting in\nincreased inference complexity. Processing large 3D volumes also requires\nsignificant computational resources, often leading existing 3D methods to also\nadopt complex strategies like sliding-window inference to manage memory usage,\nat the cost of longer inference times and greater implementation complexity. In\nthis paper, we present a simplified 3D promptable segmentation method, inspired\nby SegVol, designed to reduce inference time and eliminate prompt management\ncomplexities associated with sliding windows while achieving state-of-the-art\nperformance.\n","authors":["Théo Danielou","Daniel Tordjman","Pierre Manceron","Corentin Dancette"],"pdf_url":"https://arxiv.org/pdf/2507.07730v1.pdf","comment":"Abstract accepted at MIUA 2025"},{"id":"http://arxiv.org/abs/2502.20805v2","updated":"2025-07-10T13:08:40Z","published":"2025-02-28T07:42:54Z","title":"FunHOI: Annotation-Free 3D Hand-Object Interaction Generation via\n  Functional Text Guidanc","summary":"  Hand-object interaction(HOI) is the fundamental link between human and\nenvironment, yet its dexterous and complex pose significantly challenges for\ngesture control. Despite significant advances in AI and robotics, enabling\nmachines to understand and simulate hand-object interactions, capturing the\nsemantics of functional grasping tasks remains a considerable challenge. While\nprevious work can generate stable and correct 3D grasps, they are still far\nfrom achieving functional grasps due to unconsidered grasp semantics. To\naddress this challenge, we propose an innovative two-stage framework,\nFunctional Grasp Synthesis Net (FGS-Net), for generating 3D HOI driven by\nfunctional text. This framework consists of a text-guided 3D model generator,\nFunctional Grasp Generator (FGG), and a pose optimization strategy, Functional\nGrasp Refiner (FGR). FGG generates 3D models of hands and objects based on text\ninput, while FGR fine-tunes the poses using Object Pose Approximator and energy\nfunctions to ensure the relative position between the hand and object aligns\nwith human intent and remains physically plausible. Extensive experiments\ndemonstrate that our approach achieves precise and high-quality HOI generation\nwithout requiring additional 3D annotation data.\n","authors":["Yongqi Tian","Xueyu Sun","Haoyuan He","Linji Hao","Ning Ding","Caigui Jiang"],"pdf_url":"https://arxiv.org/pdf/2502.20805v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07722v1","updated":"2025-07-10T12:57:09Z","published":"2025-07-10T12:57:09Z","title":"Understanding Dataset Bias in Medical Imaging: A Case Study on Chest\n  X-rays","summary":"  Recent work has revisited the infamous task Name that dataset and established\nthat in non-medical datasets, there is an underlying bias and achieved high\nAccuracies on the dataset origin task. In this work, we revisit the same task\napplied to popular open-source chest X-ray datasets. Medical images are\nnaturally more difficult to release for open-source due to their sensitive\nnature, which has led to certain open-source datasets being extremely popular\nfor research purposes. By performing the same task, we wish to explore whether\ndataset bias also exists in these datasets. % We deliberately try to increase\nthe difficulty of the task by dataset transformations. We apply simple\ntransformations of the datasets to try to identify bias. Given the importance\nof AI applications in medical imaging, it's vital to establish whether modern\nmethods are taking shortcuts or are focused on the relevant pathology. We\nimplement a range of different network architectures on the datasets: NIH,\nCheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more\nexplainable research being performed in medical imaging and the creation of\nmore open-source datasets in the medical domain. The corresponding code will be\nreleased upon acceptance.\n","authors":["Ethan Dack","Chengliang Dai"],"pdf_url":"https://arxiv.org/pdf/2507.07722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07721v1","updated":"2025-07-10T12:56:24Z","published":"2025-07-10T12:56:24Z","title":"Breast Ultrasound Tumor Generation via Mask Generator and Text-Guided\n  Network:A Clinically Controllable Framework with Downstream Evaluation","summary":"  The development of robust deep learning models for breast ultrasound (BUS)\nimage analysis is significantly constrained by the scarcity of expert-annotated\ndata. To address this limitation, we propose a clinically controllable\ngenerative framework for synthesizing BUS images. This framework integrates\nclinical descriptions with structural masks to generate tumors, enabling\nfine-grained control over tumor characteristics such as morphology,\nechogencity, and shape. Furthermore, we design a semantic-curvature mask\ngenerator, which synthesizes structurally diverse tumor masks guided by\nclinical priors. During inference, synthetic tumor masks serve as input to the\ngenerative framework, producing highly personalized synthetic BUS images with\ntumors that reflect real-world morphological diversity. Quantitative\nevaluations on six public BUS datasets demonstrate the significant clinical\nutility of our synthetic images, showing their effectiveness in enhancing\ndownstream breast cancer diagnosis tasks. Furthermore, visual Turing tests\nconducted by experienced sonographers confirm the realism of the generated\nimages, indicating the framework's potential to support broader clinical\napplications.\n","authors":["Haoyu Pan","Hongxin Lin","Zetian Feng","Chuxuan Lin","Junyang Mo","Chu Zhang","Zijian Wu","Yi Wang","Qingqing Zheng"],"pdf_url":"https://arxiv.org/pdf/2507.07721v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.10252v2","updated":"2025-07-10T12:48:37Z","published":"2025-03-13T10:59:51Z","title":"SVIP: Semantically Contextualized Visual Patches for Zero-Shot Learning","summary":"  Zero-shot learning (ZSL) aims to recognize unseen classes without labeled\ntraining examples by leveraging class-level semantic descriptors such as\nattributes. A fundamental challenge in ZSL is semantic misalignment, where\nsemantic-unrelated information involved in visual features introduce ambiguity\nto visual-semantic interaction. Unlike existing methods that suppress\nsemantic-unrelated information post hoc either in the feature space or the\nmodel space, we propose addressing this issue at the input stage, preventing\nsemantic-unrelated patches from propagating through the network. To this end,\nwe introduce Semantically contextualized VIsual Patches (SVIP) for ZSL, a\ntransformer-based framework designed to enhance visual-semantic alignment.\nSpecifically, we propose a self-supervised patch selection mechanism that\npreemptively learns to identify semantic-unrelated patches in the input space.\nThis is trained with the supervision from aggregated attention scores across\nall transformer layers, which estimate each patch's semantic score. As removing\nsemantic-unrelated patches from the input sequence may disrupt object\nstructure, we replace them with learnable patch embeddings. With initialization\nfrom word embeddings, we can ensure they remain semantically meaningful\nthroughout feature extraction. Extensive experiments on ZSL benchmarks\ndemonstrate that SVIP achieves state-of-the-art performance results while\nproviding more interpretable and semantically rich feature representations.\nCode is available at https://github.com/uqzhichen/SVIP.\n","authors":["Zhi Chen","Zecheng Zhao","Jingcai Guo","Jingjing Li","Zi Huang"],"pdf_url":"https://arxiv.org/pdf/2503.10252v2.pdf","comment":"Accepted to ICCV 2025"},{"id":"http://arxiv.org/abs/2507.07712v1","updated":"2025-07-10T12:46:31Z","published":"2025-07-10T12:46:31Z","title":"Balancing the Past and Present: A Coordinated Replay Framework for\n  Federated Class-Incremental Learning","summary":"  Federated Class Incremental Learning (FCIL) aims to collaboratively process\ncontinuously increasing incoming tasks across multiple clients. Among various\napproaches, data replay has become a promising solution, which can alleviate\nforgetting by reintroducing representative samples from previous tasks.\nHowever, their performance is typically limited by class imbalance, both within\nthe replay buffer due to limited global awareness and between replayed and\nnewly arrived classes. To address this issue, we propose a class wise balancing\ndata replay method for FCIL (FedCBDR), which employs a global coordination\nmechanism for class-level memory construction and reweights the learning\nobjective to alleviate the aforementioned imbalances. Specifically, FedCBDR has\ntwo key components: 1) the global-perspective data replay module reconstructs\nglobal representations of prior task in a privacy-preserving manner, which then\nguides a class-aware and importance-sensitive sampling strategy to achieve\nbalanced replay; 2) Subsequently, to handle class imbalance across tasks, the\ntask aware temperature scaling module adaptively adjusts the temperature of\nlogits at both class and instance levels based on task dynamics, which reduces\nthe model's overconfidence in majority classes while enhancing its sensitivity\nto minority classes. Experimental results verified that FedCBDR achieves\nbalanced class-wise sampling under heterogeneous data distributions and\nimproves generalization under task imbalance between earlier and recent tasks,\nyielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.\n","authors":["Zhuang Qi","Lei Meng","Han Yu"],"pdf_url":"https://arxiv.org/pdf/2507.07712v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07709v1","updated":"2025-07-10T12:40:34Z","published":"2025-07-10T12:40:34Z","title":"One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack\n  on Unified Vision-Language Models","summary":"  Unified vision-language models(VLMs) have recently shown remarkable progress,\nenabling a single model to flexibly address diverse tasks through different\ninstructions within a shared computational architecture. This instruction-based\ncontrol mechanism creates unique security challenges, as adversarial inputs\nmust remain effective across multiple task instructions that may be\nunpredictably applied to process the same malicious content. In this paper, we\nintroduce CrossVLAD, a new benchmark dataset carefully curated from MSCOCO with\nGPT-4-assisted annotations for systematically evaluating cross-task adversarial\nattacks on unified VLMs. CrossVLAD centers on the object-change\nobjective-consistently manipulating a target object's classification across\nfour downstream tasks-and proposes a novel success rate metric that measures\nsimultaneous misclassification across all tasks, providing a rigorous\nevaluation of adversarial transferability. To tackle this challenge, we present\nCRAFT (Cross-task Region-based Attack Framework with Token-alignment), an\nefficient region-centric attack method. Extensive experiments on Florence-2 and\nother popular unified VLMs demonstrate that our method outperforms existing\napproaches in both overall cross-task attack performance and targeted\nobject-change success rates, highlighting its effectiveness in adversarially\ninfluencing unified VLMs across diverse tasks.\n","authors":["Jiale Zhao","Xinyang Jiang","Junyao Gao","Yuhao Xue","Cairong Zhao"],"pdf_url":"https://arxiv.org/pdf/2507.07709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07708v1","updated":"2025-07-10T12:38:27Z","published":"2025-07-10T12:38:27Z","title":"Motion-Aware Adaptive Pixel Pruning for Efficient Local Motion\n  Deblurring","summary":"  Local motion blur in digital images originates from the relative motion\nbetween dynamic objects and static imaging systems during exposure. Existing\ndeblurring methods face significant challenges in addressing this problem due\nto their inefficient allocation of computational resources and inadequate\nhandling of spatially varying blur patterns. To overcome these limitations, we\nfirst propose a trainable mask predictor that identifies blurred regions in the\nimage. During training, we employ blur masks to exclude sharp regions. For\ninference optimization, we implement structural reparameterization by\nconverting $3\\times 3$ convolutions to computationally efficient $1\\times 1$\nconvolutions, enabling pixel-level pruning of sharp areas to reduce\ncomputation. Second, we develop an intra-frame motion analyzer that translates\nrelative pixel displacements into motion trajectories, establishing adaptive\nguidance for region-specific blur restoration. Our method is trained end-to-end\nusing a combination of reconstruction loss, reblur loss, and mask loss guided\nby annotated blur masks. Extensive experiments demonstrate superior performance\nover state-of-the-art methods on both local and global blur datasets while\nreducing FLOPs by 49\\% compared to SOTA models (e.g., LMD-ViT). The source code\nis available at https://github.com/shangwei5/M2AENet.\n","authors":["Wei Shang","Dongwei Ren","Wanying Zhang","Pengfei Zhu","Qinghua Hu","Wangmeng Zuo"],"pdf_url":"https://arxiv.org/pdf/2507.07708v1.pdf","comment":"Accepted by ACMMM 2025"},{"id":"http://arxiv.org/abs/2507.07707v1","updated":"2025-07-10T12:36:20Z","published":"2025-07-10T12:36:20Z","title":"Compressive Imaging Reconstruction via Tensor Decomposed\n  Multi-Resolution Grid Encoding","summary":"  Compressive imaging (CI) reconstruction, such as snapshot compressive imaging\n(SCI) and compressive sensing magnetic resonance imaging (MRI), aims to recover\nhigh-dimensional images from low-dimensional compressed measurements. This\nprocess critically relies on learning an accurate representation of the\nunderlying high-dimensional image. However, existing unsupervised\nrepresentations may struggle to achieve a desired balance between\nrepresentation ability and efficiency. To overcome this limitation, we propose\nTensor Decomposed multi-resolution Grid encoding (GridTD), an unsupervised\ncontinuous representation framework for CI reconstruction. GridTD optimizes a\nlightweight neural network and the input tensor decomposition model whose\nparameters are learned via multi-resolution hash grid encoding. It inherently\nenjoys the hierarchical modeling ability of multi-resolution grid encoding and\nthe compactness of tensor decomposition, enabling effective and efficient\nreconstruction of high-dimensional images. Theoretical analyses for the\nalgorithm's Lipschitz property, generalization error bound, and fixed-point\nconvergence reveal the intrinsic superiority of GridTD as compared with\nexisting continuous representation models. Extensive experiments across diverse\nCI tasks, including video SCI, spectral SCI, and compressive dynamic MRI\nreconstruction, consistently demonstrate the superiority of GridTD over\nexisting methods, positioning GridTD as a versatile and state-of-the-art CI\nreconstruction method.\n","authors":["Zhenyu Jin","Yisi Luo","Xile Zhao","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2507.07707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07704v1","updated":"2025-07-10T12:32:28Z","published":"2025-07-10T12:32:28Z","title":"D-CNN and VQ-VAE Autoencoders for Compression and Denoising of\n  Industrial X-ray Computed Tomography Images","summary":"  The ever-growing volume of data in imaging sciences stemming from the\nadvancements in imaging technologies, necessitates efficient and reliable\nstorage solutions for such large datasets. This study investigates the\ncompression of industrial X-ray computed tomography (XCT) data using deep\nlearning autoencoders and examines how these compression algorithms affect the\nquality of the recovered data. Two network architectures with different\ncompression rates were used, a deep convolution neural network (D-CNN) and a\nvector quantized variational autoencoder (VQ-VAE). The XCT data used was from a\nsandstone sample with a complex internal pore network. The quality of the\ndecoded images obtained from the two different deep learning architectures with\ndifferent compression rates were quantified and compared to the original input\ndata. In addition, to improve image decoding quality metrics, we introduced a\nmetric sensitive to edge preservation, which is crucial for three-dimensional\ndata analysis. We showed that different architectures and compression rates are\nrequired depending on the specific characteristics needed to be preserved for\nlater analysis. The findings presented here can aid scientists to determine the\nrequirements and strategies for their data storage and analysis needs.\n","authors":["Bardia Hejazi","Keerthana Chand","Tobias Fritsch","Giovanni Bruno"],"pdf_url":"https://arxiv.org/pdf/2507.07704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.05007v2","updated":"2025-07-10T12:22:03Z","published":"2025-07-07T13:44:58Z","title":"Multi-modal Representations for Fine-grained Multi-label Critical View\n  of Safety Recognition","summary":"  The Critical View of Safety (CVS) is crucial for safe laparoscopic\ncholecystectomy, yet assessing CVS criteria remains a complex and challenging\ntask, even for experts. Traditional models for CVS recognition depend on\nvision-only models learning with costly, labor-intensive spatial annotations.\nThis study investigates how text can be harnessed as a powerful tool for both\ntraining and inference in multi-modal surgical foundation models to automate\nCVS recognition. Unlike many existing multi-modal models, which are primarily\nadapted for multi-class classification, CVS recognition requires a multi-label\nframework. Zero-shot evaluation of existing multi-modal surgical models shows a\nsignificant performance gap for this task. To address this, we propose\nCVS-AdaptNet, a multi-label adaptation strategy that enhances fine-grained,\nbinary classification across multiple labels by aligning image embeddings with\ntextual descriptions of each CVS criterion using positive and negative prompts.\nBy adapting PeskaVLP, a state-of-the-art surgical foundation model, on the\nEndoscapes-CVS201 dataset, CVS-AdaptNet achieves 57.6 mAP, improving over the\nResNet50 image-only baseline (51.5 mAP) by 6 points. Our results show that\nCVS-AdaptNet's multi-label, multi-modal framework, enhanced by textual prompts,\nboosts CVS recognition over image-only methods. We also propose text-specific\ninference methods, that helps in analysing the image-text alignment. While\nfurther work is needed to match state-of-the-art spatial annotation-based\nmethods, this approach highlights the potential of adapting generalist models\nto specialized surgical tasks. Code:\nhttps://github.com/CAMMA-public/CVS-AdaptNet\n","authors":["Britty Baby","Vinkle Srivastav","Pooja P. Jain","Kun Yuan","Pietro Mascagni","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2507.05007v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.05020v2","updated":"2025-07-10T12:21:47Z","published":"2025-07-07T14:03:10Z","title":"Adaptation of Multi-modal Representation Models for Multi-task Surgical\n  Computer Vision","summary":"  Surgical AI often involves multiple tasks within a single procedure, like\nphase recognition or assessing the Critical View of Safety in laparoscopic\ncholecystectomy. Traditional models, built for one task at a time, lack\nflexibility, requiring a separate model for each. To address this, we introduce\nMML-SurgAdapt, a unified multi-task framework with Vision-Language Models\n(VLMs), specifically CLIP, to handle diverse surgical tasks through natural\nlanguage supervision. A key challenge in multi-task learning is the presence of\npartial annotations when integrating different tasks. To overcome this, we\nemploy Single Positive Multi-Label (SPML) learning, which traditionally reduces\nannotation burden by training models with only one positive label per instance.\nOur framework extends this approach to integrate data from multiple surgical\ntasks within a single procedure, enabling effective learning despite incomplete\nor noisy annotations. We demonstrate the effectiveness of our model on a\ncombined dataset consisting of Cholec80, Endoscapes2023, and CholecT50,\nutilizing custom prompts. Extensive evaluation shows that MML-SurgAdapt\nperforms comparably to task-specific benchmarks, with the added advantage of\nhandling noisy annotations. It also outperforms the existing SPML frameworks\nfor the task. By reducing the required labels by 23%, our approach proposes a\nmore scalable and efficient labeling process, significantly easing the\nannotation burden on clinicians. To our knowledge, this is the first\napplication of SPML to integrate data from multiple surgical tasks, presenting\na novel and generalizable solution for multi-task learning in surgical computer\nvision. Implementation is available at:\nhttps://github.com/CAMMA-public/MML-SurgAdapt\n","authors":["Soham Walimbe","Britty Baby","Vinkle Srivastav","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2507.05020v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07687v1","updated":"2025-07-10T12:10:51Z","published":"2025-07-10T12:10:51Z","title":"Tree-Mamba: A Tree-Aware Mamba for Underwater Monocular Depth Estimation","summary":"  Underwater Monocular Depth Estimation (UMDE) is a critical task that aims to\nestimate high-precision depth maps from underwater degraded images caused by\nlight absorption and scattering effects in marine environments. Recently,\nMamba-based methods have achieved promising performance across various vision\ntasks; however, they struggle with the UMDE task because their inflexible state\nscanning strategies fail to model the structural features of underwater images\neffectively. Meanwhile, existing UMDE datasets usually contain unreliable depth\nlabels, leading to incorrect object-depth relationships between underwater\nimages and their corresponding depth maps. To overcome these limitations, we\ndevelop a novel tree-aware Mamba method, dubbed Tree-Mamba, for estimating\naccurate monocular depth maps from underwater degraded images. Specifically, we\npropose a tree-aware scanning strategy that adaptively constructs a minimum\nspanning tree based on feature similarity. The spatial topological features\namong the tree nodes are then flexibly aggregated through bottom-up and\ntop-down traversals, enabling stronger multi-scale feature representation\ncapabilities. Moreover, we construct an underwater depth estimation benchmark\n(called BlueDepth), which consists of 38,162 underwater image pairs with\nreliable depth labels. This benchmark serves as a foundational dataset for\ntraining existing deep learning-based UMDE methods to learn accurate\nobject-depth relationships. Extensive experiments demonstrate the superiority\nof the proposed Tree-Mamba over several leading methods in both qualitative\nresults and quantitative evaluations with competitive computational efficiency.\nCode and dataset will be available at https://wyjgr.github.io/Tree-Mamba.html.\n","authors":["Peixian Zhuang","Yijian Wang","Zhenqi Fu","Hongliang Zhang","Sam Kwong","Chongyi Li"],"pdf_url":"https://arxiv.org/pdf/2507.07687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07685v1","updated":"2025-07-10T12:07:13Z","published":"2025-07-10T12:07:13Z","title":"Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought","summary":"  Large vision-language models (LVLMs) have demonstrated remarkable\ncapabilities by integrating pre-trained vision encoders with large language\nmodels (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting\nhas been adapted for LVLMs to enhance multi-modal reasoning by generating\nintermediate rationales based on visual and textual inputs. While CoT is\nassumed to improve grounding and accuracy in LVLMs, our experiments reveal a\nkey challenge: existing LVLMs often ignore the contents of generated rationales\nin CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as\na KL-constrained reward maximization focused on rationale-conditional\nlog-likelihood. As the optimal solution, we propose rationale-enhanced decoding\n(RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes\nvisual and rationale information by multiplying distinct image-conditional and\nrationale-conditional next token distributions. Extensive experiments show that\nRED consistently and significantly improves reasoning over standard CoT and\nother decoding methods across multiple benchmarks and LVLMs. Our work offers a\npractical and effective approach to improve both the faithfulness and accuracy\nof CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded\nmulti-modal systems.\n","authors":["Shin'ya Yamaguchi","Kosuke Nishida","Daiki Chijiwa"],"pdf_url":"https://arxiv.org/pdf/2507.07685v1.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.07678v1","updated":"2025-07-10T11:59:43Z","published":"2025-07-10T11:59:43Z","title":"Action Unit Enhance Dynamic Facial Expression Recognition","summary":"  Dynamic Facial Expression Recognition(DFER) is a rapidly evolving field of\nresearch that focuses on the recognition of time-series facial expressions.\nWhile previous research on DFER has concentrated on feature learning from a\ndeep learning perspective, we put forward an AU-enhanced Dynamic Facial\nExpression Recognition architecture, namely AU-DFER, that incorporates\nAU-expression knowledge to enhance the effectiveness of deep learning modeling.\nIn particular, the contribution of the Action Units(AUs) to different\nexpressions is quantified, and a weight matrix is designed to incorporate a\npriori knowledge. Subsequently, the knowledge is integrated with the learning\noutcomes of a conventional deep learning network through the introduction of AU\nloss. The design is incorporated into the existing optimal model for dynamic\nexpression recognition for the purpose of validation. Experiments are conducted\non three recent mainstream open-source approaches to DFER on the principal\ndatasets in this field. The results demonstrate that the proposed architecture\noutperforms the state-of-the-art(SOTA) methods without the need for additional\narithmetic and generally produces improved results. Furthermore, we investigate\nthe potential of AU loss function redesign to address data label imbalance\nissues in established dynamic expression datasets. To the best of our\nknowledge, this is the first attempt to integrate quantified AU-expression\nknowledge into various DFER models. We also devise strategies to tackle label\nimbalance, or minor class problems. Our findings suggest that employing a\ndiverse strategy of loss function design can enhance the effectiveness of DFER.\nThis underscores the criticality of addressing data imbalance challenges in\nmainstream datasets within this domain. The source code is available at\nhttps://github.com/Cross-Innovation-Lab/AU-DFER.\n","authors":["Feng Liu","Lingna Gu","Chen Shi","Xiaolan Fu"],"pdf_url":"https://arxiv.org/pdf/2507.07678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07670v1","updated":"2025-07-10T11:52:20Z","published":"2025-07-10T11:52:20Z","title":"Attend-and-Refine: Interactive keypoint estimation and quantitative\n  cervical vertebrae analysis for bone age assessment","summary":"  In pediatric orthodontics, accurate estimation of growth potential is\nessential for developing effective treatment strategies. Our research aims to\npredict this potential by identifying the growth peak and analyzing cervical\nvertebra morphology solely through lateral cephalometric radiographs. We\naccomplish this by comprehensively analyzing cervical vertebral maturation\n(CVM) features from these radiographs. This methodology provides clinicians\nwith a reliable and efficient tool to determine the optimal timings for\northodontic interventions, ultimately enhancing patient outcomes. A crucial\naspect of this approach is the meticulous annotation of keypoints on the\ncervical vertebrae, a task often challenged by its labor-intensive nature. To\nmitigate this, we introduce Attend-and-Refine Network (ARNet), a\nuser-interactive, deep learning-based model designed to streamline the\nannotation process. ARNet features Interaction-guided recalibration network,\nwhich adaptively recalibrates image features in response to user feedback,\ncoupled with a morphology-aware loss function that preserves the structural\nconsistency of keypoints. This novel approach substantially reduces manual\neffort in keypoint identification, thereby enhancing the efficiency and\naccuracy of the process. Extensively validated across various datasets, ARNet\ndemonstrates remarkable performance and exhibits wide-ranging applicability in\nmedical imaging. In conclusion, our research offers an effective AI-assisted\ndiagnostic tool for assessing growth potential in pediatric orthodontics,\nmarking a significant advancement in the field.\n","authors":["Jinhee Kim","Taesung Kim","Taewoo Kim","Dong-Wook Kim","Byungduk Ahn","Yoon-Ji Kim","In-Seok Song","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2507.07670v1.pdf","comment":"Accepted to Medical Image Analysis (2025)"},{"id":"http://arxiv.org/abs/2507.07663v1","updated":"2025-07-10T11:38:54Z","published":"2025-07-10T11:38:54Z","title":"MolCLIP: A Molecular-Auxiliary CLIP Framework for Identifying Drug\n  Mechanism of Action Based on Time-Lapsed Mitochondrial Images","summary":"  Drug Mechanism of Action (MoA) mainly investigates how drug molecules\ninteract with cells, which is crucial for drug discovery and clinical\napplication. Recently, deep learning models have been used to recognize MoA by\nrelying on high-content and fluorescence images of cells exposed to various\ndrugs. However, these methods focus on spatial characteristics while\noverlooking the temporal dynamics of live cells. Time-lapse imaging is more\nsuitable for observing the cell response to drugs. Additionally, drug molecules\ncan trigger cellular dynamic variations related to specific MoA. This indicates\nthat the drug molecule modality may complement the image counterpart. This\npaper proposes MolCLIP, the first visual language model to combine microscopic\ncell video- and molecule-modalities. MolCLIP designs a molecule-auxiliary CLIP\nframework to guide video features in learning the distribution of the molecular\nlatent space. Furthermore, we integrate a metric learning strategy with MolCLIP\nto optimize the aggregation of video features. Experimental results on the\nMitoDataset demonstrate that MolCLIP achieves improvements of 51.2% and 20.5%\nin mAP for drug identification and MoA recognition, respectively.\n","authors":["Fengqian Pang","Chunyue Lei","Hongfei Zhao","Chenghao Liu","Zhiqiang Xing","Huafeng Wang","Chuyang Ye"],"pdf_url":"https://arxiv.org/pdf/2507.07663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01803v2","updated":"2025-07-10T11:21:57Z","published":"2023-03-03T09:19:08Z","title":"Uncertainty-Aware Gradient Stabilization for Small Object Detection","summary":"  Despite advances in generic object detection, there remains a performance gap\nin detecting small objects compared to normal-scale objects. We reveal that\nconventional object localization methods suffer from gradient instability in\nsmall objects due to sharper loss curvature, leading to a convergence\nchallenge. To address the issue, we propose Uncertainty-Aware Gradient\nStabilization (UGS), a framework that reformulates object localization as a\nclassification task to stabilize gradients. UGS quantizes continuous labels\ninto interval non-uniform discrete representations. Under a\nclassification-based objective, the localization branch generates bounded and\nconfidence-driven gradients, mitigating instability. Furthermore, UGS\nintegrates an uncertainty minimization (UM) loss that reduces prediction\nvariance and an uncertainty-guided refinement (UR) module that identifies and\nrefines high-uncertainty regions via perturbations. Evaluated on four\nbenchmarks, UGS consistently improves anchor-based, anchor-free, and leading\nsmall object detectors. Especially, UGS enhances DINO-5scale by 2.6 AP on\nVisDrone, surpassing previous state-of-the-art results.\n","authors":["Huixin Sun","Yanjing Li","Linlin Yang","Xianbin Cao","Baochang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07638v1","updated":"2025-07-10T11:07:13Z","published":"2025-07-10T11:07:13Z","title":"Bridging the gap in FER: addressing age bias in deep learning","summary":"  Facial Expression Recognition (FER) systems based on deep learning have\nachieved impressive performance in recent years. However, these models often\nexhibit demographic biases, particularly with respect to age, which can\ncompromise their fairness and reliability. In this work, we present a\ncomprehensive study of age-related bias in deep FER models, with a particular\nfocus on the elderly population. We first investigate whether recognition\nperformance varies across age groups, which expressions are most affected, and\nwhether model attention differs depending on age. Using Explainable AI (XAI)\ntechniques, we identify systematic disparities in expression recognition and\nattention patterns, especially for \"neutral\", \"sadness\", and \"anger\" in elderly\nindividuals. Based on these findings, we propose and evaluate three bias\nmitigation strategies: Multi-task Learning, Multi-modal Input, and Age-weighted\nLoss. Our models are trained on a large-scale dataset, AffectNet, with\nautomatically estimated age labels and validated on balanced benchmark datasets\nthat include underrepresented age groups. Results show consistent improvements\nin recognition accuracy for elderly individuals, particularly for the most\nerror-prone expressions. Saliency heatmap analysis reveals that models trained\nwith age-aware strategies attend to more relevant facial regions for each age\ngroup, helping to explain the observed improvements. These findings suggest\nthat age-related bias in FER can be effectively mitigated using simple training\nmodifications, and that even approximate demographic labels can be valuable for\npromoting fairness in large-scale affective computing systems.\n","authors":["F. Xavier Gaya-Morey","Julia Sanchez-Perez","Cristina Manresa-Yee","Jose M. Buades-Rubio"],"pdf_url":"https://arxiv.org/pdf/2507.07638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07633v1","updated":"2025-07-10T11:01:58Z","published":"2025-07-10T11:01:58Z","title":"T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates","summary":"  Recent advances in video generation techniques have given rise to an emerging\nparadigm of generative video coding, aiming to achieve semantically accurate\nreconstructions in Ultra-Low Bitrate (ULB) scenarios by leveraging strong\ngenerative priors. However, most existing methods are limited by domain\nspecificity (e.g., facial or human videos) or an excessive dependence on\nhigh-level text guidance, which often fails to capture motion details and\nresults in unrealistic reconstructions. To address these challenges, we propose\na Trajectory-Guided Generative Video Coding framework (dubbed T-GVC). T-GVC\nemploys a semantic-aware sparse motion sampling pipeline to effectively bridge\nlow-level motion tracking with high-level semantic understanding by extracting\npixel-wise motion as sparse trajectory points based on their semantic\nimportance, not only significantly reducing the bitrate but also preserving\ncritical temporal semantic information. In addition, by incorporating\ntrajectory-aligned loss constraints into diffusion processes, we introduce a\ntraining-free latent space guidance mechanism to ensure physically plausible\nmotion patterns without sacrificing the inherent capabilities of generative\nmodels. Experimental results demonstrate that our framework outperforms both\ntraditional codecs and state-of-the-art end-to-end video compression methods\nunder ULB conditions. Furthermore, additional experiments confirm that our\napproach achieves more precise motion control than existing text-guided\nmethods, paving the way for a novel direction of generative video coding guided\nby geometric motion modeling.\n","authors":["Zhitao Wang","Hengyu Man","Wenrui Li","Xingtao Wang","Xiaopeng Fan","Debin Zhao"],"pdf_url":"https://arxiv.org/pdf/2507.07633v1.pdf","comment":null}],"Robotics":[{"id":"http://arxiv.org/abs/2507.07980v1","updated":"2025-07-10T17:55:05Z","published":"2025-07-10T17:55:05Z","title":"UniTac: Whole-Robot Touch Sensing Without Tactile Sensors","summary":"  Robots can better interact with humans and unstructured environments through\ntouch sensing. However, most commercial robots are not equipped with tactile\nskins, making it challenging to achieve even basic touch-sensing functions,\nsuch as contact localization. We present UniTac, a data-driven whole-body\ntouch-sensing approach that uses only proprioceptive joint sensors and does not\nrequire the installation of additional sensors. Our approach enables a robot\nequipped solely with joint sensors to localize contacts. Our goal is to\ndemocratize touch sensing and provide an off-the-shelf tool for HRI researchers\nto provide their robots with touch-sensing capabilities. We validate our\napproach on two platforms: the Franka robot arm and the Spot quadruped. On\nFranka, we can localize contact to within 8.0 centimeters, and on Spot, we can\nlocalize to within 7.2 centimeters at around 2,000 Hz on an RTX 3090 GPU\nwithout adding any additional sensors to the robot. Project website:\nhttps://ivl.cs.brown.edu/research/unitac.\n","authors":["Wanjia Fu","Hongyu Li","Ivy X. He","Stefanie Tellex","Srinath Sridhar"],"pdf_url":"https://arxiv.org/pdf/2507.07980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07969v1","updated":"2025-07-10T17:48:03Z","published":"2025-07-10T17:48:03Z","title":"Reinforcement Learning with Action Chunking","summary":"  We present Q-chunking, a simple yet effective recipe for improving\nreinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks.\nOur recipe is designed for the offline-to-online RL setting, where the goal is\nto leverage an offline prior dataset to maximize the sample-efficiency of\nonline learning. Effective exploration and sample-efficient learning remain\ncentral challenges in this setting, as it is not obvious how the offline data\nshould be utilized to acquire a good exploratory policy. Our key insight is\nthat action chunking, a technique popularized in imitation learning where\nsequences of future actions are predicted rather than a single action at each\ntimestep, can be applied to temporal difference (TD)-based RL methods to\nmitigate the exploration challenge. Q-chunking adopts action chunking by\ndirectly running RL in a 'chunked' action space, enabling the agent to (1)\nleverage temporally consistent behaviors from offline data for more effective\nonline exploration and (2) use unbiased $n$-step backups for more stable and\nefficient TD learning. Our experimental results demonstrate that Q-chunking\nexhibits strong offline performance and online sample efficiency, outperforming\nprior best offline-to-online methods on a range of long-horizon, sparse-reward\nmanipulation tasks.\n","authors":["Qiyang Li","Zhiyuan Zhou","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2507.07969v1.pdf","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2411.05481v2","updated":"2025-07-10T17:35:28Z","published":"2024-11-08T11:19:45Z","title":"Relative Pose Estimation for Nonholonomic Robot Formation with UWB-IO\n  Measurements","summary":"  This article studies the problem of distributed formation control for\nmultiple robots by using onboard ultra wide band (UWB) distance and inertial\nodometer (IO) measurements.\n  Although this problem has been widely studied, a fundamental limitation of\nmost works is that they require each robot's pose and sensor measurements are\nexpressed in a common reference frame.\n  However, it is inapplicable for nonholonomic robot formations due to the\npractical difficulty of aligning IO measurements of individual robot in a\ncommon frame.\n  To address this problem, firstly, a concurrent-learning based estimator is\nfirstly proposed to achieve relative localization between neighboring robots in\na local frame.\n  Different from most relative localization methods in a global frame, both\nrelative position and orientation in a local frame are estimated with only UWB\nranging and IO\n  measurements.\n  Secondly, to deal with information loss caused by directed communication\ntopology, a cooperative localization algorithm is introduced to estimate the\nrelative pose to the leader robot.\n  Thirdly, based on the theoretical results on relative pose estimation, a\ndistributed formation tracking controller is proposed for nonholonomic robots.\n  Both 3D and 2D real-world experiments conducted on aerial robots and grounded\nrobots are provided to demonstrate the effectiveness of the proposed method.\n","authors":["Kunrui Ze","Wei Wang","Shuoyu Yue","Guibin Sun","Kexin Liu","Jinhu Lü"],"pdf_url":"https://arxiv.org/pdf/2411.05481v2.pdf","comment":"11 pages, 12 figures"},{"id":"http://arxiv.org/abs/2505.16042v2","updated":"2025-07-10T16:53:20Z","published":"2025-05-21T21:48:51Z","title":"Reference Free Platform Adaptive Locomotion for Quadrupedal Robots using\n  a Dynamics Conditioned Policy","summary":"  This article presents Platform Adaptive Locomotion (PAL), a unified control\nmethod for quadrupedal robots with different morphologies and dynamics. We\nleverage deep reinforcement learning to train a single locomotion policy on\nprocedurally generated robots. The policy maps proprioceptive robot state\ninformation and base velocity commands into desired joint actuation targets,\nwhich are conditioned using a latent embedding of the temporally local system\ndynamics. We explore two conditioning strategies - one using a GRU-based\ndynamics encoder and another using a morphology-based property estimator - and\nshow that morphology-aware conditioning outperforms temporal dynamics encoding\nregarding velocity task tracking for our hardware test on ANYmal C. Our results\ndemonstrate that both approaches achieve robust zero-shot transfer across\nmultiple unseen simulated quadrupeds. Furthermore, we demonstrate the need for\ncareful robot reference modelling during training: exposing the policy to a\ndiverse set of robot morphologies and dynamics leads to improved\ngeneralization, reducing the velocity tracking error by up to 30% compared to\nthe baseline method. Despite PAL not surpassing the best-performing\nreference-free controller in all cases, our analysis uncovers critical design\nchoices and informs improvements to the state of the art.\n","authors":["David Rytz","Suyoung Choi","Wanming Yu","Wolfgang Merkt","Jemin Hwangbo","Ioannis Havoutis"],"pdf_url":"https://arxiv.org/pdf/2505.16042v2.pdf","comment":"8 pages, 6 tables, 5 figures"},{"id":"http://arxiv.org/abs/2507.07872v1","updated":"2025-07-10T15:55:05Z","published":"2025-07-10T15:55:05Z","title":"Improving AEBS Validation Through Objective Intervention Classification\n  Leveraging the Prediction Divergence Principle","summary":"  The safety validation of automatic emergency braking system (AEBS) requires\naccurately distinguishing between false positive (FP) and true positive (TP)\nsystem activations. While simulations allow straightforward differentiation by\ncomparing scenarios with and without interventions, analyzing activations from\nopen-loop resimulations - such as those from field operational testing (FOT) -\nis more complex. This complexity arises from scenario parameter uncertainty and\nthe influence of driver interventions in the recorded data. Human labeling is\nfrequently used to address these challenges, relying on subjective assessments\nof intervention necessity or situational criticality, potentially introducing\nbiases and limitations. This work proposes a rule-based classification approach\nleveraging the Prediction Divergence Principle (PDP) to address those issues.\nApplied to a simplified AEBS, the proposed method reveals key strengths,\nlimitations, and system requirements for effective implementation. The findings\nsuggest that combining this approach with human labeling may enhance the\ntransparency and consistency of classification, thereby improving the overall\nvalidation process. While the rule set for classification derived in this work\nadopts a conservative approach, the paper outlines future directions for\nrefinement and broader applicability. Finally, this work highlights the\npotential of such methods to complement existing practices, paving the way for\nmore reliable and reproducible AEBS validation frameworks.\n","authors":["Daniel Betschinske","Steven Peters"],"pdf_url":"https://arxiv.org/pdf/2507.07872v1.pdf","comment":"This work has been accepted for publication at the 2025 IEEE\n  International Automated Vehicle Validation Conference (IAVVC)"},{"id":"http://arxiv.org/abs/2403.13318v2","updated":"2025-07-10T15:36:30Z","published":"2024-03-20T05:46:56Z","title":"A Survey of Machine Learning for Estimating Workload: Considering\n  Unknown Tasks","summary":"  Successful human-robot teaming will require robots to adapt autonomously to a\nhuman teammate's internal state, where a critical element of such adaptation is\nthe ability to estimate the human's workload in unknown situations. Existing\nworkload models use machine learning to model the relationship between\nphysiological signals and workload. These methods often struggle to generalize\nto unknown tasks, as the relative importance of various physiological signals\nchange significantly between tasks. Many of these changes constitute a\nmeaningful shift in the data's distribution, which violates a core assumption\nmade by the underlying machine learning approach. A survey of machine learning\ntechniques designed to overcome these challenges is presented, where common\ntechniques are evaluated using three criteria: portability, model complexity,\nand adaptability. These criteria are used to analyze each technique's\napplicability to estimating workload during unknown tasks in dynamic\nenvironments and guide future empirical experimentation.\n","authors":["Josh Bhagat Smith","Julie A. Adams"],"pdf_url":"https://arxiv.org/pdf/2403.13318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07846v1","updated":"2025-07-10T15:24:31Z","published":"2025-07-10T15:24:31Z","title":"ROS Help Desk: GenAI Powered, User-Centric Framework for ROS Error\n  Diagnosis and Debugging","summary":"  As the robotics systems increasingly integrate into daily life, from smart\nhome assistants to the new-wave of industrial automation systems (Industry\n4.0), there's an increasing need to bridge the gap between complex robotic\nsystems and everyday users. The Robot Operating System (ROS) is a flexible\nframework often utilised in writing robot software, providing tools and\nlibraries for building complex robotic systems. However, ROS's distributed\narchitecture and technical messaging system create barriers for understanding\nrobot status and diagnosing errors. This gap can lead to extended maintenance\ndowntimes, as users with limited ROS knowledge may struggle to quickly diagnose\nand resolve system issues. Moreover, this deficit in expertise often delays\nproactive maintenance and troubleshooting, further increasing the frequency and\nduration of system interruptions. ROS Help Desk provides intuitive error\nexplanations and debugging support, dynamically customized to users of varying\nexpertise levels. It features user-centric debugging tools that simplify error\ndiagnosis, implements proactive error detection capabilities to reduce\ndowntime, and integrates multimodal data processing for comprehensive system\nstate understanding across multi-sensor data (e.g., lidar, RGB). Testing\nqualitatively and quantitatively with artificially induced errors demonstrates\nthe system's ability to proactively and accurately diagnose problems,\nultimately reducing maintenance time and fostering more effective human-robot\ncollaboration.\n","authors":["Kavindie Katuwandeniya","Samith Rajapaksha Jayasekara Widhanapathirana"],"pdf_url":"https://arxiv.org/pdf/2507.07846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07845v1","updated":"2025-07-10T15:22:32Z","published":"2025-07-10T15:22:32Z","title":"Perceptual Distortions and Autonomous Representation Learning in a\n  Minimal Robotic System","summary":"  Autonomous agents, particularly in the field of robotics, rely on sensory\ninformation to perceive and navigate their environment. However, these sensory\ninputs are often imperfect, leading to distortions in the agent's internal\nrepresentation of the world. This paper investigates the nature of these\nperceptual distortions and how they influence autonomous representation\nlearning using a minimal robotic system. We utilize a simulated two-wheeled\nrobot equipped with distance sensors and a compass, operating within a simple\nsquare environment. Through analysis of the robot's sensor data during random\nexploration, we demonstrate how a distorted perceptual space emerges. Despite\nthese distortions, we identify emergent structures within the perceptual space\nthat correlate with the physical environment, revealing how the robot\nautonomously learns a structured representation for navigation without explicit\nspatial information. This work contributes to the understanding of embodied\ncognition, minimal agency, and the role of perception in self-generated\nnavigation strategies in artificial life.\n","authors":["David Warutumo","Ciira wa Maina"],"pdf_url":"https://arxiv.org/pdf/2507.07845v1.pdf","comment":"2 authors, 23 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.05548v5","updated":"2025-07-10T15:05:04Z","published":"2024-11-08T13:11:16Z","title":"Equivariant IMU Preintegration with Biases: a Galilean Group Approach","summary":"  This letter proposes a new approach for Inertial Measurement Unit (IMU)\npreintegration, a fundamental building block that can be leveraged in different\noptimization-based Inertial Navigation System (INS) localization solutions.\nInspired by recent advances in equivariant theory applied to biased INSs, we\nderive a discrete-time formulation of the IMU preintegration on\n${\\mathbf{Gal}(3) \\ltimes \\mathfrak{gal}(3)}$, the left-trivialization of the\ntangent group of the Galilean group $\\mathbf{Gal}(3)$. We define a novel\npreintegration error that geometrically couples the navigation states and the\nbias leading to lower linearization error. Our method improves in consistency\ncompared to existing preintegration approaches which treat IMU biases as a\nseparate state-space. Extensive validation against state-of-the-art methods,\nboth in simulation and with real-world IMU data, implementation in the Lie++\nlibrary, and open-source code are provided.\n","authors":["Giulio Delama","Alessandro Fornasier","Robert Mahony","Stephan Weiss"],"pdf_url":"https://arxiv.org/pdf/2411.05548v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07825v1","updated":"2025-07-10T14:54:52Z","published":"2025-07-10T14:54:52Z","title":"Beyond Robustness: Learning Unknown Dynamic Load Adaptation for\n  Quadruped Locomotion on Rough Terrain","summary":"  Unknown dynamic load carrying is one important practical application for\nquadruped robots. Such a problem is non-trivial, posing three major challenges\nin quadruped locomotion control. First, how to model or represent the dynamics\nof the load in a generic manner. Second, how to make the robot capture the\ndynamics without any external sensing. Third, how to enable the robot to\ninteract with load handling the mutual effect and stabilizing the load. In this\nwork, we propose a general load modeling approach called load characteristics\nmodeling to capture the dynamics of the load. We integrate this proposed\nmodeling technique and leverage recent advances in Reinforcement Learning (RL)\nbased locomotion control to enable the robot to infer the dynamics of load\nmovement and interact with the load indirectly to stabilize it and realize the\nsim-to-real deployment to verify its effectiveness in real scenarios. We\nconduct extensive comparative simulation experiments to validate the\neffectiveness and superiority of our proposed method. Results show that our\nmethod outperforms other methods in sudden load resistance, load stabilizing\nand locomotion with heavy load on rough terrain.\n\\href{https://leixinjonaschang.github.io/leggedloadadapt.github.io/}{Project\nPage}.\n","authors":["Leixin Chang","Yuxuan Nai","Hua Chen","Liangjing Yang"],"pdf_url":"https://arxiv.org/pdf/2507.07825v1.pdf","comment":"Accepted to the 2025 IEEE International Conference on Robotics &\n  Automation (ICRA). 8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2507.05116v2","updated":"2025-07-10T14:53:51Z","published":"2025-07-07T15:30:55Z","title":"VOTE: Vision-Language-Action Optimization with Trajectory Ensemble\n  Voting","summary":"  Recent large-scale Vision Language Action (VLA) models have shown superior\nperformance in robotic manipulation tasks guided by natural language. However,\ntheir generalization remains limited when applied to novel objects or\nunfamiliar environments that lie outside the training distribution. To address\nthis, many existing approaches integrate additional components such as depth\nestimation, segmentation, or even diffusion to improve generalization, at the\ncost of adding significant computation overhead, resulting in low efficiency.\nThis motivates the exploration of efficient action prediction methods, which\nare independent of additional high-level visual representations or diffusion\ntechniques. In this work, we propose VOTE, an efficient and general framework\nfor the optimization and acceleration of VLA models. In details, we propose a\nnovel tokenizer-free fine-tuning approach for parallel accurate action\nprediction, which reduces computational overhead and accelerates inference\nspeed. Additionally, we adopt an ensemble voting strategy for the action\nsampling, which significantly improves model performance and enhances\ngeneralization. Experimental results show that our method achieves\nstate-of-the-art performance with 35x faster inference and 145 Hz throughput.\nAll the details and codes will be open-sourced.\n","authors":["Juyi Lin","Amir Taherin","Arash Akbari","Arman Akbari","Lei Lu","Guangyu Chen","Taskin Padir","Xiaomeng Yang","Weiwei Chen","Yiqian Li","Xue Lin","David Kaeli","Pu Zhao","Yanzhi Wang"],"pdf_url":"https://arxiv.org/pdf/2507.05116v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07794v1","updated":"2025-07-10T14:20:34Z","published":"2025-07-10T14:20:34Z","title":"Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy:\n  Optical Tracking based Approach","summary":"  Mandibular Angle Split Osteotomy (MASO) is a significant procedure in oral\nand maxillofacial surgery. Despite advances in technique and instrumentation,\nits success still relies heavily on the surgeon's experience. In this work, a\nhuman-robot collaborative system is proposed to perform MASO according to a\npreoperative plan and under guidance of a surgeon. A task decomposition\nmethodology is used to divide the collaborative surgical procedure into three\nsubtasks: (1) positional control and (2) orientation control, both led by the\nrobot for precise alignment; and (3) force-control, managed by surgeon to\nensure safety. Additionally, to achieve patient tracking without the need for a\nskull clamp, an optical tracking system (OTS) is utilized. Movement of the\npatient mandibular is measured with an optical-based tracker mounted on a\ndental occlusal splint. A registration method and Robot-OTS calibration method\nare introduced to achieve reliable navigation within our framework. The\nexperiments of drilling were conducted on the realistic phantom model, which\ndemonstrated that the average error between the planned and actual drilling\npoints is 1.85mm.\n","authors":["Zhe Han","Huanyu Tian","Tom Vercauteren","Da Liu","Changsheng Li","Xingguang Duan"],"pdf_url":"https://arxiv.org/pdf/2507.07794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07781v1","updated":"2025-07-10T14:01:24Z","published":"2025-07-10T14:01:24Z","title":"SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex\n  3D Scenes","summary":"  The integration of language and 3D perception is critical for embodied AI and\nrobotic systems to perceive, understand, and interact with the physical world.\nSpatial reasoning, a key capability for understanding spatial relationships\nbetween objects, remains underexplored in current 3D vision-language research.\nExisting datasets often mix semantic cues (e.g., object name) with spatial\ncontext, leading models to rely on superficial shortcuts rather than genuinely\ninterpreting spatial relationships. To address this gap, we introduce\nS\\textsc{urprise}3D, a novel dataset designed to evaluate language-guided\nspatial reasoning segmentation in complex 3D scenes. S\\textsc{urprise}3D\nconsists of more than 200k vision language pairs across 900+ detailed indoor\nscenes from ScanNet++ v2, including more than 2.8k unique object classes. The\ndataset contains 89k+ human-annotated spatial queries deliberately crafted\nwithout object name, thereby mitigating shortcut biases in spatial\nunderstanding. These queries comprehensively cover various spatial reasoning\nskills, such as relative position, narrative perspective, parametric\nperspective, and absolute distance reasoning. Initial benchmarks demonstrate\nsignificant challenges for current state-of-the-art expert 3D visual grounding\nmethods and 3D-LLMs, underscoring the necessity of our dataset and the\naccompanying 3D Spatial Reasoning Segmentation (3D-SRS) benchmark suite.\nS\\textsc{urprise}3D and 3D-SRS aim to facilitate advancements in spatially\naware AI, paving the way for effective embodied interaction and robotic\nplanning. The code and datasets can be found in\nhttps://github.com/liziwennba/SUPRISE.\n","authors":["Jiaxin Huang","Ziwen Li","Hanlve Zhang","Runnan Chen","Xiao He","Yandong Guo","Wenping Wang","Tongliang Liu","Mingming Gong"],"pdf_url":"https://arxiv.org/pdf/2507.07781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07752v1","updated":"2025-07-10T13:32:19Z","published":"2025-07-10T13:32:19Z","title":"IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End\n  for Visual SLAM in Challenging Environments","summary":"  Robust Visual SLAM (vSLAM) is essential for autonomous systems operating in\nreal-world environments, where challenges such as dynamic objects, low texture,\nand critically, varying illumination conditions often degrade performance.\nExisting feature-based SLAM systems rely on fixed front-end parameters, making\nthem vulnerable to sudden lighting changes and unstable feature tracking. To\naddress these challenges, we propose ``IRAF-SLAM'', an Illumination-Robust and\nAdaptive Feature-Culling front-end designed to enhance vSLAM resilience in\ncomplex and challenging environments. Our approach introduces: (1) an image\nenhancement scheme to preprocess and adjust image quality under varying\nlighting conditions; (2) an adaptive feature extraction mechanism that\ndynamically adjusts detection sensitivity based on image entropy, pixel\nintensity, and gradient analysis; and (3) a feature culling strategy that\nfilters out unreliable feature points using density distribution analysis and a\nlighting impact factor. Comprehensive evaluations on the TUM-VI and European\nRobotics Challenge (EuRoC) datasets demonstrate that IRAF-SLAM significantly\nreduces tracking failures and achieves superior trajectory accuracy compared to\nstate-of-the-art vSLAM methods under adverse illumination conditions. These\nresults highlight the effectiveness of adaptive front-end strategies in\nimproving vSLAM robustness without incurring significant computational\noverhead. The implementation of IRAF-SLAM is publicly available at\nhttps://thanhnguyencanh. github.io/IRAF-SLAM/.\n","authors":["Thanh Nguyen Canh","Bao Nguyen Quoc","Haolan Zhang","Bupesh Rethinam Veeraiah","Xiem HoangVan","Nak Young Chong"],"pdf_url":"https://arxiv.org/pdf/2507.07752v1.pdf","comment":"In the European Conference on Mobile Robots 2025"},{"id":"http://arxiv.org/abs/2507.07745v1","updated":"2025-07-10T13:25:18Z","published":"2025-07-10T13:25:18Z","title":"On the capabilities of LLMs for classifying and segmenting time series\n  of fruit picking motions into primitive actions","summary":"  Despite their recent introduction to human society, Large Language Models\n(LLMs) have significantly affected the way we tackle mental challenges in our\neveryday lives. From optimizing our linguistic communication to assisting us in\nmaking important decisions, LLMs, such as ChatGPT, are notably reducing our\ncognitive load by gradually taking on an increasing share of our mental\nactivities. In the context of Learning by Demonstration (LbD), classifying and\nsegmenting complex motions into primitive actions, such as pushing, pulling,\ntwisting etc, is considered to be a key-step towards encoding a task. In this\nwork, we investigate the capabilities of LLMs to undertake this task,\nconsidering a finite set of predefined primitive actions found in fruit picking\noperations. By utilizing LLMs instead of simple supervised learning or analytic\nmethods, we aim at making the method easily applicable and deployable in a\nreal-life scenario. Three different fine-tuning approaches are investigated,\ncompared on datasets captured kinesthetically, using a UR10e robot, during a\nfruit-picking scenario.\n","authors":["Eleni Konstantinidou","Nikolaos Kounalakis","Nikolaos Efstathopoulos","Dimitrios Papageorgiou"],"pdf_url":"https://arxiv.org/pdf/2507.07745v1.pdf","comment":"This paper is a Late Breaking Results report and it will be presented\n  through a poster at the 34th IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN), 2025 at Eindhoven, the Netherlands"},{"id":"http://arxiv.org/abs/2502.20805v2","updated":"2025-07-10T13:08:40Z","published":"2025-02-28T07:42:54Z","title":"FunHOI: Annotation-Free 3D Hand-Object Interaction Generation via\n  Functional Text Guidanc","summary":"  Hand-object interaction(HOI) is the fundamental link between human and\nenvironment, yet its dexterous and complex pose significantly challenges for\ngesture control. Despite significant advances in AI and robotics, enabling\nmachines to understand and simulate hand-object interactions, capturing the\nsemantics of functional grasping tasks remains a considerable challenge. While\nprevious work can generate stable and correct 3D grasps, they are still far\nfrom achieving functional grasps due to unconsidered grasp semantics. To\naddress this challenge, we propose an innovative two-stage framework,\nFunctional Grasp Synthesis Net (FGS-Net), for generating 3D HOI driven by\nfunctional text. This framework consists of a text-guided 3D model generator,\nFunctional Grasp Generator (FGG), and a pose optimization strategy, Functional\nGrasp Refiner (FGR). FGG generates 3D models of hands and objects based on text\ninput, while FGR fine-tunes the poses using Object Pose Approximator and energy\nfunctions to ensure the relative position between the hand and object aligns\nwith human intent and remains physically plausible. Extensive experiments\ndemonstrate that our approach achieves precise and high-quality HOI generation\nwithout requiring additional 3D annotation data.\n","authors":["Yongqi Tian","Xueyu Sun","Haoyuan He","Linji Hao","Ning Ding","Caigui Jiang"],"pdf_url":"https://arxiv.org/pdf/2502.20805v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07724v1","updated":"2025-07-10T12:58:30Z","published":"2025-07-10T12:58:30Z","title":"Distributed Surface Inspection via Operational Modal Analysis by a Swarm\n  of Miniaturized Vibration-Sensing Robots","summary":"  Robot swarms offer the potential to serve a variety of distributed sensing\napplications. An interesting real-world application that stands to benefit\nsignificantly from deployment of swarms is structural monitoring, where\ntraditional sensor networks face challenges in structural coverage due to their\nstatic nature. This paper investigates the deployment of a swarm of\nminiaturized vibration sensing robots to inspect and localize structural\ndamages on a surface section within a high-fidelity simulation environment. In\nparticular, we consider a 1 m x 1 m x 3 mm steel surface section and utilize\nfinite element analysis using Abaqus to obtain realistic structural vibration\ndata. The resulting vibration data is imported into the physics-based robotic\nsimulator Webots, where we simulate the dynamics of our surface inspecting\nrobot swarm. We employ (i) Gaussian process estimators to guide the robots'\nexploration as they collect vibration samples across the surface and (ii)\noperational modal analysis to detect structural damages by estimating and\ncomparing existing and intact structural vibration patterns. We analyze the\ninfluence of exploration radii on estimation uncertainty and assess the\neffectiveness of our method across 10 randomized scenarios, where the number,\nlocations, surface area, and depth of structural damages vary. Our simulation\nstudies validate the efficacy of our miniaturized robot swarm for\nvibration-based structural inspection.\n","authors":["Thiemen Siemensma","Niels de Boer","Bahar Haghighat"],"pdf_url":"https://arxiv.org/pdf/2507.07724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07718v1","updated":"2025-07-10T12:55:04Z","published":"2025-07-10T12:55:04Z","title":"Implementation and Assessment of an Augmented Training Curriculum for\n  Surgical Robotics","summary":"  The integration of high-level assistance algorithms in surgical robotics\ntraining curricula may be beneficial in establishing a more comprehensive and\nrobust skillset for aspiring surgeons, improving their clinical performance as\na consequence. This work presents the development and validation of a\nhaptic-enhanced Virtual Reality simulator for surgical robotics training,\nfeaturing 8 surgical tasks that the trainee can interact with thanks to the\nembedded physics engine. This virtual simulated environment is augmented by the\nintroduction of high-level haptic interfaces for robotic assistance that aim at\nre-directing the motion of the trainee's hands and wrists toward targets or\naway from obstacles, and providing a quantitative performance score after the\nexecution of each training exercise.An experimental study shows that the\nintroduction of enhanced robotic assistance into a surgical robotics training\ncurriculum improves performance during the training process and, crucially,\npromotes the transfer of the acquired skills to an unassisted surgical\nscenario, like the clinical one.\n","authors":["Alberto Rota","Ke Fan","Elena De Momi"],"pdf_url":"https://arxiv.org/pdf/2507.07718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07714v1","updated":"2025-07-10T12:52:19Z","published":"2025-07-10T12:52:19Z","title":"Adaptive Gaussian Mixture Models-based Anomaly Detection for\n  under-constrained Cable-Driven Parallel Robots","summary":"  Cable-Driven Parallel Robots (CDPRs) are increasingly used for load\nmanipulation tasks involving predefined toolpaths with intermediate stops. At\neach stop, where the platform maintains a fixed pose and the motors keep the\ncables under tension, the system must evaluate whether it is safe to proceed by\ndetecting anomalies that could compromise performance (e.g., wind gusts or\ncable impacts). This paper investigates whether anomalies can be detected using\nonly motor torque data, without additional sensors. It introduces an adaptive,\nunsupervised outlier detection algorithm based on Gaussian Mixture Models\n(GMMs) to identify anomalies from torque signals. The method starts with a\nbrief calibration period, just a few seconds, during which a GMM is fit on\nknown anomaly-free data. Real-time torque measurements are then evaluated using\nMahalanobis distance from the GMM, with statistically derived thresholds\ntriggering anomaly flags. Model parameters are periodically updated using the\nlatest segments identified as anomaly-free to adapt to changing conditions.\nValidation includes 14 long-duration test sessions simulating varied wind\nintensities. The proposed method achieves a 100% true positive rate and 95.4%\naverage true negative rate, with 1-second detection latency. Comparative\nevaluation against power threshold and non-adaptive GMM methods indicates\nhigher robustness to drift and environmental variation.\n","authors":["Julio Garrido","Javier Vales","Diego Silva-Muñiz","Enrique Riveiro","Pablo López-Matencio","Josué Rivera-Andrade"],"pdf_url":"https://arxiv.org/pdf/2507.07714v1.pdf","comment":"14 pages, 8 figures, 1 table, to be submitted to Advanced Intelligent\n  Systems"},{"id":"http://arxiv.org/abs/2404.08390v2","updated":"2025-07-10T12:46:14Z","published":"2024-04-12T10:48:59Z","title":"Collective Bayesian Decision-Making in a Swarm of Miniaturized Robots\n  for Surface Inspection","summary":"  Robot swarms can effectively serve a variety of sensing and inspection\napplications. Certain inspection tasks require a binary classification\ndecision. This work presents an experimental setup for a surface inspection\ntask based on vibration sensing and studies a Bayesian two-outcome\ndecision-making algorithm in a swarm of miniaturized wheeled robots. The robots\nare tasked with individually inspecting and collectively classifying a 1mx1m\ntiled surface consisting of vibrating and non-vibrating tiles based on the\nmajority type of tiles. The robots sense vibrations using onboard IMUs and\nperform collision avoidance using a set of IR sensors. We develop a simulation\nand optimization framework leveraging the Webots robotic simulator and a\nParticle Swarm Optimization (PSO) method. We consider two existing information\nsharing strategies and propose a new one that allows the swarm to rapidly reach\naccurate classification decisions. We first find optimal parameters that allow\nefficient sampling in simulation and then evaluate our proposed strategy\nagainst the two existing ones using 100 randomized simulation and 10 real\nexperiments. We find that our proposed method compels the swarm to make\ndecisions at an accelerated rate, with an improvement of up to 20.52% in mean\ndecision time at only 0.78% loss in accuracy.\n","authors":["Thiemen Siemensma","Darren Chiu","Sneha Ramshanker","Radhika Nagpal","Bahar Haghighat"],"pdf_url":"https://arxiv.org/pdf/2404.08390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07661v1","updated":"2025-07-10T11:36:27Z","published":"2025-07-10T11:36:27Z","title":"FiDTouch: A 3D Wearable Haptic Display for the Finger Pad","summary":"  The applications of fingertip haptic devices have spread to various fields\nfrom revolutionizing virtual reality and medical training simulations to\nfacilitating remote robotic operations, proposing great potential for enhancing\nuser experiences, improving training outcomes, and new forms of interaction. In\nthis work, we present FiDTouch, a 3D wearable haptic device that delivers\ncutaneous stimuli to the finger pad, such as contact, pressure, encounter, skin\nstretch, and vibrotactile feedback. The application of a tiny inverted Delta\nrobot in the mechanism design allows providing accurate contact and fast\nchanging dynamic stimuli to the finger pad surface. The performance of the\ndeveloped display was evaluated in a two-stage user study of the perception of\nstatic spatial contact stimuli and skin stretch stimuli generated on the finger\npad. The proposed display, by providing users with precise touch and force\nstimuli, can enhance user immersion and efficiency in the fields of\nhuman-computer and human-robot interactions.\n","authors":["Daria Trinitatova","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2507.07661v1.pdf","comment":"Accepted to the IEEE World Haptics Conference 2025 (IEEE WHC 2025), 7\n  pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2507.06562v2","updated":"2025-07-10T11:05:21Z","published":"2025-07-09T05:30:53Z","title":"KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and\n  Wall Climbing","summary":"  In recent years, advancements in hardware have enabled quadruped robots to\noperate with high power and speed, while robust locomotion control using\nreinforcement learning (RL) has also been realized. As a result, expectations\nare rising for the automation of tasks such as material transport and\nexploration in unknown environments. However, autonomous locomotion in rough\nterrains with significant height variations requires vertical movement, and\nrobots capable of performing such movements stably, along with their control\nmethods, have not yet been fully established. In this study, we developed the\nquadruped robot KLEIYN, which features a waist joint, and aimed to expand\nquadruped locomotion by enabling chimney climbing through RL. To facilitate the\nlearning of vertical motion, we introduced Contact-Guided Curriculum Learning\n(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to\n1000 mm in width at an average speed of 150 mm/s, 50 times faster than\nconventional robots. Furthermore, we demonstrated that the introduction of a\nwaist joint improves climbing performance, particularly enhancing tracking\nability on narrow walls.\n","authors":["Keita Yoneda","Kento Kawaharazuka","Temma Suzuki","Takahiro Hattori","Kei Okada"],"pdf_url":"https://arxiv.org/pdf/2507.06562v2.pdf","comment":"Accepted at IROS2025, website -\n  https://keitayoneda.github.io/kleiyn-chimney-climbing/, YouTube -\n  https://www.youtube.com/watch?v=cLfUhyNFOeY"},{"id":"http://arxiv.org/abs/2503.23760v2","updated":"2025-07-10T10:55:31Z","published":"2025-03-31T06:23:14Z","title":"Towards a cognitive architecture to enable natural language interaction\n  in co-constructive task learning","summary":"  This research addresses the question, which characteristics a cognitive\narchitecture must have to leverage the benefits of natural language in\nCo-Constructive Task Learning (CCTL). To provide context, we first discuss\nInteractive Task Learning (ITL), the mechanisms of the human memory system, and\nthe significance of natural language and multi-modality. Next, we examine the\ncurrent state of cognitive architectures, analyzing their capabilities to\ninform a concept of CCTL grounded in multiple sources. We then integrate\ninsights from various research domains to develop a unified framework. Finally,\nwe conclude by identifying the remaining challenges and requirements necessary\nto achieve CCTL in Human-Robot Interaction (HRI).\n","authors":["Manuel Scheibl","Birte Richter","Alissa Müller","Michael Beetz","Britta Wrede"],"pdf_url":"https://arxiv.org/pdf/2503.23760v2.pdf","comment":"8 pages, 5 figures, accepted at: IEEE RO-MAN 2025 Conference"},{"id":"http://arxiv.org/abs/2507.07560v1","updated":"2025-07-10T08:59:18Z","published":"2025-07-10T08:59:18Z","title":"Conjugated Capabilities: Interrelations of Elementary Human Capabilities\n  and Their Implication on Human-Machine Task Allocation and Capability Testing\n  Procedures","summary":"  Human and automation capabilities are the foundation of every human-autonomy\ninteraction and interaction pattern. Therefore, machines need to understand the\ncapacity and performance of human doing, and adapt their own behavior,\naccordingly. In this work, we address the concept of conjugated capabilities,\ni.e. capabilities that are dependent or interrelated and between which effort\ncan be distributed. These may be used to overcome human limitations, by\nshifting effort from a deficient to a conjugated capability with performative\nresources. For example: A limited arm's reach may be compensated by tilting the\ntorso forward. We analyze the interrelation between elementary capabilities\nwithin the IMBA standard to uncover potential conjugation, and show evidence in\ndata of post-rehabilitation patients. From the conjugated capabilities, within\nthe example application of stationary manufacturing, we create a network of\ninterrelations. With this graph, a manifold of potential uses is enabled. We\nshowcase the graph's usage in optimizing IMBA test design to accelerate data\nrecordings, and discuss implications of conjugated capabilities on task\nallocation between the human and an autonomy.\n","authors":["Nils Mandischer","Larissa Füller","Torsten Alles","Frank Flemisch","Lars Mikelsons"],"pdf_url":"https://arxiv.org/pdf/2507.07560v1.pdf","comment":"This work was accepted by the IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC), Vienna, Austria, 2025"},{"id":"http://arxiv.org/abs/2506.22827v3","updated":"2025-07-10T08:49:49Z","published":"2025-06-28T09:39:37Z","title":"Hierarchical Vision-Language Planning for Multi-Step Humanoid\n  Manipulation","summary":"  Enabling humanoid robots to reliably execute complex multi-step manipulation\ntasks is crucial for their effective deployment in industrial and household\nenvironments. This paper presents a hierarchical planning and control framework\ndesigned to achieve reliable multi-step humanoid manipulation. The proposed\nsystem comprises three layers: (1) a low-level RL-based controller responsible\nfor tracking whole-body motion targets; (2) a mid-level set of skill policies\ntrained via imitation learning that produce motion targets for different steps\nof a task; and (3) a high-level vision-language planning module that determines\nwhich skills should be executed and also monitors their completion in real-time\nusing pretrained vision-language models (VLMs). Experimental validation is\nperformed on a Unitree G1 humanoid robot executing a non-prehensile\npick-and-place task. Over 40 real-world trials, the hierarchical system\nachieved a 73% success rate in completing the full manipulation sequence. These\nexperiments confirm the feasibility of the proposed hierarchical system,\nhighlighting the benefits of VLM-based skill planning and monitoring for\nmulti-step manipulation scenarios. See https://vlp-humanoid.github.io/ for\nvideo demonstrations of the policy rollout.\n","authors":["André Schakkal","Ben Zandonati","Zhutian Yang","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2506.22827v3.pdf","comment":"Accepted at the RSS 2025 Workshop on Robot Planning in the Era of\n  Foundation Models"},{"id":"http://arxiv.org/abs/2507.07550v1","updated":"2025-07-10T08:47:41Z","published":"2025-07-10T08:47:41Z","title":"Pluri-perspectivism in Human-robot Co-creativity with Older Adults","summary":"  This position paper explores pluriperspectivism as a core element of human\ncreative experience and its relevance to humanrobot cocreativity We propose a\nlayered fivedimensional model to guide the design of cocreative behaviors and\nthe analysis of interaction dynamics This model is based on literature and\nresults from an interview study we conducted with 10 visual artists and 8 arts\neducators examining how pluriperspectivism supports creative practice The\nfindings of this study provide insight in how robots could enhance human\ncreativity through adaptive contextsensitive behavior demonstrating the\npotential of pluriperspectivism This paper outlines future directions for\nintegrating pluriperspectivism with visionlanguage models VLMs to support\ncontext sensitivity in cocreative robots\n","authors":["Marianne Bossema","Rob Saunders","Aske Plaat","Somaya Ben Allouch"],"pdf_url":"https://arxiv.org/pdf/2507.07550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.13554v2","updated":"2025-07-10T07:28:13Z","published":"2025-04-18T08:44:06Z","title":"Task Assignment and Exploration Optimization for Low Altitude UAV Rescue\n  via Generative AI Enhanced Multi-agent Reinforcement Learning","summary":"  The integration of emerging uncrewed aerial vehicles (UAVs) with artificial\nintelligence (AI) and ground-embedded robots (GERs) has transformed emergency\nrescue operations in unknown environments. However, the high computational\ndemands often exceed a single UAV's capacity, making it difficult to\ncontinuously provide stable high-level services. To address this, this paper\nproposes a cooperation framework involving UAVs, GERs, and airships. The\nframework enables resource pooling through UAV-to-GER (U2G) and UAV-to-airship\n(U2A) links, offering computing services for offloaded tasks. Specifically, we\nformulate the multi-objective problem of task assignment and exploration as a\ndynamic long-term optimization problem aiming to minimize task completion time\nand energy use while ensuring stability. Using Lyapunov optimization, we\ntransform it into a per-slot deterministic problem and propose HG-MADDPG, which\ncombines the Hungarian algorithm with a GDM-based multi-agent deep\ndeterministic policy gradient. Simulations demonstrate significant improvements\nin offloading efficiency, latency, and system stability over baselines.\n","authors":["Xin Tang","Qian Chen","Wenjie Weng","Chao Jin","Zhang Liu","Jiacheng Wang","Geng Sun","Xiaohuan Li","Dusit Niyato"],"pdf_url":"https://arxiv.org/pdf/2504.13554v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07467v1","updated":"2025-07-10T06:42:53Z","published":"2025-07-10T06:42:53Z","title":"SCREP: Scene Coordinate Regression and Evidential Learning-based\n  Perception-Aware Trajectory Generation","summary":"  Autonomous flight in GPS denied indoor spaces requires trajectories that keep\nvisual localization error tightly bounded across varied missions. Whereas\nvisual inertial odometry (VIO) accumulates drift over time, scene coordinate\nregression (SCR) yields drift-free, high accuracy absolute pose estimation. We\npresent a perception-aware framework that couples an evidential learning-based\nSCR pose estimator with a receding horizon trajectory optimizer. The optimizer\nsteers the onboard camera toward pixels whose uncertainty predicts reliable\nscene coordinates, while a fixed-lag smoother fuses the low rate SCR stream\nwith high rate IMU data to close the perception control loop in real time. In\nsimulation, our planner reduces translation (rotation) mean error by 54% / 15%\n(40% / 31%) relative to yaw fixed and forward-looking baselines, respectively.\nMoreover, hardware in the loop experiment validates the feasibility of our\nproposed framework.\n","authors":["Juyeop Han","Lukas Lao Beyer","Guilherme V. Cavalheiro","Sertac Karaman"],"pdf_url":"https://arxiv.org/pdf/2507.07467v1.pdf","comment":"8 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2507.07444v1","updated":"2025-07-10T05:44:34Z","published":"2025-07-10T05:44:34Z","title":"Towards Safe Autonomous Driving: A Real-Time Safeguarding Concept for\n  Motion Planning Algorithms","summary":"  Ensuring the functional safety of motion planning modules in autonomous\nvehicles remains a critical challenge, especially when dealing with complex or\nlearning-based software. Online verification has emerged as a promising\napproach to monitor such systems at runtime, yet its integration into embedded\nreal-time environments remains limited. This work presents a safeguarding\nconcept for motion planning that extends prior approaches by introducing a time\nsafeguard. While existing methods focus on geometric and dynamic feasibility,\nour approach additionally monitors the temporal consistency of planning outputs\nto ensure timely system response. A prototypical implementation on a real-time\noperating system evaluates trajectory candidates using constraint-based\nfeasibility checks and cost-based plausibility metrics. Preliminary results\nshow that the safeguarding module operates within real-time bounds and\neffectively detects unsafe trajectories. However, the full integration of the\ntime safeguard logic and fallback strategies is ongoing. This study contributes\na modular and extensible framework for runtime trajectory verification and\nhighlights key aspects for deployment on automotive-grade hardware. Future work\nincludes completing the safeguarding logic and validating its effectiveness\nthrough hardware-in-the-loop simulations and vehicle-based testing. The code is\navailable at: https://github.com/TUM-AVS/motion-planning-supervisor\n","authors":["Korbinian Moller","Rafael Neher","Marvin Seegert","Johannes Betz"],"pdf_url":"https://arxiv.org/pdf/2507.07444v1.pdf","comment":"7 pages, submitted to the IEEE ICVES 2025, Coventry, UK"},{"id":"http://arxiv.org/abs/2502.13451v4","updated":"2025-07-10T02:53:25Z","published":"2025-02-19T05:52:34Z","title":"MapNav: A Novel Memory Representation via Annotated Semantic Maps for\n  Vision-and-Language Navigation","summary":"  Vision-and-language navigation (VLN) is a key task in Embodied AI, requiring\nagents to navigate diverse and unseen environments while following natural\nlanguage instructions. Traditional approaches rely heavily on historical\nobservations as spatio-temporal contexts for decision making, leading to\nsignificant storage and computational overhead. In this paper, we introduce\nMapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map\n(ASM) to replace historical frames. Specifically, our approach constructs a\ntop-down semantic map at the start of each episode and update it at each\ntimestep, allowing for precise object mapping and structured navigation\ninformation. Then, we enhance this map with explicit textual labels for key\nregions, transforming abstract semantics into clear navigation cues and\ngenerate our ASM. MapNav agent using the constructed ASM as input, and use the\npowerful end-to-end capabilities of VLM to empower VLN. Extensive experiments\ndemonstrate that MapNav achieves state-of-the-art (SOTA) performance in both\nsimulated and real-world environments, validating the effectiveness of our\nmethod. Moreover, we will release our ASM generation source code and dataset to\nensure reproducibility, contributing valuable resources to the field. We\nbelieve that our proposed MapNav can be used as a new memory representation\nmethod in VLN, paving the way for future research in this field.\n","authors":["Lingfeng Zhang","Xiaoshuai Hao","Qinwen Xu","Qiang Zhang","Xinyao Zhang","Pengwei Wang","Jing Zhang","Zhongyuan Wang","Shanghang Zhang","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2502.13451v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07376v1","updated":"2025-07-10T02:10:18Z","published":"2025-07-10T02:10:18Z","title":"PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication\n  Framework for Dynamic Target Search of Multi-Agent in Unknown Environments","summary":"  Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster\nresponse, exploration, and reconnaissance. However, dynamic and unknown\nenvironments pose significant challenges due to target unpredictability and\nenvironmental uncertainty. To tackle these issues, we propose PILOC, a\nframework that operates without global prior knowledge, leveraging local\nperception and communication. It introduces a pheromone inverse guidance\nmechanism to enable efficient coordination and dynamic target localization.\nPILOC promotes decentralized cooperation through local communication,\nsignificantly reducing reliance on global channels. Unlike conventional\nheuristics, the pheromone mechanism is embedded into the observation space of\nDeep Reinforcement Learning (DRL), supporting indirect agent coordination based\non environmental cues. We further integrate this strategy into a DRL-based\nmulti-agent architecture and conduct extensive experiments. Results show that\ncombining local communication with pheromone-based guidance significantly\nboosts search efficiency, adaptability, and system robustness. Compared to\nexisting methods, PILOC performs better under dynamic and\ncommunication-constrained scenarios, offering promising directions for future\nMASAR applications.\n","authors":["Hengrui Liu","Yi Feng","Qilong Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06971v2","updated":"2025-07-10T01:50:07Z","published":"2025-07-09T16:01:41Z","title":"Hallucinating 360°: Panoramic Street-View Generation via Local\n  Scenes Diffusion and Probabilistic Prompting","summary":"  Panoramic perception holds significant potential for autonomous driving,\nenabling vehicles to acquire a comprehensive 360{\\deg} surround view in a\nsingle shot. However, autonomous driving is a data-driven task. Complete\npanoramic data acquisition requires complex sampling systems and annotation\npipelines, which are time-consuming and labor-intensive. Although existing\nstreet view generation models have demonstrated strong data regeneration\ncapabilities, they can only learn from the fixed data distribution of existing\ndatasets and cannot achieve high-quality, controllable panoramic generation. In\nthis paper, we propose the first panoramic generation method Percep360 for\nautonomous driving. Percep360 enables coherent generation of panoramic data\nwith control signals based on the stitched panoramic data. Percep360 focuses on\ntwo key aspects: coherence and controllability. Specifically, to overcome the\ninherent information loss caused by the pinhole sampling process, we propose\nthe Local Scenes Diffusion Method (LSDM). LSDM reformulates the panorama\ngeneration as a spatially continuous diffusion process, bridging the gaps\nbetween different data distributions. Additionally, to achieve the controllable\ngeneration of panoramic images, we propose a Probabilistic Prompting Method\n(PPM). PPM dynamically selects the most relevant control cues, enabling\ncontrollable panoramic image generation. We evaluate the effectiveness of the\ngenerated images from three perspectives: image quality assessment (i.e.,\nno-reference and with reference), controllability, and their utility in\nreal-world Bird's Eye View (BEV) segmentation. Notably, the generated data\nconsistently outperforms the original stitched images in no-reference quality\nmetrics and enhances downstream perception models. The source code will be\npublicly available at https://github.com/Bryant-Teng/Percep360.\n","authors":["Fei Teng","Kai Luo","Sheng Wu","Siyu Li","Pujun Guo","Jiale Wei","Kunyu Peng","Jiaming Zhang","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2507.06971v2.pdf","comment":"The source code will be publicly available at\n  https://github.com/Bryant-Teng/Percep360"},{"id":"http://arxiv.org/abs/2507.07370v1","updated":"2025-07-10T01:49:23Z","published":"2025-07-10T01:49:23Z","title":"Data-driven Kinematic Modeling in Soft Robots: System Identification and\n  Uncertainty Quantification","summary":"  Precise kinematic modeling is critical in calibration and controller design\nfor soft robots, yet remains a challenging issue due to their highly nonlinear\nand complex behaviors. To tackle the issue, numerous data-driven machine\nlearning approaches have been proposed for modeling nonlinear dynamics.\nHowever, these models suffer from prediction uncertainty that can negatively\naffect modeling accuracy, and uncertainty quantification for kinematic modeling\nin soft robots is underexplored. In this work, using limited simulation and\nreal-world data, we first investigate multiple linear and nonlinear machine\nlearning models commonly used for kinematic modeling of soft robots. The\nresults reveal that nonlinear ensemble methods exhibit the most robust\ngeneralization performance. We then develop a conformal kinematic modeling\nframework for soft robots by utilizing split conformal prediction to quantify\npredictive position uncertainty, ensuring distribution-free prediction\nintervals with a theoretical guarantee.\n","authors":["Zhanhong Jiang","Dylan Shah","Hsin-Jung Yang","Soumik Sarkar"],"pdf_url":"https://arxiv.org/pdf/2507.07370v1.pdf","comment":"6 pages; 6 figures; accepted at the 5th Modeling, Estimation and\n  Control Conference (MECC 2025)"},{"id":"http://arxiv.org/abs/2501.02770v4","updated":"2025-07-10T01:02:17Z","published":"2025-01-06T05:21:18Z","title":"Multi-Agent Pathfinding Under Team-Connected Communication Constraint\n  via Adaptive Path Expansion and Dynamic Leading","summary":"  This paper proposes a novel planning framework to handle a multi-agent\npathfinding problem under team-connected communication constraint, where all\nagents must have a connected communication channel to the rest of the team\nduring their entire movements. Standard multi-agent path finding approaches\n(e.g., priority-based search) have potential in this domain but fail when\nneighboring configurations at start and goal differ. Their single-expansion\napproach -- computing each agent's path from the start to the goal in just a\nsingle expansion -- cannot reliably handle planning under communication\nconstraints for agents as their neighbors change during navigating. Similarly,\nleader-follower approaches (e.g., platooning) are effective at maintaining team\ncommunication, but fixing the leader at the outset of planning can cause\nplanning to become stuck in dense-clutter environments, limiting their\npractical utility. To overcome this limitation, we propose a novel two-level\nmulti-agent pathfinding framework that integrates two techniques: adaptive path\nexpansion to expand agent paths to their goals in multiple stages; and dynamic\nleading technique that enables the reselection of the leading agent during each\nagent path expansion whenever progress cannot be made. Simulation experiments\nshow the efficiency of our planners, which can handle up to 25 agents across\nfive environment types under a limited communication range constraint and up to\n11-12 agents on three environment types under line-of-sight communication\nconstraint, exceeding 90% success-rate where baselines routinely fail.\n","authors":["Hoang-Dung Bui","Erion Plaku","Gregoy J. Stein"],"pdf_url":"https://arxiv.org/pdf/2501.02770v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07356v1","updated":"2025-07-10T00:42:59Z","published":"2025-07-10T00:42:59Z","title":"UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid\n  Robots","summary":"  Humanoid robots must achieve diverse, robust, and generalizable whole-body\ncontrol to operate effectively in complex, human-centric environments. However,\nexisting methods, particularly those based on teacher-student frameworks often\nsuffer from a loss of motion diversity during policy distillation and exhibit\nlimited generalization to unseen behaviors. In this work, we present\nUniTracker, a simplified yet powerful framework that integrates a Conditional\nVariational Autoencoder (CVAE) into the student policy to explicitly model the\nlatent diversity of human motion. By leveraging a learned CVAE prior, our\nmethod enables the student to retain expressive motion characteristics while\nimproving robustness and adaptability under partial observations. The result is\na single policy capable of tracking a wide spectrum of whole-body motions with\nhigh fidelity and stability. Comprehensive experiments in both simulation and\nreal-world deployments demonstrate that UniTracker significantly outperforms\nMLP-based DAgger baselines in motion quality, generalization to unseen\nreferences, and deployment robustness, offering a practical and scalable\nsolution for expressive humanoid control.\n","authors":["Kangning Yin","Weishuai Zeng","Ke Fan","Zirui Wang","Qiang Zhang","Zheng Tian","Jingbo Wang","Jiangmiao Pang","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.07356v1.pdf","comment":"10 pages, 5 figures"}]},"2025-07-09T00:00:00Z":{"Statistics - Machine Learning":[{"id":"http://arxiv.org/abs/2208.06528v5","updated":"2025-07-09T23:50:45Z","published":"2022-08-12T23:17:46Z","title":"Dynamic Bayesian Learning for Spatiotemporal Mechanistic Models","summary":"  We develop an approach for Bayesian learning of spatiotemporal dynamical\nmechanistic models. Such learning consists of statistical emulation of the\nmechanistic system that can efficiently interpolate the output of the system\nfrom arbitrary inputs. The emulated learner can then be used to train the\nsystem from noisy data achieved by melding information from observed data with\nthe emulated mechanistic system. This joint melding of mechanistic systems\nemploy hierarchical state-space models with Gaussian process regression.\nAssuming the dynamical system is controlled by a finite collection of inputs,\nGaussian process regression learns the effect of these parameters through a\nnumber of training runs, driving the stochastic innovations of the\nspatiotemporal state-space component. This enables efficient modeling of the\ndynamics over space and time. This article details exact inference with\nanalytically accessible posterior distributions in hierarchical matrix-variate\nNormal and Wishart models in designing the emulator. This step obviates\nexpensive iterative algorithms such as Markov chain Monte Carlo or variational\napproximations. We also show how emulation is applicable to large-scale\nemulation by designing a dynamic Bayesian transfer learning framework.\nInference on mechanistic model parameters proceeds using Markov chain Monte\nCarlo as a post-emulation step using the emulator as a regression component. We\ndemonstrate this framework through solving inverse problems arising in the\nanalysis of ordinary and partial nonlinear differential equations and, in\naddition, to a black-box computer model generating spatiotemporal dynamics\nacross a graphical model.\n","authors":["Sudipto Banerjee","Xiang Chen","Ian Frankenburg","Daniel Zhou"],"pdf_url":"https://arxiv.org/pdf/2208.06528v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07338v1","updated":"2025-07-09T23:47:26Z","published":"2025-07-09T23:47:26Z","title":"Bayesian Double Descent","summary":"  Double descent is a phenomenon of over-parameterized statistical models. Our\ngoal is to view double descent from a Bayesian perspective. Over-parameterized\nmodels such as deep neural networks have an interesting re-descending property\nin their risk characteristics. This is a recent phenomenon in machine learning\nand has been the subject of many studies. As the complexity of the model\nincreases, there is a U-shaped region corresponding to the traditional\nbias-variance trade-off, but then as the number of parameters equals the number\nof observations and the model becomes one of interpolation, the risk can become\ninfinite and then, in the over-parameterized region, it re-descends -- the\ndouble descent effect. We show that this has a natural Bayesian interpretation.\nMoreover, we show that it is not in conflict with the traditional Occam's razor\nthat Bayesian models possess, in that they tend to prefer simpler models when\npossible. We illustrate the approach with an example of Bayesian model\nselection in neural networks. Finally, we conclude with directions for future\nresearch.\n","authors":["Nick Polson","Vadim Sokolov"],"pdf_url":"https://arxiv.org/pdf/2507.07338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14507v4","updated":"2025-07-09T22:10:08Z","published":"2023-08-28T11:49:23Z","title":"Spectral Estimators for Structured Generalized Linear Models via\n  Approximate Message Passing","summary":"  We consider the problem of parameter estimation in a high-dimensional\ngeneralized linear model. Spectral methods obtained via the principal\neigenvector of a suitable data-dependent matrix provide a simple yet\nsurprisingly effective solution. However, despite their wide use, a rigorous\nperformance characterization, as well as a principled way to preprocess the\ndata, are available only for unstructured (i.i.d.\\ Gaussian and Haar\northogonal) designs. In contrast, real-world data matrices are highly\nstructured and exhibit non-trivial correlations. To address the problem, we\nconsider correlated Gaussian designs capturing the anisotropic nature of the\nfeatures via a covariance matrix $\\Sigma$. Our main result is a precise\nasymptotic characterization of the performance of spectral estimators. This\nallows us to identify the optimal preprocessing that minimizes the number of\nsamples needed for parameter estimation. Surprisingly, such preprocessing is\nuniversal across a broad set of designs, which partly addresses a conjecture on\noptimal spectral estimators for rotationally invariant models. Our principled\napproach vastly improves upon previous heuristic methods, including for designs\ncommon in computational imaging and genetics. The proposed methodology, based\non approximate message passing, is broadly applicable and opens the way to the\nprecise characterization of spiked matrices and of the corresponding spectral\nmethods in a variety of settings.\n","authors":["Yihan Zhang","Hong Chang Ji","Ramji Venkataramanan","Marco Mondelli"],"pdf_url":"https://arxiv.org/pdf/2308.14507v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14054v3","updated":"2025-07-09T21:33:30Z","published":"2024-10-17T21:52:00Z","title":"Adaptive Gradient Normalization and Independent Sampling for\n  (Stochastic) Generalized-Smooth Optimization","summary":"  Recent studies have shown that many nonconvex machine learning problems\nsatisfy a generalized-smooth condition that extends beyond traditional smooth\nnonconvex optimization. However, the existing algorithms are not fully adapted\nto such generalized-smooth nonconvex geometry and encounter significant\ntechnical limitations on their convergence analysis. In this work, we first\nanalyze the convergence of adaptively normalized gradient descent under\nfunction geometries characterized by generalized-smoothness and generalized\nP{\\L} condition, revealing the advantage of adaptive gradient normalization.\nOur results provide theoretical insights into adaptive normalization across\nvarious scenarios.For stochastic generalized-smooth nonconvex optimization, we\npropose \\textbf{I}ndependent-\\textbf{A}daptively \\textbf{N}ormalized\n\\textbf{S}tochastic \\textbf{G}radient \\textbf{D}escent algorithm, which\nleverages adaptive gradient normalization, independent sampling, and gradient\nclipping to achieve an $\\mathcal{O}(\\epsilon^{-4})$ sample complexity under\nrelaxed noise assumptions. Experiments on large-scale nonconvex\ngeneralized-smooth problems demonstrate the fast convergence of our algorithm.\n","authors":["Yufeng Yang","Erin Tripp","Yifan Sun","Shaofeng Zou","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.14054v3.pdf","comment":"40 pages, 1 tables"},{"id":"http://arxiv.org/abs/2409.08801v2","updated":"2025-07-09T21:03:33Z","published":"2024-09-13T13:10:02Z","title":"Finite Sample Analysis of Distribution-Free Confidence Ellipsoids for\n  Linear Regression","summary":"  The least squares (LS) estimate is the archetypical solution of linear\nregression problems. The asymptotic Gaussianity of the scaled LS error is often\nused to construct approximate confidence ellipsoids around the LS estimate,\nhowever, for finite samples these ellipsoids do not come with strict\nguarantees, unless some strong assumptions are made on the noise distributions.\nThe paper studies the distribution-free Sign-Perturbed Sums (SPS) ellipsoidal\nouter approximation (EOA) algorithm which can construct non-asymptotically\nguaranteed confidence ellipsoids under mild assumptions, such as independent\nand symmetric noise terms. These ellipsoids have the same center and\norientation as the classical asymptotic ellipsoids, only their radii are\ndifferent, which radii can be computed by convex optimization. Here, we\nestablish high probability non-asymptotic upper bounds for the sizes of SPS\nouter ellipsoids for linear regression problems and show that the volumes of\nthese ellipsoids decrease at the optimal rate. Finally, the difference between\nour theoretical bounds and the empirical sizes of the regions are investigated\nexperimentally.\n","authors":["Szabolcs Szentpéteri","Balázs Csanád Csáji"],"pdf_url":"https://arxiv.org/pdf/2409.08801v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07276v1","updated":"2025-07-09T20:49:10Z","published":"2025-07-09T20:49:10Z","title":"TRIP: A Nonparametric Test to Diagnose Biased Feature Importance Scores","summary":"  Along with accurate prediction, understanding the contribution of each\nfeature to the making of the prediction, i.e., the importance of the feature,\nis a desirable and arguably necessary component of a machine learning model.\nFor a complex model such as a random forest, such importances are not innate --\nas they are, e.g., with linear regression. Efficient methods have been created\nto provide such capabilities, with one of the most popular among them being\npermutation feature importance due to its efficiency, model-agnostic nature,\nand perceived intuitiveness. However, permutation feature importance has been\nshown to be misleading in the presence of dependent features as a result of the\ncreation of unrealistic observations when permuting the dependent features. In\nthis work, we develop TRIP (Test for Reliable Interpretation via Permutation),\na test requiring minimal assumptions that is able to detect unreliable\npermutation feature importance scores that are the result of model\nextrapolation. To build on this, we demonstrate how the test can be\ncomplemented in order to allow its use in high dimensional settings. Through\ntesting on simulated data and applications, our results show that the test can\nbe used to reliably detect when permutation feature importance scores are\nunreliable.\n","authors":["Aaron Foote","Danny Krizanc"],"pdf_url":"https://arxiv.org/pdf/2507.07276v1.pdf","comment":"Accepted at the Workshop on Explainable Artificial Intelligence (XAI)\n  at IJCAI 2025"},{"id":"http://arxiv.org/abs/2412.16209v2","updated":"2025-07-09T19:32:05Z","published":"2024-12-17T19:38:29Z","title":"Challenges learning from imbalanced data using tree-based models:\n  Prevalence estimates systematically depend on hyperparameters and can be\n  upwardly biased","summary":"  Imbalanced binary classification problems arise in many fields of study. When\nusing machine learning models for these problems, it is common to subsample the\nmajority class (i.e., undersampling) to create a (more) balanced dataset for\nmodel training. This biases the model's predictions because the model learns\nfrom a dataset that does not follow the same data generating process as new\ndata. One way of accounting for this bias is to analytically map the resulting\npredictions to new values based on the sampling rate for the majority class,\nwhich was used to create the training dataset. While this approach may work\nwell for some machine learning models, we show that calibrating a random forest\nthis way has unintended negative consequences, including prevalence estimates\nthat can be upwardly biased. These prevalence estimates depend on both i) the\nnumber of predictors considered at each split in the random forest; and ii) the\nsampling rate used. We explain the former using known properties of random\nforests and analytical calibration. However, in investigating the latter issue,\nwe made a surprising discovery - contrary to the widespread belief that\ndecision trees are biased towards the majority class, they actually can be\nbiased towards the minority class.\n","authors":["Nathan Phelps","Daniel J. Lizotte","Douglas G. Woolford"],"pdf_url":"https://arxiv.org/pdf/2412.16209v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07041v1","updated":"2025-07-09T17:06:01Z","published":"2025-07-09T17:06:01Z","title":"Non-Asymptotic Analysis of Online Local Private Learning with SGD","summary":"  Differentially Private Stochastic Gradient Descent (DP-SGD) has been widely\nused for solving optimization problems with privacy guarantees in machine\nlearning and statistics. Despite this, a systematic non-asymptotic convergence\nanalysis for DP-SGD, particularly in the context of online problems and local\ndifferential privacy (LDP) models, remains largely elusive. Existing\nnon-asymptotic analyses have focused on non-private optimization methods, and\nhence are not applicable to privacy-preserving optimization problems. This work\ninitiates the analysis to bridge this gap and opens the door to non-asymptotic\nconvergence analysis of private optimization problems. A general framework is\ninvestigated for the online LDP model in stochastic optimization problems. We\nassume that sensitive information from individuals is collected sequentially\nand aim to estimate, in real-time, a static parameter that pertains to the\npopulation of interest. Most importantly, we conduct a comprehensive\nnon-asymptotic convergence analysis of the proposed estimators in finite-sample\nsituations, which gives their users practical guidelines regarding the effect\nof various hyperparameters, such as step size, parameter dimensions, and\nprivacy budgets, on convergence rates. Our proposed estimators are validated in\nthe theoretical and practical realms by rigorous mathematical derivations and\ncarefully constructed numerical experiments.\n","authors":["Enze Shi","Jinhan Xie","Bei Jiang","Linglong Kong","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2507.07041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07156v1","updated":"2025-07-09T16:49:11Z","published":"2025-07-09T16:49:11Z","title":"Topological Machine Learning with Unreduced Persistence Diagrams","summary":"  Supervised machine learning pipelines trained on features derived from\npersistent homology have been experimentally observed to ignore much of the\ninformation contained in a persistence diagram. Computing persistence diagrams\nis often the most computationally demanding step in such a pipeline, however.\nTo explore this, we introduce several methods to generate topological feature\nvectors from unreduced boundary matrices. We compared the performance of\npipelines trained on vectorizations of unreduced PDs to vectorizations of\nfully-reduced PDs across several data and task types. Our results indicate that\nmodels trained on PDs built from unreduced diagrams can perform on par and even\noutperform those trained on fully-reduced diagrams on some tasks. This\nobservation suggests that machine learning pipelines which incorporate\ntopology-based features may benefit in terms of computational cost and\nperformance by utilizing information contained in unreduced boundary matrices.\n","authors":["Nicole Abreu","Parker B. Edwards","Francis Motta"],"pdf_url":"https://arxiv.org/pdf/2507.07156v1.pdf","comment":"10 figures, 2 tables, 8 pages(without appendix and references)"},{"id":"http://arxiv.org/abs/2507.03772v2","updated":"2025-07-09T16:28:55Z","published":"2025-07-04T18:45:10Z","title":"Skewed Score: A statistical framework to assess autograders","summary":"  The evaluation of large language model (LLM) outputs is increasingly\nperformed by other LLMs, a setup commonly known as \"LLM-as-a-judge\", or\nautograders. While autograders offer a scalable alternative to human\nevaluation, they have shown mixed reliability and may exhibit systematic\nbiases, depending on response type, scoring methodology, domain specificity, or\nother factors. Here we propose a statistical framework based on Bayesian\ngeneralised linear models (GLMs) that enables researchers to simultaneously\nassess their autograders while addressing their primary research questions\n(e.g., LLM evaluation). Our approach models evaluation outcomes (e.g., scores\nor pairwise preferences) as a function of properties of the grader (e.g., human\nvs. autograder) and the evaluated item (e.g., response length or the LLM that\ngenerated it), allowing for explicit quantification of scoring differences and\npotential biases within a unified framework. In addition, our method can be\nused to augment traditional metrics such as inter-rater agreement, by providing\nuncertainty estimates and clarifying sources of disagreement. Overall, this\napproach contributes to more robust and interpretable use of autograders in LLM\nevaluation, enabling both performance analysis and bias detection.\n","authors":["Magda Dubois","Harry Coppock","Mario Giulianelli","Timo Flesch","Lennart Luettgau","Cozmin Ududec"],"pdf_url":"https://arxiv.org/pdf/2507.03772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18811v2","updated":"2025-07-09T16:03:16Z","published":"2023-05-30T07:57:05Z","title":"PyPOTS: A Python Toolkit for Machine Learning on Partially-Observed Time\n  Series","summary":"  PyPOTS is an open-source Python library dedicated to data mining and analysis\non multivariate partially-observed time series with missing values.\nParticularly, it provides easy access to diverse algorithms categorized into\nfive tasks: imputation, forecasting, anomaly detection, classification, and\nclustering. The included models represent a diverse set of methodological\nparadigms, offering a unified and well-documented interface suitable for both\nacademic research and practical applications. With robustness and scalability\nin its design philosophy, best practices of software construction, for example,\nunit testing, continuous integration and continuous delivery, code coverage,\nmaintainability evaluation, interactive tutorials, and parallelization, are\ncarried out as principles during the development of PyPOTS. The toolbox is\navailable on PyPI, Anaconda, and Docker. PyPOTS is open source and publicly\navailable on GitHub https://github.com/WenjieDu/PyPOTS.\n","authors":["Wenjie Du","Yiyuan Yang","Linglong Qian","Jun Wang","Qingsong Wen"],"pdf_url":"https://arxiv.org/pdf/2305.18811v2.pdf","comment":"PyPOTS website is at https://pypots.com, and PyPOTS is open source at\n  https://github.com/WenjieDu/PyPOTS"},{"id":"http://arxiv.org/abs/2507.06969v1","updated":"2025-07-09T15:59:30Z","published":"2025-07-09T15:59:30Z","title":"Unifying Re-Identification, Attribute Inference, and Data Reconstruction\n  Risks in Differential Privacy","summary":"  Differentially private (DP) mechanisms are difficult to interpret and\ncalibrate because existing methods for mapping standard privacy parameters to\nconcrete privacy risks -- re-identification, attribute inference, and data\nreconstruction -- are both overly pessimistic and inconsistent. In this work,\nwe use the hypothesis-testing interpretation of DP ($f$-DP), and determine that\nbounds on attack success can take the same unified form across\nre-identification, attribute inference, and data reconstruction risks. Our\nunified bounds are (1) consistent across a multitude of attack settings, and\n(2) tunable, enabling practitioners to evaluate risk with respect to arbitrary\n(including worst-case) levels of baseline risk. Empirically, our results are\ntighter than prior methods using $\\varepsilon$-DP, R\\'enyi DP, and concentrated\nDP. As a result, calibrating noise using our bounds can reduce the required\nnoise by 20% at the same risk level, which yields, e.g., more than 15pp\naccuracy increase in a text classification task. Overall, this unifying\nperspective provides a principled framework for interpreting and calibrating\nthe degree of protection in DP against specific levels of re-identification,\nattribute inference, or data reconstruction risk.\n","authors":["Bogdan Kulynych","Juan Felipe Gomez","Georgios Kaissis","Jamie Hayes","Borja Balle","Flavio du Pin Calmon","Jean Louis Raisaro"],"pdf_url":"https://arxiv.org/pdf/2507.06969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06961v1","updated":"2025-07-09T15:46:39Z","published":"2025-07-09T15:46:39Z","title":"Off-Policy Evaluation Under Nonignorable Missing Data","summary":"  Off-Policy Evaluation (OPE) aims to estimate the value of a target policy\nusing offline data collected from potentially different policies. In real-world\napplications, however, logged data often suffers from missingness. While OPE\nhas been extensively studied in the literature, a theoretical understanding of\nhow missing data affects OPE results remains unclear. In this paper, we\ninvestigate OPE in the presence of monotone missingness and theoretically\ndemonstrate that the value estimates remain unbiased under ignorable\nmissingness but can be biased under nonignorable (informative) missingness. To\nretain the consistency of value estimation, we propose an inverse probability\nweighted value estimator and conduct statistical inference to quantify the\nuncertainty of the estimates. Through a series of numerical experiments, we\nempirically demonstrate that our proposed estimator yields a more reliable\nvalue inference under missing data.\n","authors":["Han Wang","Yang Xu","Wenbin Lu","Rui Song"],"pdf_url":"https://arxiv.org/pdf/2507.06961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.22675v3","updated":"2025-07-09T15:42:31Z","published":"2025-06-27T22:58:37Z","title":"Bayesian Invariance Modeling of Multi-Environment Data","summary":"  Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from\nmultiple environments to identify invariant features - those with a stable\npredictive relationship to the outcome. Such features support generalization to\nnew environments and help reveal causal mechanisms. Previous methods have\nprimarily tackled this problem through hypothesis testing or regularized\noptimization. Here we develop Bayesian Invariant Prediction (BIP), a\nprobabilistic model for invariant prediction. BIP encodes the indices of\ninvariant features as a latent variable and recover them by posterior\ninference. Under the assumptions of Peters et al. [2016], the BIP posterior\ntargets the true invariant features. We prove that the posterior is consistent\nand that greater environment heterogeneity leads to faster posterior\ncontraction. To handle many features, we design an efficient variational\napproximation called VI-BIP. In simulations and real data, we find that BIP and\nVI-BIP are more accurate and scalable than existing methods for invariant\nprediction.\n","authors":["Luhuan Wu","Mingzhang Yin","Yixin Wang","John P. Cunningham","David M. Blei"],"pdf_url":"https://arxiv.org/pdf/2506.22675v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06931v1","updated":"2025-07-09T15:13:44Z","published":"2025-07-09T15:13:44Z","title":"DICE: Data Influence Cascade in Decentralized Learning","summary":"  Decentralized learning offers a promising approach to crowdsource data\nconsumptions and computational workloads across geographically distributed\ncompute interconnected through peer-to-peer networks, accommodating the\nexponentially increasing demands. However, proper incentives are still in\nabsence, considerably discouraging participation. Our vision is that a fair\nincentive mechanism relies on fair attribution of contributions to\nparticipating nodes, which faces non-trivial challenges arising from the\nlocalized connections making influence ``cascade'' in a decentralized network.\nTo overcome this, we design the first method to estimate \\textbf{D}ata\n\\textbf{I}nfluence \\textbf{C}ascad\\textbf{E} (DICE) in a decentralized\nenvironment. Theoretically, the framework derives tractable approximations of\ninfluence cascade over arbitrary neighbor hops, suggesting the influence\ncascade is determined by an interplay of data, communication topology, and the\ncurvature of loss landscape. DICE also lays the foundations for applications\nincluding selecting suitable collaborators and identifying malicious behaviors.\nProject page is available at https://raiden-zhu.github.io/blog/2025/DICE/.\n","authors":["Tongtian Zhu","Wenhao Li","Can Wang","Fengxiang He"],"pdf_url":"https://arxiv.org/pdf/2507.06931v1.pdf","comment":"Published as a poster at ICLR 2025"},{"id":"http://arxiv.org/abs/2507.06921v1","updated":"2025-07-09T14:58:54Z","published":"2025-07-09T14:58:54Z","title":"Distribution-free inference for LightGBM and GLM with Tweedie loss","summary":"  Prediction uncertainty quantification is a key research topic in recent years\nscientific and business problems. In insurance industries\n(\\cite{parodi2023pricing}), assessing the range of possible claim costs for\nindividual drivers improves premium pricing accuracy. It also enables insurers\nto manage risk more effectively by accounting for uncertainty in accident\nlikelihood and severity. In the presence of covariates, a variety of\nregression-type models are often used for modeling insurance claims, ranging\nfrom relatively simple generalized linear models (GLMs) to regularized GLMs to\ngradient boosting models (GBMs). Conformal predictive inference has arisen as a\npopular distribution-free approach for quantifying predictive uncertainty under\nrelatively weak assumptions of exchangeability, and has been well studied under\nthe classic linear regression setting. In this work, we propose new\nnon-conformity measures for GLMs and GBMs with GLM-type loss. Using regularized\nTweedie GLM regression and LightGBM with Tweedie loss, we demonstrate conformal\nprediction performance with these non-conformity measures in insurance claims\ndata. Our simulation results favor the use of locally weighted Pearson\nresiduals for LightGBM over other methods considered, as the resulting\nintervals maintained the nominal coverage with the smallest average width.\n","authors":["Alokesh Manna","Aditya Vikram Sett","Dipak K. Dey","Yuwen Gu","Elizabeth D. Schifano","Jichao He"],"pdf_url":"https://arxiv.org/pdf/2507.06921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07498v3","updated":"2025-07-09T14:47:59Z","published":"2024-08-14T12:28:21Z","title":"Wasserstein Gradient Flows of MMD Functionals with Distance Kernel and\n  Cauchy Problems on Quantile Functions","summary":"  We give a comprehensive description of Wasserstein gradient flows of maximum\nmean discrepancy (MMD) functionals $\\mathcal F_\\nu := \\text{MMD}_K^2(\\cdot,\n\\nu)$ towards given target measures $\\nu$ on the real line, where we focus on\nthe negative distance kernel $K(x,y) := -|x-y|$. In one dimension, the\nWasserstein-2 space can be isometrically embedded into the cone $\\mathcal\nC(0,1) \\subset L_2(0,1)$ of quantile functions leading to a characterization of\nWasserstein gradient flows via the solution of an associated Cauchy problem on\n$L_2(0,1)$. Based on the construction of an appropriate counterpart of\n$\\mathcal F_\\nu$ on $L_2(0,1)$ and its subdifferential, we provide a solution\nof the Cauchy problem. For discrete target measures $\\nu$, this results in a\npiecewise linear solution formula. We prove invariance and smoothing properties\nof the flow on subsets of $\\mathcal C(0,1)$. For certain $\\mathcal F_\\nu$-flows\nthis implies that initial point measures instantly become absolutely\ncontinuous, and stay so over time. Finally, we illustrate the behavior of the\nflow by various numerical examples using an implicit Euler scheme, which is\neasily computable by a bisection algorithm. For continuous targets $\\nu$, also\nthe explicit Euler scheme can be employed, although with limited convergence\nguarantees.\n","authors":["Richard Duong","Viktor Stein","Robert Beinert","Johannes Hertrich","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2408.07498v3.pdf","comment":"We corrected the implicit scheme in our code and updated the plots.\n  Also, a minor mistake in the def. (14) has been corrected. 45 pages, 23\n  figures, comments welcome!"},{"id":"http://arxiv.org/abs/2506.15079v3","updated":"2025-07-09T14:45:44Z","published":"2025-06-18T02:45:25Z","title":"Neural Canonical Polyadic Factorization for Traffic Analysis","summary":"  Modern intelligent transportation systems rely on accurate spatiotemporal\ntraffic analysis to optimize urban mobility and infrastructure resilience.\nHowever, pervasive missing data caused by sensor failures and heterogeneous\nsensing gaps fundamentally hinders reliable traffic modeling. This paper\nproposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes\nlow-rank tensor algebra with deep representation learning for robust traffic\ndata imputation. The model innovatively embeds CP decomposition into neural\narchitecture through learnable embedding projections, where sparse traffic\ntensors are encoded into dense latent factors across road segments, time\nintervals, and mobility metrics. A hierarchical feature fusion mechanism\nemploys Hadamard products to explicitly model multilinear interactions, while\nstacked multilayer perceptron layers nonlinearly refine these representations\nto capture complex spatiotemporal couplings. Extensive evaluations on six urban\ntraffic datasets demonstrate NCPF's superiority over six state-of-the-art\nbaselines. By unifying CP decomposition's interpretable factor analysis with\nneural network's nonlinear expressive power, NCPF provides a principled yet\nflexible approaches for high-dimensional traffic data imputation, offering\ncritical support for next-generation transportation digital twins and adaptive\ntraffic control systems.\n","authors":["Wenyu Luo","Yikai Hou","Peng Tang"],"pdf_url":"https://arxiv.org/pdf/2506.15079v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06867v1","updated":"2025-07-09T14:08:50Z","published":"2025-07-09T14:08:50Z","title":"Conformal Prediction for Long-Tailed Classification","summary":"  Many real-world classification problems, such as plant identification, have\nextremely long-tailed class distributions. In order for prediction sets to be\nuseful in such settings, they should (i) provide good class-conditional\ncoverage, ensuring that rare classes are not systematically omitted from the\nprediction sets, and (ii) be a reasonable size, allowing users to easily verify\ncandidate labels. Unfortunately, existing conformal prediction methods, when\napplied to the long-tailed setting, force practitioners to make a binary choice\nbetween small sets with poor class-conditional coverage or sets with very good\nclass-conditional coverage but that are extremely large. We propose methods\nwith guaranteed marginal coverage that smoothly trade off between set size and\nclass-conditional coverage. First, we propose a conformal score function,\nprevalence-adjusted softmax, that targets a relaxed notion of class-conditional\ncoverage called macro-coverage. Second, we propose a label-weighted conformal\nprediction method that allows us to interpolate between marginal and\nclass-conditional conformal prediction. We demonstrate our methods on Pl@ntNet\nand iNaturalist, two long-tailed image datasets with 1,081 and 8,142 classes,\nrespectively.\n","authors":["Tiffany Ding","Jean-Baptiste Fermanian","Joseph Salmon"],"pdf_url":"https://arxiv.org/pdf/2507.06867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06844v1","updated":"2025-07-09T13:44:27Z","published":"2025-07-09T13:44:27Z","title":"Adaptive collaboration for online personalized distributed learning with\n  heterogeneous clients","summary":"  We study the problem of online personalized decentralized learning with $N$\nstatistically heterogeneous clients collaborating to accelerate local training.\nAn important challenge in this setting is to select relevant collaborators to\nreduce gradient variance while mitigating the introduced bias. To tackle this,\nwe introduce a gradient-based collaboration criterion, allowing each client to\ndynamically select peers with similar gradients during the optimization\nprocess. Our criterion is motivated by a refined and more general theoretical\nanalysis of the All-for-one algorithm, proved to be optimal in Even et al.\n(2022) for an oracle collaboration scheme. We derive excess loss upper-bounds\nfor smooth objective functions, being either strongly convex, non-convex, or\nsatisfying the Polyak-Lojasiewicz condition; our analysis reveals that the\nalgorithm acts as a variance reduction method where the speed-up depends on a\nsufficient variance. We put forward two collaboration methods instantiating the\nproposed general schema; and we show that one variant preserves the optimality\nof All-for-one. We validate our results with experiments on synthetic and real\ndatasets.\n","authors":["Constantin Philippenko","Batiste Le Bars","Kevin Scaman","Laurent Massoulié"],"pdf_url":"https://arxiv.org/pdf/2507.06844v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2507.06839v1","updated":"2025-07-09T13:39:37Z","published":"2025-07-09T13:39:37Z","title":"Scalable Gaussian Processes: Advances in Iterative Methods and Pathwise\n  Conditioning","summary":"  Gaussian processes are a powerful framework for uncertainty-aware function\napproximation and sequential decision-making. Unfortunately, their classical\nformulation does not scale gracefully to large amounts of data and modern\nhardware for massively-parallel computation, prompting many researchers to\ndevelop techniques which improve their scalability. This dissertation focuses\non the powerful combination of iterative methods and pathwise conditioning to\ndevelop methodological contributions which facilitate the use of Gaussian\nprocesses in modern large-scale settings. By combining these two techniques\nsynergistically, expensive computations are expressed as solutions to systems\nof linear equations and obtained by leveraging iterative linear system solvers.\nThis drastically reduces memory requirements, facilitating application to\nsignificantly larger amounts of data, and introduces matrix multiplication as\nthe main computational operation, which is ideal for modern hardware.\n","authors":["Jihao Andreas Lin"],"pdf_url":"https://arxiv.org/pdf/2507.06839v1.pdf","comment":"PhD Thesis, University of Cambridge"},{"id":"http://arxiv.org/abs/2007.14245v4","updated":"2025-07-09T13:07:00Z","published":"2020-07-11T21:43:20Z","title":"Bayesian Multi-Scale Neural Network for Crowd Counting","summary":"  Crowd counting is a challenging yet critical task in computer vision with\napplications ranging from public safety to urban planning. Recent advances\nusing Convolutional Neural Networks (CNNs) that estimate density maps have\nshown significant success. However, accurately counting individuals in highly\ncongested scenes remains an open problem due to severe occlusions, scale\nvariations, and perspective distortions, where people appear at drastically\ndifferent sizes across the image. In this work, we propose a novel deep\nlearning architecture that effectively addresses these challenges. Our network\nintegrates a ResNet-based feature extractor for capturing rich hierarchical\nrepresentations, followed by a downsampling block employing dilated\nconvolutions to preserve spatial resolution while expanding the receptive\nfield. An upsampling block using transposed convolutions reconstructs the\nhigh-resolution density map. Central to our architecture is a novel\nPerspective-aware Aggregation Module (PAM) designed to enhance robustness to\nscale and perspective variations by adaptively aggregating multi-scale\ncontextual information. We detail the training procedure, including the loss\nfunctions and optimization strategies used. Our method is evaluated on three\nwidely used benchmark datasets using Mean Absolute Error (MAE) and Mean Squared\nError (MSE) as evaluation metrics. Experimental results demonstrate that our\nmodel achieves superior performance compared to existing state-of-the-art\nmethods. Additionally, we incorporate principled Bayesian inference techniques\nto provide uncertainty estimates along with the crowd count predictions,\noffering a measure of confidence in the model's outputs.\n","authors":["Abhinav Sagar"],"pdf_url":"https://arxiv.org/pdf/2007.14245v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23244v2","updated":"2025-07-09T12:54:23Z","published":"2024-10-30T17:29:03Z","title":"Very fast Bayesian Additive Regression Trees on GPU","summary":"  Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian\nregression technique based on an ensemble of decision trees. It is part of the\ntoolbox of many statisticians. The overall statistical quality of the\nregression is typically higher than other generic alternatives, and it requires\nless manual tuning, making it a good default choice. However, it is a niche\nmethod compared to its natural competitor XGBoost, due to the longer running\ntime, making sample sizes above 10,000-100,000 a nuisance. I present a\nGPU-enabled implementation of BART, faster by up to 200x relative to a single\nCPU core, making BART competitive in running time with XGBoost. This\nimplementation is available in the Python package bartz.\n","authors":["Giacomo Petrillo"],"pdf_url":"https://arxiv.org/pdf/2410.23244v2.pdf","comment":"Check out the software at https://github.com/Gattocrucco/bartz"},{"id":"http://arxiv.org/abs/2507.04417v2","updated":"2025-07-09T12:33:51Z","published":"2025-07-06T15:13:31Z","title":"Neural Networks for Tamed Milstein Approximation of SDEs with Additive\n  Symmetric Jump Noise Driven by a Poisson Random Measure","summary":"  This work aims to estimate the drift and diffusion functions in stochastic\ndifferential equations (SDEs) driven by a particular class of L\\'evy processes\nwith finite jump intensity, using neural networks. We propose a framework that\nintegrates the Tamed-Milstein scheme with neural networks employed as\nnon-parametric function approximators. Estimation is carried out in a\nnon-parametric fashion for the drift function $f: \\mathbb{Z} \\to \\mathbb{R}$,\nthe diffusion coefficient $g: \\mathbb{Z} \\to \\mathbb{R}$. The model of interest\nis given by \\[ dX(t) = \\xi + f(X(t))\\, dt + g(X(t))\\, dW_t + \\gamma\n\\int_{\\mathbb{Z}} z\\, N(dt,dz), \\] where $W_t$ is a standard Brownian motion,\nand $N(dt,dz)$ is a Poisson random measure on $(\\mathbb{R}_{+} \\times\n\\mathbb{Z}$, $\\mathcal{B} (\\mathbb{R}_{+}) \\otimes \\mathcal{Z}$, $\\lambda(\n\\Lambda \\otimes v))$, with $\\lambda, \\gamma > 0$, $\\Lambda$ being the Lebesgue\nmeasure on $\\mathbb{R}_{+}$, and $v$ a finite measure on the measurable space\n$(\\mathbb{Z}, \\mathcal{Z})$. Neural networks are used as non-parametric\nfunction approximators, enabling the modeling of complex nonlinear dynamics\nwithout assuming restrictive functional forms. The proposed methodology\nconstitutes a flexible alternative for inference in systems with\nstate-dependent noise and discontinuities driven by L\\'evy processes.\n","authors":["Jose-Hermenegildo Ramirez-Gonzalez","Ying Sun"],"pdf_url":"https://arxiv.org/pdf/2507.04417v2.pdf","comment":"14 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2507.06775v1","updated":"2025-07-09T12:03:25Z","published":"2025-07-09T12:03:25Z","title":"Mutual Information Free Topological Generalization Bounds via Stability","summary":"  Providing generalization guarantees for stochastic optimization algorithms is\na major challenge in modern learning theory. Recently, several studies\nhighlighted the impact of the geometry of training trajectories on the\ngeneralization error, both theoretically and empirically. Among these works, a\nseries of topological generalization bounds have been proposed, relating the\ngeneralization error to notions of topological complexity that stem from\ntopological data analysis (TDA). Despite their empirical success, these bounds\nrely on intricate information-theoretic (IT) terms that can be bounded in\nspecific cases but remain intractable for practical algorithms (such as ADAM),\npotentially reducing the relevance of the derived bounds. In this paper, we\nseek to formulate comprehensive and interpretable topological generalization\nbounds free of intractable mutual information terms. To this end, we introduce\na novel learning theoretic framework that departs from the existing strategies\nvia proof techniques rooted in algorithmic stability. By extending an existing\nnotion of \\textit{hypothesis set stability}, to \\textit{trajectory stability},\nwe prove that the generalization error of trajectory-stable algorithms can be\nupper bounded in terms of (i) TDA quantities describing the complexity of the\ntrajectory of the optimizer in the parameter space, and (ii) the trajectory\nstability parameter of the algorithm. Through a series of experimental\nevaluations, we demonstrate that the TDA terms in the bound are of great\nimportance, especially as the number of training samples grows. This ultimately\nforms an explanation of the empirical success of the topological generalization\nbounds.\n","authors":["Mario Tuci","Lennart Bastian","Benjamin Dupuis","Nassir Navab","Tolga Birdal","Umut Şimşekli"],"pdf_url":"https://arxiv.org/pdf/2507.06775v1.pdf","comment":"25 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.13849v3","updated":"2025-07-09T12:01:30Z","published":"2024-10-17T17:59:01Z","title":"From Gradient Clipping to Normalization for Heavy Tailed SGD","summary":"  Recent empirical evidence indicates that many machine learning applications\ninvolve heavy-tailed gradient noise, which challenges the standard assumptions\nof bounded variance in stochastic optimization. Gradient clipping has emerged\nas a popular tool to handle this heavy-tailed noise, as it achieves good\nperformance in this setting both theoretically and practically. However, our\ncurrent theoretical understanding of non-convex gradient clipping has three\nmain shortcomings. First, the theory hinges on large, increasing clipping\nthresholds, which are in stark contrast to the small constant clipping\nthresholds employed in practice. Second, clipping thresholds require knowledge\nof problem-dependent parameters to guarantee convergence. Lastly, even with\nthis knowledge, current sampling complexity upper bounds for the method are\nsub-optimal in nearly all parameters. To address these issues, we study\nconvergence of Normalized SGD (NSGD). First, we establish a parameter-free\nsample complexity for NSGD of\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an\n$\\varepsilon$-stationary point. Furthermore, we prove tightness of this result,\nby providing a matching algorithm-specific lower bound. In the setting where\nall problem parameters are known, we show this complexity is improved to\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the\npreviously known lower bound for all first-order methods in all problem\ndependent parameters. Finally, we establish high-probability convergence of\nNSGD with a mild logarithmic dependence on the failure probability. Our work\ncomplements the studies of gradient clipping under heavy tailed noise improving\nthe sample complexities of existing algorithms and offering an alternative\nmechanism to achieve high probability convergence.\n","authors":["Florian Hübler","Ilyas Fatkhullin","Niao He"],"pdf_url":"https://arxiv.org/pdf/2410.13849v3.pdf","comment":"Fixed a typo, and removed the abuse of notation in the proof of\n  Theorem 4"},{"id":"http://arxiv.org/abs/2507.06752v1","updated":"2025-07-09T11:23:05Z","published":"2025-07-09T11:23:05Z","title":"Mathematical artificial data for operator learning","summary":"  Machine learning has emerged as a transformative tool for solving\ndifferential equations (DEs), yet prevailing methodologies remain constrained\nby dual limitations: data-driven methods demand costly labeled datasets while\nmodel-driven techniques face efficiency-accuracy trade-offs. We present the\nMathematical Artificial Data (MAD) framework, a new paradigm that integrates\nphysical laws with data-driven learning to facilitate large-scale operator\ndiscovery. By exploiting DEs' intrinsic mathematical structure to generate\nphysics-embedded analytical solutions and associated synthetic data, MAD\nfundamentally eliminates dependence on experimental or simulated training data.\nThis enables computationally efficient operator learning across multi-parameter\nsystems while maintaining mathematical rigor. Through numerical demonstrations\nspanning 2D parametric problems where both the boundary values and source term\nare functions, we showcase MAD's generalizability and superior\nefficiency/accuracy across various DE scenarios. This\nphysics-embedded-data-driven framework and its capacity to handle complex\nparameter spaces gives it the potential to become a universal paradigm for\nphysics-informed machine intelligence in scientific computing.\n","authors":["Heng Wu","Benzhuo Lu"],"pdf_url":"https://arxiv.org/pdf/2507.06752v1.pdf","comment":"22 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.06726v1","updated":"2025-07-09T10:36:37Z","published":"2025-07-09T10:36:37Z","title":"stCEG: An R Package for Modelling Events over Spatial Areas Using Chain\n  Event Graphs","summary":"  stCEG is an R package which allows a user to fully specify a Chain Event\nGraph (CEG) model from data and to produce interactive plots. It includes\nfunctions for the user to visualise spatial variables they wish to include in\nthe model. There is also a web-based graphical user interface (GUI) provided,\nincreasing ease of use for those without knowledge of R. We demonstrate stCEG\nusing a dataset of homicides in London, which is included in the package. stCEG\nis the first software package for CEGs that allows for full model\ncustomisation.\n","authors":["Hollie Calley","Daniel Williamson"],"pdf_url":"https://arxiv.org/pdf/2507.06726v1.pdf","comment":"30 pages, 20 figures. Submitted to the Journal of Statistical\n  Software"},{"id":"http://arxiv.org/abs/2504.04320v3","updated":"2025-07-09T10:00:04Z","published":"2025-04-06T01:37:50Z","title":"Causal Inference Isn't Special: Why It's Just Another Prediction Problem","summary":"  Causal inference is often portrayed as fundamentally distinct from predictive\nmodeling, with its own terminology, goals, and intellectual challenges. But at\nits core, causal inference is simply a structured instance of prediction under\ndistribution shift. In both cases, we begin with labeled data from a source\ndomain and seek to generalize to a target domain where outcomes are not\nobserved. The key difference is that in causal inference, the labels --\npotential outcomes -- are selectively observed based on treatment assignment,\nintroducing bias that must be addressed through assumptions. This perspective\nreframes causal estimation as a familiar generalization problem and highlights\nhow techniques from predictive modeling, such as reweighting and domain\nadaptation, apply directly to causal tasks. It also clarifies that causal\nassumptions are not uniquely strong -- they are simply more explicit. By\nviewing causal inference through the lens of prediction, we demystify its\nlogic, connect it to familiar tools, and make it more accessible to\npractitioners and educators alike.\n","authors":["Carlos Fernández-Loría"],"pdf_url":"https://arxiv.org/pdf/2504.04320v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16286v2","updated":"2025-07-09T09:34:24Z","published":"2023-11-27T20:02:55Z","title":"A statistical approach to latent dynamic modeling with differential\n  equations","summary":"  Ordinary differential equations (ODEs) can provide mechanistic models of\ntemporally local changes of processes, where parameters are often informed by\nexternal knowledge. While ODEs are popular in systems modeling, they are less\nestablished for statistical modeling of longitudinal cohort data, e.g., in a\nclinical setting. Yet, modeling of local changes could also be attractive for\nassessing the trajectory of an individual in a cohort in the immediate future\ngiven its current status, where ODE parameters could be informed by further\ncharacteristics of the individual. However, several hurdles so far limit such\nuse of ODEs, as compared to regression-based function fitting approaches. The\npotentially higher level of noise in cohort data might be detrimental to ODEs,\nas the shape of the ODE solution heavily depends on the initial value. In\naddition, larger numbers of variables multiply such problems and might be\ndifficult to handle for ODEs. To address this, we propose to use each\nobservation in the course of time as the initial value to obtain multiple local\nODE solutions and build a combined estimator of the underlying dynamics. Neural\nnetworks are used for obtaining a low-dimensional latent space for dynamic\nmodeling from a potentially large number of variables, and for obtaining\npatient-specific ODE parameters from baseline variables. Simultaneous\nidentification of dynamic models and of a latent space is enabled by recently\ndeveloped differentiable programming techniques. We illustrate the proposed\napproach in an application with spinal muscular atrophy patients and a\ncorresponding simulation study. In particular, modeling of local changes in\nhealth status at any point in time is contrasted to the interpretation of\nfunctions obtained from a global regression. This more generally highlights how\ndifferent application settings might demand different modeling strategies.\n","authors":["Maren Hackenberg","Astrid Pechmann","Clemens Kreutz","Janbernd Kirschner","Harald Binder"],"pdf_url":"https://arxiv.org/pdf/2311.16286v2.pdf","comment":"31 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.07150v1","updated":"2025-07-09T09:17:17Z","published":"2025-07-09T09:17:17Z","title":"Class conditional conformal prediction for multiple inputs by p-value\n  aggregation","summary":"  Conformal prediction methods are statistical tools designed to quantify\nuncertainty and generate predictive sets with guaranteed coverage\nprobabilities. This work introduces an innovative refinement to these methods\nfor classification tasks, specifically tailored for scenarios where multiple\nobservations (multi-inputs) of a single instance are available at prediction\ntime. Our approach is particularly motivated by applications in citizen\nscience, where multiple images of the same plant or animal are captured by\nindividuals. Our method integrates the information from each observation into\nconformal prediction, enabling a reduction in the size of the predicted label\nset while preserving the required class-conditional coverage guarantee. The\napproach is based on the aggregation of conformal p-values computed from each\nobservation of a multi-input. By exploiting the exact distribution of these\np-values, we propose a general aggregation framework using an abstract scoring\nfunction, encompassing many classical statistical tools. Knowledge of this\ndistribution also enables refined versions of standard strategies, such as\nmajority voting. We evaluate our method on simulated and real data, with a\nparticular focus on Pl@ntNet, a prominent citizen science platform that\nfacilitates the collection and identification of plant species through\nuser-submitted images.\n","authors":["Jean-Baptiste Fermanian","Mohamed Hebiri","Joseph Salmon"],"pdf_url":"https://arxiv.org/pdf/2507.07150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06677v1","updated":"2025-07-09T09:09:00Z","published":"2025-07-09T09:09:00Z","title":"Fast Gaussian Processes under Monotonicity Constraints","summary":"  Gaussian processes (GPs) are widely used as surrogate models for complicated\nfunctions in scientific and engineering applications. In many cases, prior\nknowledge about the function to be approximated, such as monotonicity, is\navailable and can be leveraged to improve model fidelity. Incorporating such\nconstraints into GP models enhances predictive accuracy and reduces\nuncertainty, but remains a computationally challenging task for\nhigh-dimensional problems. In this work, we present a novel virtual point-based\nframework for building constrained GP models under monotonicity constraints,\nbased on regularized linear randomize-then-optimize (RLRTO), which enables\nefficient sampling from a constrained posterior distribution by means of\nsolving randomized optimization problems. We also enhance two existing virtual\npoint-based approaches by replacing Gibbs sampling with the No U-Turn Sampler\n(NUTS) for improved efficiency. A Python implementation of these methods is\nprovided and can be easily applied to a wide range of problems. This\nimplementation is then used to validate the approaches on approximating a range\nof synthetic functions, demonstrating comparable predictive performance between\nall considered methods and significant improvements in computational efficiency\nwith the two NUTS methods and especially with the RLRTO method. The framework\nis further applied to construct surrogate models for systems of differential\nequations.\n","authors":["Chao Zhang","Jasper M. Everink","Jakob Sauer Jørgensen"],"pdf_url":"https://arxiv.org/pdf/2507.06677v1.pdf","comment":"35 pages, 10 figures"},{"id":"http://arxiv.org/abs/2507.06657v1","updated":"2025-07-09T08:41:39Z","published":"2025-07-09T08:41:39Z","title":"Non-asymptotic confidence regions on RKHS. The Paley-Wiener and standard\n  Sobolev space cases","summary":"  We consider the problem of constructing a global, probabilistic, and\nnon-asymptotic confidence region for an unknown function observed on a random\ndesign. The unknown function is assumed to lie in a reproducing kernel Hilbert\nspace (RKHS). We show that this construction can be reduced to accurately\nestimating the RKHS norm of the unknown function. Our analysis primarily\nfocuses both on the Paley-Wiener and on the standard Sobolev space settings.\n","authors":["Fabrice Gamboa","Olivier Roustant"],"pdf_url":"https://arxiv.org/pdf/2507.06657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20623v2","updated":"2025-07-09T08:24:09Z","published":"2025-06-25T17:12:22Z","title":"Lost in Retraining: Roaming the Parameter Space of Exponential Families\n  Under Closed-Loop Learning","summary":"  Closed-loop learning is the process of repeatedly estimating a model from\ndata generated from the model itself. It is receiving great attention due to\nthe possibility that large neural network models may, in the future, be\nprimarily trained with data generated by artificial neural networks themselves.\nWe study this process for models that belong to exponential families, deriving\nequations of motions that govern the dynamics of the parameters. We show that\nmaximum likelihood estimation of the parameters endows sufficient statistics\nwith the martingale property and that as a result the process converges to\nabsorbing states that amplify initial biases present in the data. However, we\nshow that this outcome may be prevented if the data contains at least one data\npoint generated from a ground truth model, by relying on maximum a posteriori\nestimation or by introducing regularisation.\n","authors":["Fariba Jangjoo","Matteo Marsili","Yasser Roudi"],"pdf_url":"https://arxiv.org/pdf/2506.20623v2.pdf","comment":"21 pages, 3 figures"},{"id":"http://arxiv.org/abs/2507.06637v1","updated":"2025-07-09T08:06:50Z","published":"2025-07-09T08:06:50Z","title":"Semi-parametric Functional Classification via Path Signatures Logistic\n  Regression","summary":"  We propose Path Signatures Logistic Regression (PSLR), a semi-parametric\nframework for classifying vector-valued functional data with scalar covariates.\nClassical functional logistic regression models rely on linear assumptions and\nfixed basis expansions, which limit flexibility and degrade performance under\nirregular sampling. PSLR overcomes these issues by leveraging truncated path\nsignatures to construct a finite-dimensional, basis-free representation that\ncaptures nonlinear and cross-channel dependencies. By embedding trajectories as\ntime-augmented paths, PSLR extracts stable, geometry-aware features that are\nrobust to sampling irregularity without requiring a common time grid, while\nstill preserving subject-specific timing patterns. We establish theoretical\nguarantees for the existence and consistent estimation of the optimal\ntruncation order, along with non-asymptotic risk bounds. Experiments on\nsynthetic and real-world datasets show that PSLR outperforms traditional\nfunctional classifiers in accuracy, robustness, and interpretability,\nparticularly under non-uniform sampling schemes. Our results highlight the\npractical and theoretical benefits of integrating rough path theory into modern\nfunctional data analysis.\n","authors":["Pengcheng Zeng","Siyuan Jiang"],"pdf_url":"https://arxiv.org/pdf/2507.06637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06619v1","updated":"2025-07-09T07:46:29Z","published":"2025-07-09T07:46:29Z","title":"Steps Adaptive Decay DPSGD: Enhancing Performance on Imbalanced Datasets\n  with Differential Privacy with HAM10000","summary":"  When applying machine learning to medical image classification, data leakage\nis a critical issue. Previous methods, such as adding noise to gradients for\ndifferential privacy, work well on large datasets like MNIST and CIFAR-100, but\nfail on small, imbalanced medical datasets like HAM10000. This is because the\nimbalanced distribution causes gradients from minority classes to be clipped\nand lose crucial information, while majority classes dominate. This leads the\nmodel to fall into suboptimal solutions early. To address this, we propose\nSAD-DPSGD, which uses a linear decaying mechanism for noise and clipping\nthresholds. By allocating more privacy budget and using higher clipping\nthresholds in the initial training phases, the model avoids suboptimal\nsolutions and enhances performance. Experiments show that SAD-DPSGD outperforms\nAuto-DPSGD on HAM10000, improving accuracy by 2.15% under $\\epsilon = 3.0$ ,\n$\\delta = 10^{-3}$.\n","authors":["Xiaobo Huang","Fang Xie"],"pdf_url":"https://arxiv.org/pdf/2507.06619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.07308v2","updated":"2025-07-09T05:41:13Z","published":"2025-06-08T22:48:07Z","title":"PASS: Private Attributes Protection with Stochastic Data Substitution","summary":"  The growing Machine Learning (ML) services require extensive collections of\nuser data, which may inadvertently include people's private information\nirrelevant to the services. Various studies have been proposed to protect\nprivate attributes by removing them from the data while maintaining the\nutilities of the data for downstream tasks. Nevertheless, as we theoretically\nand empirically show in the paper, these methods reveal severe vulnerability\nbecause of a common weakness rooted in their adversarial training based\nstrategies. To overcome this limitation, we propose a novel approach, PASS,\ndesigned to stochastically substitute the original sample with another one\naccording to certain probabilities, which is trained with a novel loss function\nsoundly derived from information-theoretic objective defined for\nutility-preserving private attributes protection. The comprehensive evaluation\nof PASS on various datasets of different modalities, including facial images,\nhuman activity sensory signals, and voice recording datasets, substantiates\nPASS's effectiveness and generalizability.\n","authors":["Yizhuo Chen"," Chun-Fu"," Chen","Hsiang Hsu","Shaohan Hu","Tarek Abdelzaher"],"pdf_url":"https://arxiv.org/pdf/2506.07308v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06552v1","updated":"2025-07-09T05:11:19Z","published":"2025-07-09T05:11:19Z","title":"On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and\n  Information-Theoretic Perspective","summary":"  This paper studies the hardness of unsupervised domain adaptation (UDA) under\ncovariate shift. We model the uncertainty that the learner faces by a\ndistribution $\\pi$ in the ground-truth triples $(p, q, f)$ -- which we call a\nUDA class -- where $(p, q)$ is the source -- target distribution pair and $f$\nis the classifier. We define the performance of a learner as the overall target\ndomain risk, averaged over the randomness of the ground-truth triple. This\nformulation couples the source distribution, the target distribution and the\nclassifier in the ground truth, and deviates from the classical worst-case\nanalyses, which pessimistically emphasize the impact of hard but rare UDA\ninstances. In this formulation, we precisely characterize the optimal learner.\nThe performance of the optimal learner then allows us to define the learning\ndifficulty for the UDA class and for the observed sample. To quantify this\ndifficulty, we introduce an information-theoretic quantity -- Posterior Target\nLabel Uncertainty (PTLU) -- along with its empirical estimate (EPTLU) from the\nsample , which capture the uncertainty in the prediction for the target domain.\nBriefly, PTLU is the entropy of the predicted label in the target domain under\nthe posterior distribution of ground-truth classifier given the observed source\nand target samples. By proving that such a quantity serves to lower-bound the\nrisk of any learner, we suggest that these quantities can be used as proxies\nfor evaluating the hardness of UDA learning. We provide several examples to\ndemonstrate the advantage of PTLU, relative to the existing measures, in\nevaluating the difficulty of UDA learning.\n","authors":["Zhiyi Dong","Zixuan Liu","Yongyi Mao"],"pdf_url":"https://arxiv.org/pdf/2507.06552v1.pdf","comment":"Accepted at the 4th Conference on Lifelong Learning Agents (CoLLAs\n  2025)"}],"Robotics":[{"id":"http://arxiv.org/abs/2410.13973v4","updated":"2025-07-09T23:40:31Z","published":"2024-10-17T18:57:15Z","title":"MarineFormer: A Spatio-Temporal Attention Model for USV Navigation in\n  Dynamic Marine Environments","summary":"  Autonomous navigation in marine environments can be extremely challenging,\nespecially in the presence of spatially varying flow disturbances and dynamic\nand static obstacles. In this work, we demonstrate that incorporating local\nflow field measurements fundamentally alters the nature of the problem,\ntransforming otherwise unsolvable navigation scenarios into tractable ones.\nHowever, the mere availability of flow data is not sufficient; it must be\neffectively fused with conventional sensory inputs such as ego-state and\nobstacle states. To this end, we propose \\textbf{MarineFormer}, a\nTransformer-based policy architecture that integrates two complementary\nattention mechanisms: spatial attention for sensor fusion, and temporal\nattention for capturing environmental dynamics. MarineFormer is trained\nend-to-end via reinforcement learning in a 2D simulated environment with\nrealistic flow features and obstacles. Extensive evaluations against classical\nand state-of-the-art baselines show that our approach improves episode\ncompletion success rate by nearly 23\\% while reducing path length. Ablation\nstudies further highlight the critical role of flow measurements and the\neffectiveness of our proposed architecture in leveraging them.\n","authors":["Ehsan Kazemi","Dechen Gao","Iman Soltani"],"pdf_url":"https://arxiv.org/pdf/2410.13973v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07327v1","updated":"2025-07-09T23:03:30Z","published":"2025-07-09T23:03:30Z","title":"Effects of Wrist-Worn Haptic Feedback on Force Accuracy and Task Speed\n  during a Teleoperated Robotic Surgery Task","summary":"  Previous work has shown that the addition of haptic feedback to the hands can\nimprove awareness of tool-tissue interactions and enhance performance of\nteleoperated tasks in robot-assisted minimally invasive surgery. However,\nhand-based haptic feedback occludes direct interaction with the manipulanda of\nsurgeon console in teleoperated surgical robots. We propose relocating haptic\nfeedback to the wrist using a wearable haptic device so that haptic feedback\nmechanisms do not need to be integrated into the manipulanda. However, it is\nunknown if such feedback will be effective, given that it is not co-located\nwith the finger movements used for manipulation. To test if relocated haptic\nfeedback improves force application during teleoperated tasks using da Vinci\nResearch Kit (dVRK) surgical robot, participants learned to palpate a phantom\ntissue to desired forces. A soft pneumatic wrist-worn haptic device with an\nanchoring system renders tool-tissue interaction forces to the wrist of the\nuser. Participants performed the palpation task with and without wrist-worn\nhaptic feedback and were evaluated for the accuracy of applied forces.\nParticipants demonstrated statistically significant lower force error when\nwrist-worn haptic feedback was provided. Participants also performed the\npalpation task with longer movement times when provided wrist-worn haptic\nfeedback, indicating that the haptic feedback may have caused participants to\noperate at a different point in the speed-accuracy tradeoff curve.\n","authors":["Brian B. Vuong","Josie Davidson","Sangheui Cheon","Kyujin Cho","Allison M. Okamura"],"pdf_url":"https://arxiv.org/pdf/2507.07327v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2507.07315v1","updated":"2025-07-09T22:25:35Z","published":"2025-07-09T22:25:35Z","title":"Classifying Emergence in Robot Swarms: An Observer-Dependent Approach","summary":"  Emergence and swarms are widely discussed topics, yet no consensus exists on\ntheir formal definitions. This lack of agreement makes it difficult not only\nfor new researchers to grasp these concepts, but also for experts who may use\nthe same terms to mean different things. Many attempts have been made to\nobjectively define 'swarm' or 'emergence,' with recent work highlighting the\nrole of the external observer. Still, several researchers argue that once an\nobserver's vantage point (e.g., scope, resolution, context) is established, the\nterms can be made objective or measured quantitatively. In this note, we\npropose a framework to discuss these ideas rigorously by separating externally\nobservable states from latent, unobservable ones. This allows us to compare and\ncontrast existing definitions of swarms and emergence on common ground. We\nargue that these concepts are ultimately subjective-shaped less by the system\nitself than by the perception and tacit knowledge of the observer.\nSpecifically, we suggest that a 'swarm' is not defined by its group behavior\nalone, but by the process generating that behavior. Our broader goal is to\nsupport the design and deployment of robotic swarm systems, highlighting the\ncritical distinction between multi-robot systems and true swarms.\n","authors":["Ricardo Vega","Cameron Nowzari"],"pdf_url":"https://arxiv.org/pdf/2507.07315v1.pdf","comment":"25 pages, 3 tables, 8 figures"},{"id":"http://arxiv.org/abs/2507.07302v1","updated":"2025-07-09T22:01:32Z","published":"2025-07-09T22:01:32Z","title":"Application of LLMs to Multi-Robot Path Planning and Task Allocation","summary":"  Efficient exploration is a well known problem in deep reinforcement learning\nand this problem is exacerbated in multi-agent reinforcement learning due the\nintrinsic complexities of such algorithms. There are several approaches to\nefficiently explore an environment to learn to solve tasks by multi-agent\noperating in that environment, of which, the idea of expert exploration is\ninvestigated in this work. More specifically, this work investigates the\napplication of large-language models as expert planners for efficient\nexploration in planning based tasks for multiple agents.\n","authors":["Ashish Kumar"],"pdf_url":"https://arxiv.org/pdf/2507.07302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07299v1","updated":"2025-07-09T21:46:43Z","published":"2025-07-09T21:46:43Z","title":"LangNavBench: Evaluation of Natural Language Understanding in Semantic\n  Navigation","summary":"  Recent progress in large vision-language models has driven improvements in\nlanguage-based semantic navigation, where an embodied agent must reach a target\nobject described in natural language. Despite these advances, we still lack a\nclear, language-focused benchmark for testing how well such agents ground the\nwords in their instructions. We address this gap with LangNav, an open-set\ndataset specifically created to test an agent's ability to locate objects\ndescribed at different levels of detail, from broad category names to fine\nattributes and object-object relations. Every description in LangNav was\nmanually checked, yielding a lower error rate than existing lifelong- and\nsemantic-navigation datasets. On top of LangNav we build LangNavBench, a\nbenchmark that measures how well current semantic-navigation methods understand\nand act on these descriptions while moving toward their targets. LangNavBench\nallows us to systematically compare models on their handling of attributes,\nspatial and relational cues, and category hierarchies, offering the first\nthorough, language-centric evaluation of embodied navigation systems. We also\npresent Multi-Layered Feature Map (MLFM), a method that builds a queryable\nmulti-layered semantic map, particularly effective when dealing with small\nobjects or instructions involving spatial relations. MLFM outperforms\nstate-of-the-art mapping-based navigation baselines on the LangNav dataset.\n","authors":["Sonia Raychaudhuri","Enrico Cancelli","Tommaso Campari","Lamberto Ballan","Manolis Savva","Angel X. Chang"],"pdf_url":"https://arxiv.org/pdf/2507.07299v1.pdf","comment":null}]}}